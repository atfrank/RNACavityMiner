Total number of RNAS: 131 Total number of samples: 6676
Number of positive samples: 404
Number of negative samples: 6272
Number of training samples: 4265
Number of test 1 samples: 1090
Number of test 2 samples: 1275
Number of test 3 samples: 46
Number of features: 340
Fitting 3 folds for each of 300 candidates, totalling 900 fits
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=190, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=   6.5s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=150, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   7.5s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=90, reg_alpha=1.1, reg_lambda=1.3, subsample=0.7; total time=   4.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=25, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=   1.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=85, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=   2.4s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=125, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=   3.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=335, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=   8.5s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=335, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=   8.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=215, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=   5.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=30, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   0.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=235, reg_alpha=1.1, reg_lambda=1.1, subsample=0.9; total time=   6.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=390, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=  18.2s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=35, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=   2.2s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=280, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=  15.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=145, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   8.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=340, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=  16.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=185, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   5.2s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=185, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   5.2s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=475, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=  21.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=30, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   1.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=150, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   4.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=80, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=   2.2s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=300, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=   8.3s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=75, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=   3.8s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=265, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=   7.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=365, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=  19.4s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=200, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=   5.8s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=210, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   5.4s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=415, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=  10.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=50, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=   2.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=50, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=   2.7s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=280, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=   7.0s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=270, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=   7.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=335, reg_alpha=1.3, reg_lambda=1.1, subsample=0.8; total time=  18.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=100, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   5.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=420, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=  21.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=470, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  12.9s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=305, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=  15.7s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=395, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=   9.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=130, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=   7.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=190, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=   5.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=495, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=  14.2s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=445, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  20.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=465, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  20.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=385, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=  21.2s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=405, reg_alpha=1.1, reg_lambda=1.1, subsample=0.9; total time=  19.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=155, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   8.2s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=310, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   8.5s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=95, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=   4.8s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=315, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=   8.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=205, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=   5.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=205, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=   5.9s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=115, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=   2.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=385, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=  20.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=385, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=  18.4s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=235, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=   6.0s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=485, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=  13.8s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=290, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   7.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=110, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=   6.6s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=140, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=   3.7s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=240, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=   6.0s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=425, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  19.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=65, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   3.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=65, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   3.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=160, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   9.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=90, reg_alpha=1.1, reg_lambda=1.3, subsample=0.7; total time=   4.5s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=490, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=  24.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=60, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   3.0s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=80, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   2.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=45, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   1.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=45, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   1.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=325, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=   8.9s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=390, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=  18.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=175, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=  10.0s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=220, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   5.4s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=220, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   5.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=145, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   8.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=70, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   4.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=170, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=   9.8s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=285, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=  15.9s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=400, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=  18.8s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=150, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   4.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=350, reg_alpha=1.1, reg_lambda=1.2, subsample=0.8; total time=  19.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=465, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  11.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=415, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  10.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=200, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=   5.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=170, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=  10.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=475, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=  24.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=65, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   3.4s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=400, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=  10.9s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=385, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   9.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=400, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=  18.6s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=85, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   2.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=360, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=  20.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=20, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=   0.6s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=20, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=   0.6s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=20, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=   0.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=190, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   9.7s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=395, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=   9.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=340, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=  18.2s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=495, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=  14.2s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=495, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=  14.3s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=465, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  20.9s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=495, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=  12.4s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=115, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   2.9s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=405, reg_alpha=1.1, reg_lambda=1.1, subsample=0.9; total time=  19.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=250, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=  12.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=195, reg_alpha=1.1, reg_lambda=1.1, subsample=0.9; total time=   5.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=495, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=  13.8s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=465, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=  23.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=265, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   6.5s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=35, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   2.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=475, reg_alpha=1.1, reg_lambda=1.3, subsample=0.7; total time=  24.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=175, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   9.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=445, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=  20.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=80, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   2.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=150, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   4.2s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=440, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  20.0s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=125, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=   3.5s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=370, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   9.3s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=65, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   3.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=280, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   7.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=185, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   5.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=335, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=  18.0s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=490, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=  13.5s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=240, reg_alpha=1.1, reg_lambda=1.2, subsample=0.8; total time=   6.0s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=240, reg_alpha=1.1, reg_lambda=1.2, subsample=0.8; total time=   6.0s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=25, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   0.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=190, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=   6.3s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=150, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   7.5s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=90, reg_alpha=1.1, reg_lambda=1.3, subsample=0.7; total time=   4.5s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=25, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=   1.5s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=425, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  22.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=300, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=  17.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=30, reg_alpha=1.3, reg_lambda=1.1, subsample=0.8; total time=   1.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=325, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=  16.4s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=85, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=   2.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=100, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   3.0s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=220, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   5.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=315, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=  15.8s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=70, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   4.2s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=265, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=  15.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=390, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  20.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=420, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=  19.5s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=75, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=   3.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=265, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=   7.8s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=465, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  11.5s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=230, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=  13.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=170, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=  10.2s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=475, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=  25.0s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=335, reg_alpha=1.3, reg_lambda=1.1, subsample=0.8; total time=  19.0s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=100, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   6.0s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=420, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=  22.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=360, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=  20.2s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=190, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   9.9s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=55, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=   2.8s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=495, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  25.0s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=55, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   3.3s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=445, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  20.3s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=145, reg_alpha=1.3, reg_lambda=1.1, subsample=0.8; total time=   7.5s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=490, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=  22.0s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=70, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   2.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=70, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   2.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=70, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   2.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=115, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   2.9s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=115, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   2.9s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=405, reg_alpha=1.1, reg_lambda=1.1, subsample=0.9; total time=  19.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=145, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=   4.1s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=155, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   8.2s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=195, reg_alpha=1.1, reg_lambda=1.1, subsample=0.9; total time=   5.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=495, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=  14.2s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=395, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=  21.2s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=265, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   6.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=35, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   2.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=35, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   2.2s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=475, reg_alpha=1.1, reg_lambda=1.3, subsample=0.7; total time=  24.4s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=235, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=   6.2s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=485, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=  14.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=290, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   7.4s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=80, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   2.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=80, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   2.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=210, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   5.9s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=210, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=  11.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=205, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=   5.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=125, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=   3.6s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=370, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   9.4s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=300, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   7.6s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=280, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   7.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=335, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=  18.4s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=315, reg_alpha=1.1, reg_lambda=1.3, subsample=0.7; total time=   8.8s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=110, reg_alpha=1.1, reg_lambda=1.2, subsample=0.8; total time=   6.4s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=240, reg_alpha=1.1, reg_lambda=1.2, subsample=0.8; total time=   6.1s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=160, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   9.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=150, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   7.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=490, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=  23.8s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=80, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   2.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=300, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=  17.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=145, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=   4.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=175, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=  10.0s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=35, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=   2.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=85, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=   2.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=100, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   2.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=490, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=  13.5s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=340, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=  16.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=285, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=  16.0s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=475, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=  21.1s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=30, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   1.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=30, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   1.6s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=80, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=   2.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=80, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=   2.2s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=350, reg_alpha=1.1, reg_lambda=1.2, subsample=0.8; total time=  19.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=465, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  11.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=230, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=  13.2s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=170, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=  10.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=80, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=   2.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=455, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  23.1s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=65, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   3.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=335, reg_alpha=1.3, reg_lambda=1.1, subsample=0.8; total time=  18.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=400, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=  18.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=220, reg_alpha=1.1, reg_lambda=1.1, subsample=0.9; total time=  13.0s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=405, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=  21.9s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=190, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   9.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=130, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=   7.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=190, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=   5.2s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=190, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=   5.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=495, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=  14.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=495, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=  14.3s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=465, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  21.0s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=495, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=  12.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=315, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  17.0s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=395, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=   9.8s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=145, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=   4.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=265, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   7.5s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=455, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=  11.5s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=95, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=   4.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=465, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=  23.4s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=265, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   6.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=345, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=  17.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=185, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   5.2s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=175, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   9.7s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=330, reg_alpha=1.1, reg_lambda=1.3, subsample=0.7; total time=   8.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=425, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  12.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=290, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   7.4s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=150, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   4.2s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=440, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  20.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=205, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=   5.9s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=180, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   8.9s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=300, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=   7.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=185, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   5.2s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=185, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=   9.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=170, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   4.7s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=325, reg_alpha=1.3, reg_lambda=1.1, subsample=0.8; total time=   8.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=315, reg_alpha=1.1, reg_lambda=1.3, subsample=0.7; total time=   8.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=350, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   9.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=60, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=   3.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=245, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=  14.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=325, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=  19.4s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=85, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=   2.4s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=125, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=   3.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=125, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=   3.2s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=335, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=   8.5s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=60, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   3.0s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=80, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   2.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=215, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=   5.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=30, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   0.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=30, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   0.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=235, reg_alpha=1.1, reg_lambda=1.1, subsample=0.9; total time=   6.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=145, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=   4.2s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=30, reg_alpha=1.3, reg_lambda=1.1, subsample=0.8; total time=   1.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=325, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=  16.0s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=85, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=   2.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=490, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=  13.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=145, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   8.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=70, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   4.2s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=265, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=  15.5s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=390, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  20.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=420, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=  19.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=300, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=   8.2s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=155, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=   7.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=365, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=  19.2s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=165, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   9.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=415, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=  10.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=455, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  22.8s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=400, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=  10.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=335, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  19.0s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=220, reg_alpha=1.1, reg_lambda=1.1, subsample=0.9; total time=  13.0s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=470, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  13.0s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=305, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=  15.8s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=395, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=  10.0s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=340, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=  18.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=55, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   3.2s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=440, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=  12.9s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=165, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=   8.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=145, reg_alpha=1.3, reg_lambda=1.1, subsample=0.8; total time=   7.4s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=465, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=  13.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=465, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=  13.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=315, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  17.0s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=395, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=   9.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=145, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=   4.0s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=155, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   8.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=310, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   8.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=495, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=  14.0s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=395, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=  20.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=345, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=  17.2s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=385, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=  18.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=330, reg_alpha=1.1, reg_lambda=1.3, subsample=0.7; total time=   8.1s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=445, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=  20.2s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=210, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   5.9s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=240, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=   6.1s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=210, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=  10.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=205, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=   6.0s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=370, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   9.2s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=300, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   7.5s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=195, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=  11.6s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=250, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=   6.4s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=170, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   4.8s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=490, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=  13.4s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=350, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   9.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=395, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=  18.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=465, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=  13.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=325, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=  19.4s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=85, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=   2.5s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=425, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  22.2s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=45, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   1.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=325, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=   9.0s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=235, reg_alpha=1.1, reg_lambda=1.1, subsample=0.9; total time=   6.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=30, reg_alpha=1.3, reg_lambda=1.1, subsample=0.8; total time=   1.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=325, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=  16.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=100, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   2.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=490, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=  13.3s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=340, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=  16.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=265, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=  15.5s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=475, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=  21.2s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=420, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=  19.5s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=75, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=   3.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=155, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=   7.7s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=415, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  10.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=230, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=  13.0s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=210, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   5.4s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=80, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=   2.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=80, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=   2.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=455, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  23.4s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=270, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=   7.0s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=385, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   9.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=100, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   5.9s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=400, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=  18.5s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=85, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   2.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=85, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   2.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=360, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=  20.0s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=305, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=  15.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=495, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  24.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=55, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   3.2s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=445, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  20.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=145, reg_alpha=1.3, reg_lambda=1.1, subsample=0.8; total time=   7.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=490, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=  21.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=385, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=  20.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=225, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=   6.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=250, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=  12.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=265, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   7.4s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=455, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=  11.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=465, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=  23.5s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=385, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=  20.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=385, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=  18.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=235, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=   6.0s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=445, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=  20.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=110, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=   6.5s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=140, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=   3.7s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=240, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=   6.0s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=425, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  19.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=180, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   8.9s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=280, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   7.2s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=25, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   0.8s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=25, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   0.7s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=25, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   0.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=185, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=   9.4s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=250, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=   6.4s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=490, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=  13.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=20, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   1.2s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=405, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=  11.5s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=60, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=   3.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=25, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   0.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=410, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=  11.9s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=405, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=  10.4s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=370, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=   9.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=190, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=   6.3s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=160, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   8.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=490, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=  23.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=60, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   3.0s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=215, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=   6.0s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=325, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=   8.9s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=390, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=  18.2s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=280, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=  15.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=315, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=  15.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=170, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=   9.8s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=285, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=  16.0s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=400, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=  19.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=150, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   4.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=350, reg_alpha=1.1, reg_lambda=1.2, subsample=0.8; total time=  19.3s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=155, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=   7.6s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=415, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  10.4s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=200, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=   5.8s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=165, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   9.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=415, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=  11.0s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=50, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=   2.7s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=280, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=   7.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=280, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=   7.0s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=270, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=   6.9s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=385, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   9.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=335, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  19.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=220, reg_alpha=1.1, reg_lambda=1.1, subsample=0.9; total time=  13.0s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=470, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  12.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=405, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=  21.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=495, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  24.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=440, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=  12.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=495, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=  14.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=30, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   0.8s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=30, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   0.8s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=30, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   0.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=490, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=  22.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=385, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=  20.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=225, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=   6.5s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=395, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=   9.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=265, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   7.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=310, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   8.5s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=95, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=   4.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=315, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=   9.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=395, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=  20.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=345, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=  17.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=185, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   5.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=185, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   5.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=175, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   9.8s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=485, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=  13.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=425, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  12.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=210, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   5.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=440, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  20.2s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=125, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=   3.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=180, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   8.8s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=300, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=   7.5s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=195, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=  11.5s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=250, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=   6.4s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=325, reg_alpha=1.3, reg_lambda=1.1, subsample=0.8; total time=   8.2s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=315, reg_alpha=1.1, reg_lambda=1.3, subsample=0.7; total time=   8.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=20, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   1.2s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=405, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=  11.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=245, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=  14.4s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=410, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=  11.9s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=35, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=   1.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=410, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=  19.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=325, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=  19.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=25, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=   1.5s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=425, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  22.2s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=300, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=  17.2s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=145, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=   4.2s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=175, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=  10.0s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=35, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=   2.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=280, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=  15.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=315, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=  15.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=170, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=   9.8s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=185, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   5.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=390, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  20.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=400, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=  19.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=300, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=   8.2s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=265, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=   7.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=365, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=  19.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=165, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   9.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=210, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   5.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=475, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=  24.3s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=65, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   3.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=400, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=  11.0s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=335, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  19.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=420, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=  21.8s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=405, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=  21.5s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=55, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=   2.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=55, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=   2.8s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=130, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=   7.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=340, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=  18.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=440, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=  12.5s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=165, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=   8.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=165, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=   8.4s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=465, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=  13.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=495, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=  12.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=315, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  17.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=225, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=   6.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=250, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=  12.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=195, reg_alpha=1.1, reg_lambda=1.1, subsample=0.9; total time=   5.6s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=455, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=  11.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=315, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=   8.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=205, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=   5.8s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=115, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=   2.9s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=115, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=   2.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=385, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=  21.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=475, reg_alpha=1.1, reg_lambda=1.3, subsample=0.7; total time=  24.2s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=330, reg_alpha=1.1, reg_lambda=1.3, subsample=0.7; total time=   8.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=425, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  12.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=110, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=   6.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=150, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   4.2s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=140, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=   3.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=210, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=  10.9s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=425, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  19.6s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=300, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   7.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=195, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=  11.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=335, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=  17.8s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=110, reg_alpha=1.1, reg_lambda=1.2, subsample=0.8; total time=   6.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=405, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=  11.5s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=60, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=   3.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=245, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=  14.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=465, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=  13.5s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=190, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   4.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=455, reg_alpha=1.1, reg_lambda=1.1, subsample=0.9; total time=  22.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=125, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=   7.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=375, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  17.4s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=385, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  10.5s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=395, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=  18.8s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=370, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=   9.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=35, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=   1.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=410, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=  19.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=165, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   4.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=165, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   4.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=125, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=   7.5s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=375, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  17.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=435, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=  20.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=450, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=  11.8s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=300, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=   8.8s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=155, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   4.0s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=400, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=  10.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=40, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=   1.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=170, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=  10.2s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=375, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=   9.2s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=395, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   9.7s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=50, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   1.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=385, reg_alpha=1.1, reg_lambda=1.1, subsample=0.9; total time=  11.1s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=290, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=  14.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=185, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=   5.3s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=175, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   9.0s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=55, reg_alpha=1.1, reg_lambda=1.1, subsample=0.9; total time=   3.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=55, reg_alpha=1.1, reg_lambda=1.1, subsample=0.9; total time=   3.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=475, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  23.9s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=75, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=   2.0s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=75, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=   2.0s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=140, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=   7.2s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=295, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=  16.0s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=140, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   7.0s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=380, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=  10.0s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=180, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   8.9s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=465, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=  12.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=305, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  16.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=80, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=   4.8s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=200, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=  11.2s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=375, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   9.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=90, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=   2.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=235, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=  13.8s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=65, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=   3.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=65, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=   3.9s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=220, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   5.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=380, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=  20.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=450, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=  12.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=20, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   1.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=90, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   2.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=335, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   9.4s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=30, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   0.9s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=55, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=   2.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=235, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=  13.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=185, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=  10.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=140, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=   7.3s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=130, reg_alpha=1.1, reg_lambda=1.2, subsample=0.8; total time=   6.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=145, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   4.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=145, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   4.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=105, reg_alpha=1.3, reg_lambda=1.1, subsample=0.8; total time=   2.7s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=105, reg_alpha=1.3, reg_lambda=1.1, subsample=0.8; total time=   2.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=255, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   7.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=240, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=  14.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=920, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=320, warm_start=False; total time=   2.4s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=420, warm_start=False; total time=   6.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=405, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=  10.5s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=35, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=   1.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=410, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=  18.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=450, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=  20.0s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=430, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=  22.2s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=380, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=  20.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=345, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  17.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=155, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   3.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=390, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=  11.0s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=190, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   5.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=190, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   5.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=100, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=   2.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=400, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=  11.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=170, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=  10.0s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=280, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  15.2s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=265, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   6.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=495, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=  21.8s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=435, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=  12.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=450, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  12.4s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=320, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   8.2s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=450, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=  12.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=445, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=  12.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=305, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=  17.5s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=465, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=  11.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=210, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=  12.0s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=110, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   6.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=245, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   7.0s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=245, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   6.9s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=375, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   9.5s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=385, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=   9.8s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=385, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=   9.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=200, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   5.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=65, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=   1.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=380, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=  20.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=450, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=  12.3s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=20, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   1.1s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=20, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   1.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=90, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   2.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=335, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   9.2s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=30, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   0.9s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=160, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=   8.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=440, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  23.2s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=255, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=   6.5s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=200, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=  11.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=105, reg_alpha=1.3, reg_lambda=1.1, subsample=0.8; total time=   2.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=255, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   7.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=255, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   7.1s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=70, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   3.5s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=920, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=1720, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=1320, warm_start=False; total time=  12.7s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=720, warm_start=False; total time=  15.3s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=720, warm_start=False; total time=  15.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=1020, warm_start=False; total time=  24.4s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=8, n_estimators=1020, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=20, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=20, warm_start=True; total time=   0.0s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=190, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   4.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=455, reg_alpha=1.1, reg_lambda=1.1, subsample=0.9; total time=  23.4s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=265, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=   6.8s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=265, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=   6.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=435, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=  20.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=350, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   8.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=280, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=  15.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=300, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=   8.8s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=155, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   4.0s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=400, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=  10.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=170, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=  10.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=375, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=   9.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=305, reg_alpha=1.3, reg_lambda=1.1, subsample=0.8; total time=   7.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=170, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=  10.0s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=280, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  15.1s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=210, reg_alpha=1.3, reg_lambda=1.1, subsample=0.8; total time=  10.7s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=190, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   4.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=435, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=  20.4s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=435, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=  12.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=450, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  12.5s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=195, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=  11.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=450, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=  12.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=250, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=   7.1s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=180, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   8.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=245, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=  11.9s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=80, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=   4.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=210, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=  12.0s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=110, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   6.5s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=200, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=  11.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=385, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   9.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=90, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=   2.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=235, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=  13.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=240, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   7.0s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=200, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   5.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=370, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=  10.8s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=70, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   3.9s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=130, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   3.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=130, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   3.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=400, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=  11.5s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=105, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   5.8s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=90, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   2.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=105, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=   5.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=130, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   6.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=415, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=  22.1s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=140, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=   7.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=130, reg_alpha=1.1, reg_lambda=1.2, subsample=0.8; total time=   6.6s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=350, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   8.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=445, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  12.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=240, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=  14.1s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=320, warm_start=False; total time=   2.3s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=420, warm_start=False; total time=   6.5s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=420, warm_start=False; total time=   6.2s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=720, warm_start=False; total time=  15.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1220, warm_start=False; total time=  22.7s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1720, warm_start=False; total time=  25.4s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=20, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=420, warm_start=False; total time=   3.5s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=420, warm_start=False; total time=   3.6s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=25, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   0.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=410, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=  11.7s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=405, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=  10.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=370, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=   9.6s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=425, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=  10.6s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=425, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=  10.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=165, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   4.6s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=265, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=   6.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=435, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=  20.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=385, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  10.5s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=280, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=  15.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=300, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=   8.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=375, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=  18.0s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=275, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=  15.4s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=400, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=  11.0s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=50, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   1.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=335, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   9.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=290, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=  14.0s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=265, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   6.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=175, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   9.0s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=435, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=  20.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=460, reg_alpha=1.1, reg_lambda=1.2, subsample=0.8; total time=  13.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=75, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=   2.0s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=95, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=   2.8s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=320, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   8.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=450, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=  12.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=140, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   7.0s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=380, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=   9.9s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=205, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   5.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=205, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   5.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=465, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=  11.8s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=305, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  16.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=330, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  16.8s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=375, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   9.5s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=460, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=  20.7s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=185, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=   4.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=65, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=   2.0s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=380, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=  21.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=450, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=  12.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=105, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   5.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=105, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=   5.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=130, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   6.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=235, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=  13.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=440, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  22.6s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=350, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   8.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=295, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  16.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=240, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=  13.9s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=920, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=1720, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=1720, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=1320, warm_start=False; total time=  12.6s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=1320, warm_start=False; total time=  12.4s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1220, warm_start=False; total time=  22.9s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1220, warm_start=False; total time=  22.8s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1820, warm_start=True; total time=  11.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=720, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=420, warm_start=False; total time=   3.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=420, warm_start=False; total time=   2.9s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=425, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=  10.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=450, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=  20.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=430, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=  22.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=380, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=  20.5s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=450, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=  11.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=375, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=  18.2s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=170, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=  10.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=375, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=   9.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=395, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   9.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=335, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   9.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=280, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  15.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=185, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=   5.2s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=495, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=  21.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=435, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=  12.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=460, reg_alpha=1.1, reg_lambda=1.2, subsample=0.8; total time=  12.9s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=320, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   8.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=195, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=  11.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=75, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   1.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=445, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=  12.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=305, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=  17.4s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=290, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   7.9s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=80, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=   4.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=175, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=  10.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=110, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   6.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=330, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  16.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=110, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   5.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=460, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=  20.7s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=185, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=   4.7s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=220, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   5.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=125, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=   6.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=70, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   3.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=335, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=   9.5s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=35, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   1.0s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=35, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   1.0s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=415, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=  19.2s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=130, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   6.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=160, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=   8.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=440, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  22.6s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=255, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=   6.5s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=350, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   8.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=445, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  12.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=270, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=   6.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=70, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   3.5s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=320, warm_start=False; total time=   2.4s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=1520, warm_start=True; total time=  24.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=1520, warm_start=True; total time=  24.1s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=8, n_estimators=1020, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=8, n_estimators=1020, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1720, warm_start=False; total time=  25.4s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1720, warm_start=False; total time=  25.5s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=1820, warm_start=False; total time=  21.2s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=720, warm_start=False; total time=   4.2s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=720, warm_start=False; total time=   4.2s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=720, warm_start=False; total time=   4.2s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=620, warm_start=False; total time=   9.2s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=120, warm_start=False; total time=   1.1s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=450, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=  20.0s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=430, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=  22.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=380, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=  20.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=345, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  17.2s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=400, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=  10.2s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=40, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=   1.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=40, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=   1.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=275, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=  15.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=400, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=  11.2s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=50, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   1.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=335, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   9.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=290, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=  14.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=265, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   6.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=175, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   9.0s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=435, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=  20.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=460, reg_alpha=1.1, reg_lambda=1.2, subsample=0.8; total time=  13.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=95, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=   2.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=140, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=   7.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=295, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=  16.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=380, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=  10.0s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=250, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=   7.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=205, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   5.2s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=245, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=  12.1s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=80, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=   4.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=210, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=  12.2s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=175, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=  10.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=245, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   7.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=385, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   9.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=110, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   5.8s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=385, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=  10.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=240, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   7.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=185, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=   4.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=65, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=   2.0s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=370, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=  11.0s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=335, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=   9.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=400, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=  11.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=105, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   5.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=335, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   9.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=30, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   0.9s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=55, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=   2.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=415, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=  22.8s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=185, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=  10.8s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=200, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=  11.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=295, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  16.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=70, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   3.5s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1520, warm_start=False; total time= 1.2min
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=720, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=720, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=1820, warm_start=False; total time=  41.2s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=920, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=920, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=920, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1020, warm_start=True; total time=  33.2s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=6, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=6, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=6, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=120, warm_start=False; total time=   3.1s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=300, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=   7.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=185, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   5.2s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=185, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=   9.4s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=170, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   4.7s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=325, reg_alpha=1.3, reg_lambda=1.1, subsample=0.8; total time=   8.2s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=110, reg_alpha=1.1, reg_lambda=1.2, subsample=0.8; total time=   6.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=20, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   1.2s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=350, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   9.5s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=395, reg_alpha=1.3, reg_lambda=1.2, subsample=0.7; total time=  18.2s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=465, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=  13.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=190, reg_alpha=1.2, reg_lambda=1.1, subsample=0.9; total time=   4.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=455, reg_alpha=1.1, reg_lambda=1.1, subsample=0.9; total time=  23.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=125, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=   7.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=375, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  17.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=385, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  10.7s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=350, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   8.8s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=450, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=  11.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=345, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  17.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=390, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=  10.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=275, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=  15.5s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=305, reg_alpha=1.3, reg_lambda=1.1, subsample=0.8; total time=   7.6s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=395, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   9.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=385, reg_alpha=1.1, reg_lambda=1.1, subsample=0.9; total time=  11.0s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=210, reg_alpha=1.3, reg_lambda=1.1, subsample=0.8; total time=  10.6s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=185, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=   5.2s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=190, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   4.7s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=190, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   4.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=55, reg_alpha=1.1, reg_lambda=1.1, subsample=0.9; total time=   3.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=475, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  24.0s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=450, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  12.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=295, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=  16.0s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=445, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=  12.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=305, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=  17.4s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=290, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   7.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=305, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  16.5s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=80, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=   4.8s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=200, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=  11.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=385, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   9.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=90, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=   2.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=235, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=  13.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=240, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   6.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=200, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   5.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=370, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=  10.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=70, reg_alpha=1.1, reg_lambda=1.1, subsample=0.7; total time=   3.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=335, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=   9.3s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=35, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=   1.0s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=415, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=  19.2s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=105, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=   5.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=160, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=   8.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=415, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=  22.2s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=255, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=   6.6s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=200, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=  11.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=445, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  12.2s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=270, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=   6.9s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1520, warm_start=False; total time= 1.2min
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=1820, warm_start=False; total time=  41.2s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1020, warm_start=True; total time=  32.9s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=120, warm_start=False; total time=   1.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=120, warm_start=False; total time=   3.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=4, n_estimators=1220, warm_start=False; total time=  14.9s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=350, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   8.7s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=280, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=  15.2s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=375, reg_alpha=1.2, reg_lambda=1.2, subsample=0.8; total time=  18.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=390, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=  10.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=190, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   5.5s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=100, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=   2.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=100, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=   2.8s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=305, reg_alpha=1.3, reg_lambda=1.1, subsample=0.8; total time=   7.5s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=170, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=  10.1s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=385, reg_alpha=1.1, reg_lambda=1.1, subsample=0.9; total time=  11.1s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=210, reg_alpha=1.3, reg_lambda=1.1, subsample=0.8; total time=  10.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=495, reg_alpha=1.3, reg_lambda=1.2, subsample=0.8; total time=  21.9s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=475, reg_alpha=1.2, reg_lambda=1.1, subsample=0.7; total time=  23.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=95, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=   2.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=140, reg_alpha=1.1, reg_lambda=1.3, subsample=0.8; total time=   7.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=195, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=  11.2s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=75, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   1.9s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=75, reg_alpha=1.2, reg_lambda=1.2, subsample=0.7; total time=   1.9s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=140, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   6.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=250, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=   7.0s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=180, reg_alpha=1.1, reg_lambda=1.2, subsample=0.7; total time=   8.9s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=245, reg_alpha=1.3, reg_lambda=1.1, subsample=0.7; total time=  11.9s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=290, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=   8.0s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=175, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=  10.3s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=80, reg_alpha=1.3, reg_lambda=1.3, subsample=0.9; total time=   4.7s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=330, reg_alpha=1.2, reg_lambda=1.2, subsample=0.9; total time=  16.5s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=110, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   5.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=460, reg_alpha=1.2, reg_lambda=1.3, subsample=0.9; total time=  21.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=65, reg_alpha=1.3, reg_lambda=1.1, subsample=0.9; total time=   3.9s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=220, reg_alpha=1.1, reg_lambda=1.3, subsample=0.9; total time=   5.6s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=125, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=   6.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=125, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=   6.4s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=130, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=   3.3s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=400, reg_alpha=1.3, reg_lambda=1.2, subsample=0.9; total time=  11.5s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=415, reg_alpha=1.2, reg_lambda=1.3, subsample=0.7; total time=  19.0s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=55, reg_alpha=1.1, reg_lambda=1.1, subsample=0.8; total time=   2.8s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=235, reg_alpha=1.3, reg_lambda=1.3, subsample=0.8; total time=  13.4s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=185, reg_alpha=1.2, reg_lambda=1.3, subsample=0.8; total time=  10.8s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=140, reg_alpha=1.1, reg_lambda=1.2, subsample=0.9; total time=   7.4s
[CV] END colsample_bytree=0.7, max_depth=4, n_estimators=130, reg_alpha=1.1, reg_lambda=1.2, subsample=0.8; total time=   6.7s
[CV] END colsample_bytree=0.8, max_depth=2, n_estimators=145, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=   4.1s
[CV] END colsample_bytree=0.8, max_depth=4, n_estimators=295, reg_alpha=1.3, reg_lambda=1.3, subsample=0.7; total time=  16.1s
[CV] END colsample_bytree=0.7, max_depth=2, n_estimators=270, reg_alpha=1.2, reg_lambda=1.1, subsample=0.8; total time=   6.8s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1520, warm_start=False; total time= 1.2min
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=1820, warm_start=False; total time=  41.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1020, warm_start=True; total time=  33.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=220, warm_start=False; total time=   4.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=4, n_estimators=1220, warm_start=False; total time=  14.9s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=120, warm_start=False; total time=   1.3s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1020, warm_start=False; total time=  12.7s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=1020, warm_start=False; total time=   8.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=20, warm_start=False; total time=   0.6s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1220, warm_start=True; total time=  22.9s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=1520, warm_start=True; total time=  24.5s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=1020, warm_start=False; total time=  24.7s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=1020, warm_start=False; total time=  24.7s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=420, warm_start=False; total time=   3.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=120, warm_start=True; total time=   1.2s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=120, warm_start=True; total time=   1.2s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=120, warm_start=True; total time=   1.2s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=1820, warm_start=False; total time=  21.2s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=1820, warm_start=False; total time=  21.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=20, warm_start=True; total time=   0.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=20, warm_start=True; total time=   0.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=20, warm_start=True; total time=   0.2s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=620, warm_start=False; total time=   9.1s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=620, warm_start=False; total time=   9.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=4, n_estimators=1220, warm_start=False; total time=  14.7s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1020, warm_start=False; total time=  15.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=1020, warm_start=False; total time=   8.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=720, warm_start=False; total time=  34.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=720, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1420, warm_start=False; total time=  13.6s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=720, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=720, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=720, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=620, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=620, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=620, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1320, warm_start=True; total time=  36.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1820, warm_start=True; total time=  25.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=8, n_estimators=820, warm_start=True; total time=   6.7s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1720, warm_start=False; total time=  18.4s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=1820, warm_start=True; total time=  23.8s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=520, warm_start=False; total time=  14.1s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=1220, warm_start=True; total time=  33.1s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=120, warm_start=True; total time=   2.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=120, warm_start=True; total time=   2.0s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=120, warm_start=False; total time=   1.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=120, warm_start=False; total time=   3.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=220, warm_start=False; total time=   3.9s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1520, warm_start=True; total time= 1.1min
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=720, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=720, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1420, warm_start=False; total time=  13.6s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=620, warm_start=False; total time=  17.9s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1920, warm_start=True; total time=  38.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=620, warm_start=False; total time=   9.9s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=520, warm_start=False; total time=   7.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=320, warm_start=True; total time=   4.8s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=1020, warm_start=False; total time=  15.2s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1420, warm_start=True; total time=  18.5s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=520, warm_start=False; total time=  14.2s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=920, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=920, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=920, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=20, warm_start=False; total time=   0.6s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=20, warm_start=False; total time=   0.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=1320, warm_start=False; total time=  15.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=4, n_estimators=320, warm_start=False; total time=   3.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=1620, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=1620, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=1620, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=1420, warm_start=False; total time= 1.1min
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=420, warm_start=False; total time=  19.9s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=220, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=220, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=220, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=720, warm_start=True; total time=  20.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1220, warm_start=True; total time=  11.5s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=620, warm_start=True; total time=  18.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1820, warm_start=True; total time=  32.4s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1120, warm_start=True; total time=  34.4s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1520, warm_start=True; total time= 1.1min
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1420, warm_start=False; total time=  13.5s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1320, warm_start=True; total time=  36.4s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1820, warm_start=True; total time=  25.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=8, n_estimators=820, warm_start=True; total time=   6.7s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=320, warm_start=True; total time=   4.8s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1220, warm_start=True; total time=  18.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=1820, warm_start=True; total time=  23.7s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1020, warm_start=True; total time=  14.3s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=820, warm_start=False; total time=   9.8s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=820, warm_start=False; total time=   9.8s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=1420, warm_start=False; total time= 1.1min
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=320, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=320, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=320, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=220, warm_start=False; total time=   1.7s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=220, warm_start=False; total time=   1.7s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=620, warm_start=False; total time=  14.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=720, warm_start=True; total time=  20.8s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=1220, warm_start=True; total time=  22.6s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=1820, warm_start=True; total time=  10.6s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1520, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1520, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1520, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=620, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=620, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=620, warm_start=True; total time=   0.0s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1820, warm_start=True; total time=  10.7s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1820, warm_start=True; total time=  10.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1820, warm_start=True; total time=  32.4s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1120, warm_start=True; total time=  34.2s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1020, warm_start=True; total time=   5.9s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1020, warm_start=True; total time=   5.9s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=120, warm_start=False; total time=   1.3s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=120, warm_start=False; total time=   1.3s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1020, warm_start=False; total time=  12.6s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=20, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=20, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=20, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=720, warm_start=False; total time=  34.2s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=920, warm_start=False; total time=   8.7s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=1020, warm_start=True; total time=  15.3s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1220, warm_start=True; total time=  24.3s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=4, n_estimators=820, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=4, n_estimators=820, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=4, n_estimators=820, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=420, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=420, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1820, warm_start=True; total time=  25.5s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=620, warm_start=True; total time=  20.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1220, warm_start=True; total time=  18.1s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1420, warm_start=True; total time=  18.7s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=520, warm_start=False; total time=  14.1s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=1220, warm_start=True; total time=  33.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=120, warm_start=True; total time=   2.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=1120, warm_start=True; total time=  23.4s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=1720, warm_start=True; total time=  49.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=720, warm_start=True; total time=  20.7s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=620, warm_start=True; total time=  19.2s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=1820, warm_start=True; total time=  10.5s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=520, warm_start=False; total time=   9.7s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=420, warm_start=False; total time=  12.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=420, warm_start=False; total time=   2.9s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1820, warm_start=True; total time=  32.5s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1120, warm_start=True; total time=  34.5s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1020, warm_start=True; total time=   6.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=720, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=720, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=720, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1020, warm_start=False; total time=  15.3s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1020, warm_start=False; total time=  12.6s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=720, warm_start=False; total time=  34.8s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=1020, warm_start=True; total time=  15.4s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1320, warm_start=True; total time=  36.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=620, warm_start=True; total time=  20.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=1620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=1620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=1620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=20, warm_start=True; total time=   0.5s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=20, warm_start=True; total time=   0.5s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=20, warm_start=True; total time=   0.5s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=8, n_estimators=820, warm_start=True; total time=   6.8s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1720, warm_start=False; total time=  18.5s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=1820, warm_start=True; total time=  23.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1720, warm_start=False; total time=  21.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=820, warm_start=False; total time=  10.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=4, n_estimators=320, warm_start=False; total time=   3.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=920, warm_start=False; total time=  19.6s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=220, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=220, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=220, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=1720, warm_start=True; total time=  49.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=220, warm_start=False; total time=   1.7s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1920, warm_start=True; total time=  11.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1920, warm_start=False; total time= 1.0min
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=520, warm_start=False; total time=   6.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=420, warm_start=False; total time=  12.1s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=220, warm_start=False; total time=   4.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1520, warm_start=True; total time= 1.2min
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=1020, warm_start=True; total time=  15.5s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1220, warm_start=True; total time=  24.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1920, warm_start=True; total time=  39.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=520, warm_start=False; total time=   7.1s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1220, warm_start=True; total time=  18.4s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1420, warm_start=True; total time=  19.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1020, warm_start=True; total time=  14.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=20, warm_start=False; total time=   0.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=1320, warm_start=False; total time=  15.6s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=4, n_estimators=320, warm_start=False; total time=   3.1s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=920, warm_start=False; total time=  19.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=1720, warm_start=True; total time=  50.2s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1920, warm_start=True; total time=  11.5s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1920, warm_start=False; total time= 1.0min
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1020, warm_start=False; total time=  16.2s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=820, warm_start=True; total time=  16.4s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1120, warm_start=False; total time=  13.3s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=1920, warm_start=False; total time=  46.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=6, n_estimators=320, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=6, n_estimators=320, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=6, n_estimators=320, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1820, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1820, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1820, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=320, warm_start=True; total time=   3.8s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=320, warm_start=True; total time=   3.8s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=1820, warm_start=True; total time=  37.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=720, warm_start=True; total time=  23.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=1320, warm_start=True; total time=  22.6s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=420, warm_start=False; total time=   4.1s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1620, warm_start=False; total time=  25.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=120, warm_start=True; total time=   1.3s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=1220, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=1220, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=1220, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=620, warm_start=True; total time=   0.0s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1020, warm_start=False; total time=  15.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=1020, warm_start=False; total time=   8.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=20, warm_start=False; total time=   0.6s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=20, warm_start=False; total time=   0.6s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1220, warm_start=True; total time=  23.1s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=120, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=120, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=120, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=920, warm_start=False; total time=   8.8s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=920, warm_start=False; total time=   8.7s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=620, warm_start=False; total time=  17.8s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1220, warm_start=True; total time=  24.4s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=620, warm_start=True; total time=  20.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=620, warm_start=False; total time=  10.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1720, warm_start=False; total time=  18.5s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=1020, warm_start=False; total time=  15.5s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1720, warm_start=False; total time=  21.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=1220, warm_start=True; total time=  33.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=1420, warm_start=False; total time= 1.1min
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=620, warm_start=False; total time=  14.8s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=120, warm_start=True; total time=   2.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=120, warm_start=True; total time=   2.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=120, warm_start=True; total time=   2.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1220, warm_start=True; total time=  11.6s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=1220, warm_start=True; total time=  22.9s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=1820, warm_start=True; total time=  10.6s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=520, warm_start=False; total time=   9.8s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1620, warm_start=False; total time=  40.8s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=1920, warm_start=False; total time=  46.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=320, warm_start=True; total time=   3.8s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=620, warm_start=False; total time=  28.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=820, warm_start=True; total time=  24.2s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=1320, warm_start=True; total time=  22.5s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=1720, warm_start=False; total time=  38.8s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1620, warm_start=False; total time=  24.4s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=220, warm_start=False; total time=   3.3s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1220, warm_start=True; total time=  22.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=620, warm_start=False; total time=  17.8s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1920, warm_start=True; total time=  38.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=620, warm_start=False; total time=   9.9s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=320, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=320, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=320, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=520, warm_start=False; total time=   6.9s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=320, warm_start=True; total time=   4.9s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1720, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1720, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1720, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=420, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=1020, warm_start=False; total time=  15.2s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=920, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=920, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=920, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1720, warm_start=False; total time=  21.5s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1020, warm_start=True; total time=  14.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=1320, warm_start=False; total time=  15.4s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=920, warm_start=False; total time=  19.2s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=1120, warm_start=True; total time=  23.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=4, n_estimators=420, warm_start=True; total time=   9.3s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=420, warm_start=False; total time=  20.4s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1920, warm_start=True; total time=  11.2s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1920, warm_start=False; total time= 1.0min
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=520, warm_start=False; total time=   6.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1620, warm_start=False; total time=  41.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1320, warm_start=True; total time=  19.6s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=1820, warm_start=False; total time=  40.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=920, warm_start=True; total time=   8.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=920, warm_start=True; total time=   8.8s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=8, n_estimators=1620, warm_start=False; total time=   9.5s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=720, warm_start=False; total time=  12.2s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1320, warm_start=True; total time=  32.4s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=1720, warm_start=False; total time=  38.6s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=1820, warm_start=False; total time=  50.5s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=1120, warm_start=True; total time=  23.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=4, n_estimators=420, warm_start=True; total time=   9.3s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=4, n_estimators=420, warm_start=True; total time=   9.4s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=420, warm_start=False; total time=  20.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=620, warm_start=False; total time=  14.7s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1220, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1220, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1220, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1220, warm_start=True; total time=  11.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=1220, warm_start=True; total time=  22.7s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=620, warm_start=True; total time=  18.9s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1020, warm_start=False; total time=  16.1s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=120, warm_start=True; total time=   2.9s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1120, warm_start=False; total time=  13.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1520, warm_start=False; total time=  18.4s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=120, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=120, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=120, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=120, warm_start=False; total time=   1.3s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=120, warm_start=False; total time=   1.3s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=120, warm_start=False; total time=   1.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=1820, warm_start=False; total time=  40.3s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=1820, warm_start=True; total time=  36.2s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=8, n_estimators=1620, warm_start=False; total time=   9.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=720, warm_start=True; total time=  23.6s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=920, warm_start=True; total time=  15.5s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1620, warm_start=False; total time=  32.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=320, warm_start=True; total time=   2.2s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=1820, warm_start=False; total time=  50.6s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1320, warm_start=True; total time=  14.5s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=420, warm_start=True; total time=   6.4s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=620, warm_start=False; total time=  18.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=1620, warm_start=True; total time=  25.8s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=120, warm_start=True; total time=   1.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=820, warm_start=False; total time=  19.8s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1420, warm_start=False; total time=  43.9s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1120, warm_start=False; total time=  12.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1120, warm_start=False; total time=  11.9s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=520, warm_start=False; total time=   6.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=420, warm_start=False; total time=  12.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1620, warm_start=False; total time=  41.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=1820, warm_start=False; total time=  40.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1120, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1120, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1120, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=6, n_estimators=1620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=6, n_estimators=1620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=6, n_estimators=1620, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=20, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=20, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=20, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=620, warm_start=False; total time=  28.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=820, warm_start=True; total time=  24.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=720, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=720, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=720, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=1320, warm_start=True; total time=  22.6s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=920, warm_start=True; total time=  15.6s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1620, warm_start=False; total time=  24.3s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=120, warm_start=True; total time=   1.3s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=120, warm_start=True; total time=   1.3s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=320, warm_start=True; total time=   2.2s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=1520, warm_start=False; total time=  11.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=1820, warm_start=False; total time=  32.4s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1520, warm_start=True; total time=  22.6s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1520, warm_start=True; total time=  21.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=1220, warm_start=False; total time=  18.2s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=220, warm_start=False; total time=   5.4s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=1920, warm_start=True; total time=  14.4s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1420, warm_start=True; total time=   8.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1420, warm_start=False; total time=  43.5s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1120, warm_start=True; total time=  35.4s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1020, warm_start=True; total time=  17.1s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=720, warm_start=True; total time=  22.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=520, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=520, warm_start=False; total time=   0.0s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=820, warm_start=True; total time=  16.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1520, warm_start=False; total time=  18.4s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1320, warm_start=True; total time=  19.5s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1620, warm_start=True; total time=  26.9s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=620, warm_start=False; total time=  27.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=220, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=220, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=220, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=8, n_estimators=1620, warm_start=False; total time=   9.5s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=720, warm_start=False; total time=  12.6s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1320, warm_start=True; total time=  32.4s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=1720, warm_start=False; total time=  39.1s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1220, warm_start=False; total time=   7.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1220, warm_start=False; total time=   7.4s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=1820, warm_start=False; total time=  32.6s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=6, n_estimators=320, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=6, n_estimators=320, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=6, n_estimators=320, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=8, n_estimators=1520, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=8, n_estimators=1520, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=8, n_estimators=1520, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1320, warm_start=True; total time=  14.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=1920, warm_start=False; total time=  23.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=1620, warm_start=True; total time=  25.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=620, warm_start=True; total time=  11.7s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=1220, warm_start=True; total time=  14.4s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=1820, warm_start=True; total time=  17.4s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=1020, warm_start=True; total time=  18.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1120, warm_start=True; total time=  35.9s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1420, warm_start=False; total time=  31.7s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=8, n_estimators=1920, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=8, n_estimators=1920, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=8, n_estimators=1920, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=620, warm_start=True; total time=  11.6s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=620, warm_start=False; total time=   5.9s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1820, warm_start=True; total time=  40.6s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=920, warm_start=True; total time=  13.6s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1320, warm_start=False; total time=  12.7s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=920, warm_start=True; total time=  17.5s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1920, warm_start=True; total time=  16.4s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=20, warm_start=True; total time=   0.0s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=620, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=620, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=320, warm_start=True; total time=   2.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=120, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=120, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=120, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=120, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=120, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=120, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=1520, warm_start=False; total time=  11.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1220, warm_start=False; total time=   7.3s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=220, warm_start=False; total time=   3.3s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=220, warm_start=False; total time=   3.4s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1220, warm_start=False; total time=  17.4s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1520, warm_start=True; total time=  22.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=420, warm_start=True; total time=   6.5s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=620, warm_start=False; total time=  19.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=1620, warm_start=True; total time=  26.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=120, warm_start=True; total time=   1.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=120, warm_start=True; total time=   1.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=820, warm_start=False; total time=  20.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=1820, warm_start=True; total time=  17.7s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=1020, warm_start=True; total time=  18.4s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=1020, warm_start=True; total time=  18.5s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1120, warm_start=False; total time=  12.3s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1420, warm_start=False; total time=  32.5s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=620, warm_start=True; total time=   4.4s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=620, warm_start=True; total time=  11.9s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=620, warm_start=False; total time=   6.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1820, warm_start=True; total time=  41.2s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=920, warm_start=True; total time=  13.9s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1320, warm_start=False; total time=  12.8s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=920, warm_start=True; total time=  17.7s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=1420, warm_start=True; total time=  20.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1020, warm_start=True; total time=   8.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1620, warm_start=True; total time=  36.5s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=320, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=320, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=320, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=620, warm_start=False; total time=   0.0s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=520, warm_start=False; total time=  10.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1020, warm_start=False; total time=  16.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=120, warm_start=True; total time=   2.9s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=120, warm_start=True; total time=   2.9s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1120, warm_start=False; total time=  13.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=1920, warm_start=False; total time=  45.6s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1620, warm_start=True; total time=  27.2s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=920, warm_start=True; total time=   8.8s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=820, warm_start=True; total time=  23.8s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=720, warm_start=True; total time=  23.2s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=920, warm_start=True; total time=  15.4s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=420, warm_start=False; total time=   4.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1620, warm_start=False; total time=  32.6s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=1820, warm_start=False; total time=  50.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1320, warm_start=True; total time=  14.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=1220, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=1220, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=1220, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=420, warm_start=True; total time=   6.4s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1520, warm_start=True; total time=  21.3s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1020, warm_start=True; total time=   9.9s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=220, warm_start=False; total time=   5.3s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=1920, warm_start=True; total time=  14.3s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=820, warm_start=False; total time=  19.7s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1820, warm_start=True; total time= 1.4min
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1020, warm_start=True; total time=  17.1s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1120, warm_start=True; total time=  21.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1820, warm_start=True; total time=  41.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=520, warm_start=True; total time=   3.7s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1420, warm_start=True; total time=  21.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=420, warm_start=False; total time=  12.2s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1920, warm_start=True; total time=  20.5s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1020, warm_start=True; total time=   8.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=120, warm_start=True; total time=   5.7s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=1320, warm_start=True; total time=  10.6s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=1820, warm_start=False; total time=  45.7s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=1220, warm_start=True; total time=  14.9s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=520, warm_start=False; total time=   9.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=1220, warm_start=False; total time=  31.2s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1820, warm_start=True; total time=  38.0s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1220, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1220, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1220, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=1920, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=1920, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=1920, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1220, warm_start=False; total time=  17.5s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1220, warm_start=False; total time=  17.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=120, warm_start=False; total time=   3.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=1920, warm_start=False; total time=  23.5s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=1220, warm_start=False; total time=  18.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1020, warm_start=True; total time=  10.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=620, warm_start=True; total time=  11.8s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=1220, warm_start=True; total time=  14.5s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=1820, warm_start=True; total time=  17.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1820, warm_start=True; total time= 1.5min
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=620, warm_start=True; total time=  11.9s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=620, warm_start=False; total time=  19.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1820, warm_start=False; total time=  59.4s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1920, warm_start=True; total time=  20.9s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=1420, warm_start=True; total time=  19.9s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1620, warm_start=True; total time=  36.9s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1820, warm_start=False; total time=  21.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=1220, warm_start=True; total time=  15.1s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=620, warm_start=True; total time=   9.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=1220, warm_start=False; total time=  31.1s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1820, warm_start=True; total time=  38.4s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=320, warm_start=True; total time=   5.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=1120, warm_start=True; total time=  17.8s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=720, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=720, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=720, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1820, warm_start=True; total time=  27.3s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=4, n_estimators=1820, warm_start=False; total time=  23.8s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=820, warm_start=False; total time=  12.2s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=1920, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=1920, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=1920, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=120, warm_start=False; total time=   3.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=120, warm_start=False; total time=   3.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=1920, warm_start=False; total time=  23.7s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=620, warm_start=False; total time=  18.9s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1020, warm_start=True; total time=  10.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=1920, warm_start=True; total time=  14.4s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1420, warm_start=True; total time=   8.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1420, warm_start=True; total time=   8.4s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1820, warm_start=True; total time= 1.4min
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=720, warm_start=True; total time=  22.2s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1120, warm_start=True; total time=  21.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1820, warm_start=False; total time=  58.4s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=920, warm_start=True; total time=  17.6s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=1420, warm_start=True; total time=  19.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=8, n_estimators=920, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=8, n_estimators=920, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=8, n_estimators=920, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=120, warm_start=True; total time=   5.7s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=8, n_estimators=220, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=8, n_estimators=220, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=8, n_estimators=220, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1620, warm_start=True; total time=  36.4s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=1820, warm_start=False; total time=  45.9s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1820, warm_start=False; total time=  34.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1120, warm_start=False; total time=  17.5s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1120, warm_start=False; total time=  17.4s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=1620, warm_start=True; total time= 1.2min
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1520, warm_start=True; total time=  12.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=320, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=320, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=320, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1320, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1320, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1320, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1020, warm_start=True; total time=   9.7s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=520, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=920, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=920, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=920, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=620, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=620, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=620, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=620, warm_start=False; total time=   6.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=620, warm_start=False; total time=  19.6s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1320, warm_start=False; total time=  15.2s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=920, warm_start=True; total time=  13.7s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=520, warm_start=True; total time=   3.6s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1420, warm_start=True; total time=  21.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=420, warm_start=False; total time=  12.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1920, warm_start=True; total time=  16.4s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=1420, warm_start=False; total time=  23.8s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=1420, warm_start=False; total time=  43.1s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1820, warm_start=False; total time=  21.1s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=620, warm_start=True; total time=   9.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=1220, warm_start=False; total time=  30.8s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1820, warm_start=True; total time=  38.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=320, warm_start=True; total time=   5.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=20, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=20, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=20, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=1120, warm_start=True; total time=  17.7s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=1720, warm_start=True; total time=  53.8s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=820, warm_start=False; total time=  12.2s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=1820, warm_start=False; total time=  12.6s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=120, warm_start=True; total time=   1.2s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=120, warm_start=True; total time=   1.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=1620, warm_start=True; total time=  36.4s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=120, warm_start=True; total time=   3.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=120, warm_start=True; total time=   3.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=120, warm_start=True; total time=   3.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=420, warm_start=False; total time=   4.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=220, warm_start=False; total time=   1.7s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=6, n_estimators=1220, warm_start=False; total time=   0.0s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=20, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=20, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1020, warm_start=True; total time=   8.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=120, warm_start=True; total time=   5.8s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=4, n_estimators=1220, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=4, n_estimators=1220, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=4, n_estimators=1220, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1620, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1620, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1620, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=1320, warm_start=True; total time=  10.5s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=1420, warm_start=False; total time=  43.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=520, warm_start=False; total time=   7.2s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=1220, warm_start=False; total time=  10.5s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=920, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=920, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=920, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=4, n_estimators=1720, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=4, n_estimators=1720, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=4, n_estimators=1720, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=1620, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=1620, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=1620, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=620, warm_start=True; total time=   9.1s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1820, warm_start=False; total time=  34.3s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1120, warm_start=False; total time=  17.5s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=1620, warm_start=True; total time= 1.2min
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=4, n_estimators=1820, warm_start=False; total time=  23.7s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=820, warm_start=False; total time=  12.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=1820, warm_start=False; total time=  12.6s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=120, warm_start=True; total time=   1.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=1620, warm_start=True; total time=  36.3s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=1920, warm_start=False; total time=  28.8s
[CV] END activation=relu, alpha=0.002075525175169418, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0001146578777894657, solver=adam; total time=  16.5s
[CV] END activation=relu, alpha=0.022134217239908344, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0011209419502813012, solver=lbfgs; total time=   3.3s
[CV] END activation=relu, alpha=0.022134217239908344, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0011209419502813012, solver=lbfgs; total time=   2.9s
[CV] END activation=relu, alpha=0.0086783403968907, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.003910391751237239, solver=adam; total time=  15.2s
[CV] END activation=tanh, alpha=0.008285763240229227, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0008934649001416108, solver=lbfgs; total time=  12.6s
[CV] END activation=tanh, alpha=0.011801672336104206, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0005443060666769468, solver=lbfgs; total time=   5.0s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=820, warm_start=True; total time=  16.9s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1520, warm_start=False; total time=  18.4s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1320, warm_start=True; total time=  19.6s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=1620, warm_start=True; total time=  27.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=1820, warm_start=True; total time=  36.2s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=720, warm_start=False; total time=  12.2s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1320, warm_start=True; total time=  32.7s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=420, warm_start=False; total time=   4.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1620, warm_start=False; total time=  32.4s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=1520, warm_start=False; total time=  11.5s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=1820, warm_start=False; total time=  32.6s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1520, warm_start=True; total time=  22.4s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1520, warm_start=True; total time=  21.1s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=1220, warm_start=False; total time=  18.4s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=220, warm_start=False; total time=   5.4s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=620, warm_start=True; total time=  11.8s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=1220, warm_start=True; total time=  14.4s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1420, warm_start=False; total time=  43.7s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1120, warm_start=True; total time=  35.7s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1020, warm_start=True; total time=  17.1s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=720, warm_start=True; total time=  22.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=620, warm_start=False; total time=  19.5s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1320, warm_start=False; total time=  15.4s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1320, warm_start=False; total time=  15.2s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=520, warm_start=True; total time=   3.6s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1420, warm_start=True; total time=  21.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=420, warm_start=False; total time=  12.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1920, warm_start=True; total time=  16.6s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=1420, warm_start=False; total time=  23.9s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=1420, warm_start=False; total time=  43.6s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=520, warm_start=False; total time=   7.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=1220, warm_start=True; total time=  15.2s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=520, warm_start=False; total time=   9.3s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1520, warm_start=True; total time=  13.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=1020, warm_start=False; total time=  48.2s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=1620, warm_start=True; total time= 1.2min
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=220, warm_start=True; total time=   3.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1520, warm_start=True; total time=  12.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=720, warm_start=False; total time=   8.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=1520, warm_start=False; total time=  28.4s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=1920, warm_start=True; total time= 1.0min
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1820, warm_start=False; total time=  21.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=520, warm_start=False; total time=   7.6s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=1220, warm_start=False; total time=  10.5s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1820, warm_start=False; total time=  34.8s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=1020, warm_start=False; total time=  48.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=1720, warm_start=True; total time=  55.3s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=1920, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=1920, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=1920, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=20, warm_start=False; total time=   0.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=20, warm_start=False; total time=   0.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=20, warm_start=False; total time=   0.4s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=220, warm_start=True; total time=   3.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=220, warm_start=True; total time=   3.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1520, warm_start=True; total time=  12.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=720, warm_start=False; total time=   8.9s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=6, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=6, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=6, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=1520, warm_start=False; total time=  28.9s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=1620, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=1620, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=1620, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=1920, warm_start=False; total time=  28.9s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=420, warm_start=False; total time=   4.1s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1220, warm_start=False; total time=   9.2s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=320, warm_start=False; total time=   7.6s
[CV] END activation=relu, alpha=0.0008233391333156122, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0009617786011786374, solver=sgd; total time=  15.8s
[CV] END activation=tanh, alpha=0.004961825274863458, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=9.9878841113572e-05, solver=adam; total time=  20.2s
[CV] END activation=tanh, alpha=0.0009047547290952491, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0012431777364156544, solver=lbfgs; total time=   3.2s
[CV] END activation=tanh, alpha=0.008285763240229227, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0008934649001416108, solver=lbfgs; total time=  11.1s
[CV] END activation=tanh, alpha=0.03271167847947162, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=7.536165898692318e-05, solver=lbfgs; total time=  22.6s
[CV] END activation=relu, alpha=0.017613741020518686, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.00043450866394032937, solver=adam; total time=  18.0s
[CV] END activation=tanh, alpha=0.022112651421771292, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=5.470154377822502e-05, solver=sgd; total time= 2.1min
[CV] END activation=tanh, alpha=0.006822437220692069, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0003655888513705942, solver=sgd; total time=  41.5s
[CV] END activation=tanh, alpha=0.01522510654076898, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0016681162438721957, solver=sgd; total time= 2.4min
[CV] END activation=tanh, alpha=0.01905713632581814, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0003076038869931741, solver=lbfgs; total time=  20.4s
[CV] END activation=relu, alpha=0.015024550677117178, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=5.0563072883905715e-05, solver=adam; total time= 1.2min
[CV] END activation=relu, alpha=0.015076867017041537, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0011089659087447463, solver=adam; total time=  20.7s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1420, warm_start=False; total time=  31.5s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=620, warm_start=True; total time=   4.3s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=620, warm_start=True; total time=   4.3s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1120, warm_start=True; total time=  21.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=1820, warm_start=False; total time=  58.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=4, n_estimators=1320, warm_start=False; total time=  13.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1920, warm_start=True; total time=  20.6s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=1420, warm_start=False; total time=  24.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=1320, warm_start=True; total time=  10.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=1820, warm_start=False; total time=  45.9s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=1220, warm_start=False; total time=  10.4s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=520, warm_start=False; total time=   9.3s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1520, warm_start=True; total time=  13.2s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1520, warm_start=True; total time=  13.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=1020, warm_start=False; total time=  48.2s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=1720, warm_start=True; total time=  54.1s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=4, n_estimators=1820, warm_start=False; total time=  23.9s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1020, warm_start=True; total time=   9.8s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1420, warm_start=True; total time=  19.9s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=1620, warm_start=True; total time=  36.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=220, warm_start=False; total time=   1.7s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=220, warm_start=False; total time=   1.7s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1220, warm_start=False; total time=   9.0s
[CV] END activation=relu, alpha=0.002075525175169418, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0001146578777894657, solver=adam; total time=  14.9s
[CV] END activation=tanh, alpha=0.0005970647070236323, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0004393500253283666, solver=sgd; total time= 3.2min
[CV] END activation=tanh, alpha=0.0004350469238413108, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0001974619862719662, solver=lbfgs; total time=  10.5s
[CV] END activation=relu, alpha=0.015435469314775598, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0003557641348576518, solver=adam; total time=  10.6s
[CV] END activation=relu, alpha=0.020211490288053288, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0018107596016739649, solver=sgd; total time= 2.0min
[CV] END activation=tanh, alpha=0.023317209321110872, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0007896211858382457, solver=sgd; total time=  41.5s
[CV] END activation=tanh, alpha=0.01905713632581814, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0003076038869931741, solver=lbfgs; total time=  19.2s
[CV] END activation=tanh, alpha=0.0004980715609349804, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.004689673148973987, solver=lbfgs; total time=   4.6s
[CV] END activation=relu, alpha=0.0022203338800437077, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.00021323610574975382, solver=sgd; total time=  16.4s
[CV] END activation=tanh, alpha=0.01706975085135707, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0018350986859731633, solver=adam; total time=   2.7s
[CV] END activation=tanh, alpha=0.01706975085135707, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0018350986859731633, solver=adam; total time=   3.0s
[CV] END activation=relu, alpha=0.046592512602266434, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.000253834084185533, solver=sgd; total time= 3.1min
[CV] END activation=relu, alpha=0.0012775213837489733, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0004767842126388066, solver=sgd; total time= 1.9min
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=6, n_estimators=1220, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=6, n_estimators=1220, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=320, warm_start=False; total time=   7.7s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=320, warm_start=False; total time=   7.5s
[CV] END activation=relu, alpha=0.0008233391333156122, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0009617786011786374, solver=sgd; total time=  15.7s
[CV] END activation=tanh, alpha=0.004961825274863458, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=9.9878841113572e-05, solver=adam; total time=  20.2s
[CV] END activation=tanh, alpha=0.0009047547290952491, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0012431777364156544, solver=lbfgs; total time=   3.1s
[CV] END activation=tanh, alpha=0.008285763240229227, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0008934649001416108, solver=lbfgs; total time=  11.2s
[CV] END activation=tanh, alpha=0.03271167847947162, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=7.536165898692318e-05, solver=lbfgs; total time=  25.7s
[CV] END activation=relu, alpha=0.017613741020518686, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.00043450866394032937, solver=adam; total time=  17.3s
[CV] END activation=tanh, alpha=0.021501859432782072, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0005694637318553642, solver=lbfgs; total time=  19.9s
[CV] END activation=tanh, alpha=0.021501859432782072, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0005694637318553642, solver=lbfgs; total time=  19.9s
[CV] END activation=relu, alpha=0.010577481151427308, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0005862326413765109, solver=lbfgs; total time=  19.1s
[CV] END activation=tanh, alpha=0.013729327978472887, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0003872881056711532, solver=lbfgs; total time=   5.3s
[CV] END activation=tanh, alpha=0.013729327978472887, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0003872881056711532, solver=lbfgs; total time=   4.3s
[CV] END activation=tanh, alpha=0.013729327978472887, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0003872881056711532, solver=lbfgs; total time=   2.9s
[CV] END activation=tanh, alpha=0.012757990283794434, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0031882559307257587, solver=sgd; total time= 1.3min
[CV] END activation=relu, alpha=0.020211490288053288, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0018107596016739649, solver=sgd; total time= 2.2min
[CV] END activation=relu, alpha=0.002025567874020686, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.002590262624333099, solver=adam; total time=  21.7s
[CV] END activation=tanh, alpha=0.01905713632581814, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0003076038869931741, solver=lbfgs; total time=  21.4s
[CV] END activation=relu, alpha=0.015024550677117178, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=5.0563072883905715e-05, solver=adam; total time= 1.3min
[CV] END activation=relu, alpha=0.046592512602266434, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.000253834084185533, solver=sgd; total time= 3.0min
[CV] END activation=tanh, alpha=0.009052741516855579, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0011758376683753931, solver=lbfgs; total time=   3.6s
[CV] END activation=tanh, alpha=0.009052741516855579, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0011758376683753931, solver=lbfgs; total time=   3.7s
[CV] END activation=tanh, alpha=0.004885074233032532, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0006734867951207869, solver=sgd; total time=  41.4s
[CV] END activation=relu, alpha=0.005100294666934283, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.002339160796464639, solver=lbfgs; total time=  10.1s
[CV] END activation=tanh, alpha=0.025696220062070865, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.002330502078781765, solver=adam; total time=   2.5s
[CV] END activation=tanh, alpha=0.0015524358028988227, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0006978629040964538, solver=lbfgs; total time=  19.9s
[CV] END activation=relu, alpha=0.01137699830903779, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0009299739736360966, solver=adam; total time=   9.0s
[CV] END activation=relu, alpha=0.01137699830903779, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0009299739736360966, solver=adam; total time=  10.2s
[CV] END activation=relu, alpha=0.01557638335003179, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0021487494827681125, solver=adam; total time=   2.4s
[CV] END activation=tanh, alpha=0.0003032183386859539, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0015768657560180904, solver=adam; total time=  14.1s
[CV] END activation=relu, alpha=0.004256590494919544, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00010228631316585768, solver=adam; total time=  16.9s
[CV] END activation=relu, alpha=0.004790270185041674, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0017452765065740685, solver=sgd; total time=  38.5s
[CV] END activation=relu, alpha=0.008754002449704996, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0005642043316975841, solver=adam; total time=  12.2s
[CV] END activation=relu, alpha=0.008754002449704996, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0005642043316975841, solver=adam; total time=  13.0s
[CV] END activation=tanh, alpha=0.008530098332571795, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.000297300912899126, solver=lbfgs; total time=   4.6s
[CV] END activation=tanh, alpha=0.0014099409612413295, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0008307430950140481, solver=sgd; total time=  19.0s
[CV] END activation=tanh, alpha=0.010745375851566086, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.001652918249800711, solver=adam; total time=   9.6s
[CV] END activation=relu, alpha=0.018882340912264747, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=4.1706015049635146e-05, solver=sgd; total time=  16.5s
[CV] END activation=tanh, alpha=0.006888053876286935, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0014208356194821722, solver=adam; total time=   3.6s
[CV] END activation=tanh, alpha=0.0025459721042527697, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0004133817218329473, solver=adam; total time=  15.2s
[CV] END activation=relu, alpha=0.0033209789053893573, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0006282417371991485, solver=sgd; total time= 1.9min
[CV] END activation=relu, alpha=0.001476224915031703, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0002846810133188014, solver=lbfgs; total time=  11.9s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=320, warm_start=True; total time=   5.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=1120, warm_start=True; total time=  17.6s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1820, warm_start=True; total time=  26.7s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1820, warm_start=True; total time=  27.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=1420, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=1420, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=1420, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=4, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=4, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=4, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=720, warm_start=False; total time=   8.8s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1020, warm_start=True; total time=   9.9s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1420, warm_start=True; total time=  20.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=1920, warm_start=True; total time= 1.0min
[CV] END activation=relu, alpha=0.0008233391333156122, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0009617786011786374, solver=sgd; total time=  15.8s
[CV] END activation=tanh, alpha=0.004961825274863458, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=9.9878841113572e-05, solver=adam; total time=  20.6s
[CV] END activation=tanh, alpha=0.0009047547290952491, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0012431777364156544, solver=lbfgs; total time=   2.9s
[CV] END activation=tanh, alpha=0.03271167847947162, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=7.536165898692318e-05, solver=lbfgs; total time=  18.5s
[CV] END activation=tanh, alpha=0.0017156828265544332, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.001020529459982444, solver=lbfgs; total time=  23.3s
[CV] END activation=tanh, alpha=0.022112651421771292, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=5.470154377822502e-05, solver=sgd; total time= 2.1min
[CV] END activation=relu, alpha=0.013123929257878928, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0005556739093215221, solver=adam; total time=   7.2s
[CV] END activation=tanh, alpha=0.006822437220692069, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0003655888513705942, solver=sgd; total time=  41.5s
[CV] END activation=tanh, alpha=0.01522510654076898, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0016681162438721957, solver=sgd; total time= 2.5min
[CV] END activation=tanh, alpha=0.0004980715609349804, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.004689673148973987, solver=lbfgs; total time=   4.4s
[CV] END activation=tanh, alpha=0.0004980715609349804, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.004689673148973987, solver=lbfgs; total time=   4.4s
[CV] END activation=relu, alpha=0.0022203338800437077, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.00021323610574975382, solver=sgd; total time=  16.5s
[CV] END activation=tanh, alpha=0.01706975085135707, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0018350986859731633, solver=adam; total time=   5.2s
[CV] END activation=relu, alpha=0.046592512602266434, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.000253834084185533, solver=sgd; total time= 3.0min
[CV] END activation=tanh, alpha=0.002409083208842631, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.004527848431280144, solver=sgd; total time=  36.0s
[CV] END activation=relu, alpha=0.0014056568932398197, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0006441541392987803, solver=adam; total time=  16.4s
[CV] END activation=relu, alpha=0.0014056568932398197, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0006441541392987803, solver=adam; total time=  15.3s
[CV] END activation=tanh, alpha=0.004885074233032532, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0006734867951207869, solver=sgd; total time=  42.9s
[CV] END activation=relu, alpha=0.005100294666934283, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.002339160796464639, solver=lbfgs; total time=   2.6s
[CV] END activation=relu, alpha=0.005100294666934283, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.002339160796464639, solver=lbfgs; total time=   3.2s
[CV] END activation=tanh, alpha=0.025696220062070865, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.002330502078781765, solver=adam; total time=   3.0s
[CV] END activation=tanh, alpha=0.0015524358028988227, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0006978629040964538, solver=lbfgs; total time=  21.3s
[CV] END activation=tanh, alpha=0.008458103391255481, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0018033939926601445, solver=sgd; total time=  42.4s
[CV] END activation=relu, alpha=0.0016475771270150147, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0005829716649993588, solver=sgd; total time= 3.0min
[CV] END activation=tanh, alpha=0.0006051130040693857, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0013232752191340979, solver=sgd; total time=  42.0s
[CV] END activation=tanh, alpha=0.06641479537712633, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0013296366774833378, solver=sgd; total time= 1.8min
[CV] END activation=tanh, alpha=0.034601982675292325, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0019246610969967711, solver=adam; total time=  15.5s
[CV] END activation=tanh, alpha=0.034601982675292325, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0019246610969967711, solver=adam; total time=  10.8s
[CV] END activation=relu, alpha=0.00521583766298311, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0006069704291210512, solver=adam; total time=  15.1s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=1820, warm_start=False; total time=  12.6s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1420, warm_start=True; total time=  20.2s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=1920, warm_start=True; total time= 1.0min
[CV] END activation=tanh, alpha=0.0005970647070236323, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0004393500253283666, solver=sgd; total time= 3.2min
[CV] END activation=tanh, alpha=0.012757990283794434, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0031882559307257587, solver=sgd; total time= 1.2min
[CV] END activation=relu, alpha=0.009453838715277224, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00042752701065839103, solver=lbfgs; total time=  11.7s
[CV] END activation=relu, alpha=0.004016911110335401, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0002668419407799118, solver=sgd; total time=  17.1s
[CV] END activation=relu, alpha=0.004016911110335401, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0002668419407799118, solver=sgd; total time=  17.0s
[CV] END activation=relu, alpha=0.002390096485691469, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0005506095121649894, solver=lbfgs; total time=  22.5s
[CV] END activation=tanh, alpha=0.0038543069734368503, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0013490448357937168, solver=lbfgs; total time=   3.1s
[CV] END activation=tanh, alpha=0.0038543069734368503, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0013490448357937168, solver=lbfgs; total time=   3.1s
[CV] END activation=tanh, alpha=0.0038543069734368503, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0013490448357937168, solver=lbfgs; total time=   3.1s
[CV] END activation=tanh, alpha=0.023317209321110872, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0007896211858382457, solver=sgd; total time=  41.5s
[CV] END activation=relu, alpha=0.014054431668111154, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00012387162130363913, solver=sgd; total time= 1.9min
[CV] END activation=relu, alpha=0.015076867017041537, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0011089659087447463, solver=adam; total time=  15.5s
[CV] END activation=relu, alpha=0.0193768988104896, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00033862211725792533, solver=lbfgs; total time=  12.0s
[CV] END activation=tanh, alpha=0.0030469905134305653, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0007363224255568026, solver=sgd; total time=  19.4s
[CV] END activation=relu, alpha=0.004703511304129294, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0003236409350800037, solver=lbfgs; total time=  11.9s
[CV] END activation=relu, alpha=0.004703511304129294, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0003236409350800037, solver=lbfgs; total time=  11.6s
[CV] END activation=relu, alpha=0.0019529450873474105, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0004014911030602172, solver=adam; total time=  17.4s
[CV] END activation=relu, alpha=0.011109581153272064, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0002098079511345487, solver=lbfgs; total time=  11.1s
[CV] END activation=relu, alpha=0.011109581153272064, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0002098079511345487, solver=lbfgs; total time=  10.1s
[CV] END activation=tanh, alpha=0.002409083208842631, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.004527848431280144, solver=sgd; total time=  30.3s
[CV] END activation=relu, alpha=0.0012775213837489733, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0004767842126388066, solver=sgd; total time= 1.9min
[CV] END activation=tanh, alpha=0.008458103391255481, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0018033939926601445, solver=sgd; total time=  41.4s
[CV] END activation=relu, alpha=0.004256590494919544, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00010228631316585768, solver=adam; total time=  17.0s
[CV] END activation=relu, alpha=0.0016475771270150147, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0005829716649993588, solver=sgd; total time= 3.0min
[CV] END activation=tanh, alpha=0.0006051130040693857, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0013232752191340979, solver=sgd; total time=  41.5s
[CV] END activation=relu, alpha=0.0014718191949998913, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.00044341202737456563, solver=adam; total time=  20.4s
[CV] END activation=relu, alpha=0.001476224915031703, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0002846810133188014, solver=lbfgs; total time=  12.3s
[CV] END activation=relu, alpha=0.012927260969222188, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0013364917207447488, solver=lbfgs; total time=  11.2s
[CV] END activation=tanh, alpha=0.004208810605708498, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.00010147822923253085, solver=sgd; total time= 3.3min
[CV] END activation=tanh, alpha=0.0024417493984765634, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.000685254661240559, solver=lbfgs; total time=  11.1s
[CV] END activation=tanh, alpha=0.0024417493984765634, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.000685254661240559, solver=lbfgs; total time=  10.0s
[CV] END activation=tanh, alpha=0.009646569177315501, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0010590388043206305, solver=adam; total time=  24.3s
[CV] END activation=tanh, alpha=0.002792338357677655, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00030900542728840426, solver=adam; total time=  13.6s
[CV] END activation=tanh, alpha=0.006925083521688643, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0024602564367333987, solver=adam; total time=  10.2s
[CV] END activation=tanh, alpha=0.006925083521688643, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0024602564367333987, solver=adam; total time=   9.1s
[CV] END activation=tanh, alpha=0.015588408788798136, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0022827615052853456, solver=adam; total time=  18.1s
[CV] END activation=relu, alpha=0.008369258788831878, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0003719416123127553, solver=sgd; total time=  16.6s
[CV] END activation=tanh, alpha=0.013225547847176992, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.00010645722197437816, solver=adam; total time=  46.9s
[CV] END activation=relu, alpha=0.0047276930875493105, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.000580856436459806, solver=sgd; total time= 1.9min
[CV] END activation=tanh, alpha=0.020136810162603963, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00017712979356367323, solver=adam; total time=  38.8s
[CV] END activation=tanh, alpha=0.011801672336104206, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0005443060666769468, solver=lbfgs; total time=   3.2s
[CV] END activation=tanh, alpha=0.0017156828265544332, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.001020529459982444, solver=lbfgs; total time=  22.8s
[CV] END activation=tanh, alpha=0.022112651421771292, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=5.470154377822502e-05, solver=sgd; total time= 2.1min
[CV] END activation=tanh, alpha=0.0004350469238413108, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0001974619862719662, solver=lbfgs; total time=  10.9s
[CV] END activation=tanh, alpha=0.006822437220692069, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0003655888513705942, solver=sgd; total time=  41.5s
[CV] END activation=relu, alpha=0.009453838715277224, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00042752701065839103, solver=lbfgs; total time=  12.4s
[CV] END activation=relu, alpha=0.009453838715277224, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00042752701065839103, solver=lbfgs; total time=  12.6s
[CV] END activation=relu, alpha=0.004016911110335401, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0002668419407799118, solver=sgd; total time=  16.7s
[CV] END activation=relu, alpha=0.002390096485691469, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0005506095121649894, solver=lbfgs; total time=  20.5s
[CV] END activation=relu, alpha=0.002390096485691469, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0005506095121649894, solver=lbfgs; total time=  22.3s
[CV] END activation=tanh, alpha=0.023317209321110872, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0007896211858382457, solver=sgd; total time=  42.4s
[CV] END activation=relu, alpha=0.014054431668111154, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00012387162130363913, solver=sgd; total time= 2.0min
[CV] END activation=relu, alpha=0.0193768988104896, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00033862211725792533, solver=lbfgs; total time=  11.5s
[CV] END activation=relu, alpha=0.010403173803583481, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=8.755221609262623e-05, solver=lbfgs; total time=  12.1s
[CV] END activation=tanh, alpha=0.010873309044139858, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.001002285329743341, solver=sgd; total time= 2.5min
[CV] END activation=tanh, alpha=0.009052741516855579, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0011758376683753931, solver=lbfgs; total time=   4.4s
[CV] END activation=tanh, alpha=0.004885074233032532, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0006734867951207869, solver=sgd; total time=  41.4s
[CV] END activation=tanh, alpha=0.003910763942446413, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0008866989587581721, solver=adam; total time=  20.9s
[CV] END activation=tanh, alpha=0.008356205618454274, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0005158330676782927, solver=sgd; total time= 2.1min
[CV] END activation=relu, alpha=0.008754002449704996, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0005642043316975841, solver=adam; total time=  18.8s
[CV] END activation=relu, alpha=0.02921934009067769, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0017689441245158453, solver=sgd; total time=  16.3s
[CV] END activation=relu, alpha=0.018882340912264747, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=4.1706015049635146e-05, solver=sgd; total time=  16.3s
[CV] END activation=tanh, alpha=0.006888053876286935, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0014208356194821722, solver=adam; total time=   4.1s
[CV] END activation=tanh, alpha=0.006888053876286935, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0014208356194821722, solver=adam; total time=   6.0s
[CV] END activation=tanh, alpha=0.0025459721042527697, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0004133817218329473, solver=adam; total time=  25.2s
[CV] END activation=relu, alpha=0.0033209789053893573, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0006282417371991485, solver=sgd; total time= 1.9min
[CV] END activation=tanh, alpha=0.004208810605708498, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.00010147822923253085, solver=sgd; total time= 3.3min
[CV] END activation=tanh, alpha=0.0024417493984765634, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.000685254661240559, solver=lbfgs; total time=  12.0s
[CV] END activation=tanh, alpha=0.009646569177315501, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0010590388043206305, solver=adam; total time=  20.2s
[CV] END activation=tanh, alpha=0.009646569177315501, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0010590388043206305, solver=adam; total time=  17.7s
[CV] END activation=tanh, alpha=0.002792338357677655, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00030900542728840426, solver=adam; total time=  14.6s
[CV] END activation=tanh, alpha=0.006925083521688643, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0024602564367333987, solver=adam; total time=   9.5s
[CV] END activation=relu, alpha=0.004791391397458033, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0015647636405187841, solver=adam; total time=   5.8s
[CV] END activation=tanh, alpha=0.015588408788798136, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0022827615052853456, solver=adam; total time=  18.8s
[CV] END activation=tanh, alpha=0.01101777585894205, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0012976018568827616, solver=lbfgs; total time=  10.3s
[CV] END activation=tanh, alpha=0.004765967915234576, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0005214197239471825, solver=adam; total time=  19.7s
[CV] END activation=tanh, alpha=0.007503618273633049, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0009512630806759365, solver=lbfgs; total time=  10.9s
[CV] END activation=relu, alpha=0.003806126221860297, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0008496317307534936, solver=sgd; total time= 1.9min
[CV] END activation=relu, alpha=0.0235493877206639, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.001168789936564047, solver=lbfgs; total time=  19.4s
[CV] END activation=relu, alpha=0.0235493877206639, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.001168789936564047, solver=lbfgs; total time=  18.1s
[CV] END activation=tanh, alpha=0.009993405239869163, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0016122269081311146, solver=lbfgs; total time=   3.3s
[CV] END activation=tanh, alpha=0.009993405239869163, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0016122269081311146, solver=lbfgs; total time=   3.0s
[CV] END activation=relu, alpha=0.044625088655929124, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.00045584538780684954, solver=adam; total time=  46.0s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=1520, warm_start=False; total time=  28.5s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=1920, warm_start=False; total time=  28.5s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=420, warm_start=False; total time=   4.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1220, warm_start=False; total time=   9.1s
[CV] END activation=relu, alpha=0.002075525175169418, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0001146578777894657, solver=adam; total time=  16.5s
[CV] END activation=relu, alpha=0.022134217239908344, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0011209419502813012, solver=lbfgs; total time=   8.9s
[CV] END activation=relu, alpha=0.0086783403968907, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.003910391751237239, solver=adam; total time=  10.2s
[CV] END activation=relu, alpha=0.0086783403968907, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.003910391751237239, solver=adam; total time=  16.0s
[CV] END activation=tanh, alpha=0.011801672336104206, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0005443060666769468, solver=lbfgs; total time=   5.4s
[CV] END activation=tanh, alpha=0.0017156828265544332, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.001020529459982444, solver=lbfgs; total time=  24.0s
[CV] END activation=relu, alpha=0.017613741020518686, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.00043450866394032937, solver=adam; total time=  24.2s
[CV] END activation=tanh, alpha=0.021501859432782072, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0005694637318553642, solver=lbfgs; total time=  22.1s
[CV] END activation=relu, alpha=0.010577481151427308, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0005862326413765109, solver=lbfgs; total time=  21.4s
[CV] END activation=relu, alpha=0.010577481151427308, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0005862326413765109, solver=lbfgs; total time=  16.9s
[CV] END activation=tanh, alpha=0.012757990283794434, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0031882559307257587, solver=sgd; total time= 1.4min
[CV] END activation=tanh, alpha=0.01522510654076898, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0016681162438721957, solver=sgd; total time= 2.7min
[CV] END activation=relu, alpha=0.0022203338800437077, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.00021323610574975382, solver=sgd; total time=  16.5s
[CV] END activation=relu, alpha=0.015024550677117178, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=5.0563072883905715e-05, solver=adam; total time= 1.3min
[CV] END activation=relu, alpha=0.0193768988104896, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00033862211725792533, solver=lbfgs; total time=  12.1s
[CV] END activation=relu, alpha=0.010403173803583481, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=8.755221609262623e-05, solver=lbfgs; total time=  11.3s
[CV] END activation=tanh, alpha=0.0030469905134305653, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0007363224255568026, solver=sgd; total time=  19.6s
[CV] END activation=relu, alpha=0.004703511304129294, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0003236409350800037, solver=lbfgs; total time=  11.2s
[CV] END activation=relu, alpha=0.0019529450873474105, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0004014911030602172, solver=adam; total time=  20.2s
[CV] END activation=relu, alpha=0.0019529450873474105, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0004014911030602172, solver=adam; total time=  20.1s
[CV] END activation=relu, alpha=0.011109581153272064, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0002098079511345487, solver=lbfgs; total time=  10.8s
[CV] END activation=tanh, alpha=0.002409083208842631, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.004527848431280144, solver=sgd; total time=  31.1s
[CV] END activation=relu, alpha=0.0012775213837489733, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0004767842126388066, solver=sgd; total time= 1.9min
[CV] END activation=tanh, alpha=0.008458103391255481, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0018033939926601445, solver=sgd; total time=  42.6s
[CV] END activation=relu, alpha=0.004256590494919544, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00010228631316585768, solver=adam; total time=  17.2s
[CV] END activation=relu, alpha=0.004790270185041674, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0017452765065740685, solver=sgd; total time=  33.3s
[CV] END activation=relu, alpha=0.004790270185041674, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0017452765065740685, solver=sgd; total time=  34.8s
[CV] END activation=tanh, alpha=0.0014099409612413295, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0008307430950140481, solver=sgd; total time=  19.3s
[CV] END activation=tanh, alpha=0.010745375851566086, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.001652918249800711, solver=adam; total time=  13.2s
[CV] END activation=tanh, alpha=0.024532564823503605, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0036279443298852044, solver=lbfgs; total time=   3.6s
[CV] END activation=relu, alpha=0.02459188460395712, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=6.711885803807861e-07, solver=sgd; total time= 1.9min
[CV] END activation=relu, alpha=0.0014718191949998913, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.00044341202737456563, solver=adam; total time=  15.8s
[CV] END activation=relu, alpha=0.0014718191949998913, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.00044341202737456563, solver=adam; total time=  25.4s
[CV] END activation=tanh, alpha=0.004208810605708498, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.00010147822923253085, solver=sgd; total time= 3.3min
[CV] END activation=tanh, alpha=0.0008401025147722742, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0002550512570598277, solver=sgd; total time= 2.1min
[CV] END activation=tanh, alpha=0.007364529375983353, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0010703060252087756, solver=sgd; total time=  41.9s
[CV] END activation=tanh, alpha=0.006713070674592943, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0005953749592320846, solver=adam; total time=  19.3s
[CV] END activation=relu, alpha=0.004682250544842704, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.001577661209323617, solver=adam; total time=  20.0s
[CV] END activation=relu, alpha=0.004682250544842704, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.001577661209323617, solver=adam; total time=  17.5s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
[CV] END activation=tanh, alpha=0.0005970647070236323, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0004393500253283666, solver=sgd; total time= 3.3min
[CV] END activation=relu, alpha=0.013123929257878928, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0005556739093215221, solver=adam; total time=   6.4s
[CV] END activation=relu, alpha=0.013123929257878928, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0005556739093215221, solver=adam; total time=   7.0s
[CV] END activation=tanh, alpha=0.0004350469238413108, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0001974619862719662, solver=lbfgs; total time=  10.9s
[CV] END activation=relu, alpha=0.015435469314775598, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0003557641348576518, solver=adam; total time=   8.5s
[CV] END activation=relu, alpha=0.015435469314775598, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0003557641348576518, solver=adam; total time=   8.1s
[CV] END activation=relu, alpha=0.020211490288053288, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0018107596016739649, solver=sgd; total time= 2.0min
[CV] END activation=relu, alpha=0.002025567874020686, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.002590262624333099, solver=adam; total time=  15.3s
[CV] END activation=relu, alpha=0.002025567874020686, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.002590262624333099, solver=adam; total time=  18.3s
[CV] END activation=relu, alpha=0.014054431668111154, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00012387162130363913, solver=sgd; total time= 1.9min
[CV] END activation=relu, alpha=0.015076867017041537, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0011089659087447463, solver=adam; total time=  14.8s
[CV] END activation=relu, alpha=0.010403173803583481, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=8.755221609262623e-05, solver=lbfgs; total time=  11.4s
[CV] END activation=tanh, alpha=0.010873309044139858, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.001002285329743341, solver=sgd; total time= 2.4min
[CV] END activation=relu, alpha=0.0014056568932398197, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0006441541392987803, solver=adam; total time=  16.4s
[CV] END activation=relu, alpha=0.0008875139721023235, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0003420817947521096, solver=adam; total time=  20.2s
[CV] END activation=tanh, alpha=0.001822277965651674, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0007510450288025116, solver=lbfgs; total time=   3.2s
[CV] END activation=tanh, alpha=0.001822277965651674, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0007510450288025116, solver=lbfgs; total time=   3.1s
[CV] END activation=tanh, alpha=0.001822277965651674, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0007510450288025116, solver=lbfgs; total time=   3.0s
[CV] END activation=tanh, alpha=0.003910763942446413, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0008866989587581721, solver=adam; total time=  25.9s
[CV] END activation=tanh, alpha=0.008356205618454274, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0005158330676782927, solver=sgd; total time= 2.1min
[CV] END activation=tanh, alpha=0.008530098332571795, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.000297300912899126, solver=lbfgs; total time=   4.7s
[CV] END activation=tanh, alpha=0.0014099409612413295, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0008307430950140481, solver=sgd; total time=  19.3s
[CV] END activation=relu, alpha=0.02921934009067769, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0017689441245158453, solver=sgd; total time=  15.9s
[CV] END activation=tanh, alpha=0.024532564823503605, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0036279443298852044, solver=lbfgs; total time=   3.1s
[CV] END activation=tanh, alpha=0.024532564823503605, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0036279443298852044, solver=lbfgs; total time=   3.5s
[CV] END activation=relu, alpha=0.02459188460395712, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=6.711885803807861e-07, solver=sgd; total time=   2.7s
[CV] END activation=relu, alpha=0.02459188460395712, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=6.711885803807861e-07, solver=sgd; total time= 1.1min
[CV] END activation=tanh, alpha=0.0006051130040693857, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0013232752191340979, solver=sgd; total time=  41.9s
[CV] END activation=tanh, alpha=0.06641479537712633, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0013296366774833378, solver=sgd; total time= 2.1min
[CV] END activation=tanh, alpha=0.034601982675292325, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0019246610969967711, solver=adam; total time=  17.8s
[CV] END activation=relu, alpha=0.00521583766298311, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0006069704291210512, solver=adam; total time=  14.2s
[CV] END activation=relu, alpha=0.01806839210645113, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0004727126474495221, solver=sgd; total time= 3.0min
[CV] END activation=relu, alpha=0.008369258788831878, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0003719416123127553, solver=sgd; total time=  16.4s
[CV] END activation=tanh, alpha=0.013225547847176992, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.00010645722197437816, solver=adam; total time=  42.9s
[CV] END activation=relu, alpha=0.003806126221860297, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0008496317307534936, solver=sgd; total time= 1.8min
[CV] END activation=relu, alpha=0.0235493877206639, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.001168789936564047, solver=lbfgs; total time=  18.7s
[CV] END activation=tanh, alpha=0.00900714098154974, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0016867284020696271, solver=lbfgs; total time=   3.2s
[CV] END activation=tanh, alpha=0.00900714098154974, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0016867284020696271, solver=lbfgs; total time=   3.2s
[CV] END activation=tanh, alpha=0.00900714098154974, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0016867284020696271, solver=lbfgs; total time=   3.2s
[CV] END activation=tanh, alpha=0.009993405239869163, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0016122269081311146, solver=lbfgs; total time=   3.0s
[CV] END activation=relu, alpha=0.044625088655929124, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.00045584538780684954, solver=adam; total time=  32.7s
[CV] END activation=relu, alpha=0.02643313503929547, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0008132044228692657, solver=sgd; total time= 2.3min
[CV] END activation=relu, alpha=0.0511348025470494, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0004017667491825165, solver=adam; total time=  37.7s
[CV] END activation=tanh, alpha=0.02414375246123209, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00024349688567817652, solver=sgd; total time= 2.1min
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
[CV] END activation=tanh, alpha=0.0030469905134305653, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0007363224255568026, solver=sgd; total time=  20.4s
[CV] END activation=tanh, alpha=0.010873309044139858, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.001002285329743341, solver=sgd; total time= 2.6min
[CV] END activation=relu, alpha=0.0008875139721023235, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0003420817947521096, solver=adam; total time=  12.4s
[CV] END activation=relu, alpha=0.0008875139721023235, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0003420817947521096, solver=adam; total time=  16.2s
[CV] END activation=tanh, alpha=0.003910763942446413, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0008866989587581721, solver=adam; total time=  26.8s
[CV] END activation=tanh, alpha=0.008356205618454274, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0005158330676782927, solver=sgd; total time= 2.1min
[CV] END activation=tanh, alpha=0.008530098332571795, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.000297300912899126, solver=lbfgs; total time=  10.1s
[CV] END activation=relu, alpha=0.02921934009067769, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0017689441245158453, solver=sgd; total time=  16.0s
[CV] END activation=tanh, alpha=0.010745375851566086, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.001652918249800711, solver=adam; total time=  11.0s
[CV] END activation=relu, alpha=0.018882340912264747, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=4.1706015049635146e-05, solver=sgd; total time=  16.3s
[CV] END activation=tanh, alpha=0.0025459721042527697, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0004133817218329473, solver=adam; total time=  20.6s
[CV] END activation=relu, alpha=0.0033209789053893573, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0006282417371991485, solver=sgd; total time= 1.8min
[CV] END activation=relu, alpha=0.001476224915031703, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0002846810133188014, solver=lbfgs; total time=  13.0s
[CV] END activation=relu, alpha=0.012927260969222188, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0013364917207447488, solver=lbfgs; total time=  10.3s
[CV] END activation=relu, alpha=0.007759724535829794, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0024717188550603215, solver=sgd; total time= 1.6min
[CV] END activation=relu, alpha=0.01806839210645113, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0004727126474495221, solver=sgd; total time= 3.0min
[CV] END activation=tanh, alpha=0.024703224115945367, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00024586745789043085, solver=lbfgs; total time=  11.6s
[CV] END activation=tanh, alpha=0.01101777585894205, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0012976018568827616, solver=lbfgs; total time=  10.3s
[CV] END activation=tanh, alpha=0.013225547847176992, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.00010645722197437816, solver=adam; total time=  47.5s
[CV] END activation=relu, alpha=0.0047276930875493105, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.000580856436459806, solver=sgd; total time= 1.9min
[CV] END activation=tanh, alpha=0.020136810162603963, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00017712979356367323, solver=adam; total time=  44.9s
[CV] END activation=relu, alpha=0.007765290390851806, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0013024594320840534, solver=lbfgs; total time=   3.3s
[CV] END activation=tanh, alpha=0.03758187178041404, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0012176436573579864, solver=lbfgs; total time=   3.7s
[CV] END activation=tanh, alpha=0.03758187178041404, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0012176436573579864, solver=lbfgs; total time=   3.5s
[CV] END activation=relu, alpha=0.02643313503929547, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0008132044228692657, solver=sgd; total time= 2.3min
[CV] END activation=relu, alpha=0.0511348025470494, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0004017667491825165, solver=adam; total time=  31.4s
[CV] END activation=relu, alpha=0.002800727840411334, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00029618026094500546, solver=lbfgs; total time=  19.7s
[CV] END activation=tanh, alpha=0.02414375246123209, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00024349688567817652, solver=sgd; total time= 2.1min
[CV] END activation=relu, alpha=0.006832756371352915, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0008489186291873664, solver=sgd; total time=  39.6s
[CV] END activation=tanh, alpha=0.0035766993839981853, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.000392847853734784, solver=lbfgs; total time=  10.2s
[CV] END activation=relu, alpha=0.005818710633284476, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=5.1286797532166e-05, solver=adam; total time=  16.6s
[CV] END activation=relu, alpha=0.010696692688238531, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0008720102514840693, solver=adam; total time=  10.3s
[CV] END activation=relu, alpha=0.005089431279065441, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.001165593624737755, solver=sgd; total time= 2.3min
[CV] END activation=relu, alpha=0.017864926592473195, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.00023048939801302665, solver=adam; total time=  24.8s
[CV] END activation=relu, alpha=0.017864926592473195, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.00023048939801302665, solver=adam; total time=  19.0s
[CV] END activation=relu, alpha=0.004473197015203755, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0005341212449732535, solver=lbfgs; total time=   4.0s
[CV] END activation=relu, alpha=0.004473197015203755, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0005341212449732535, solver=lbfgs; total time=   3.4s
[CV] END activation=tanh, alpha=0.0007181763779822477, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.001054163305803131, solver=adam; total time=  29.3s
[CV] END activation=tanh, alpha=0.013839209485258235, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00019162366430828279, solver=lbfgs; total time=  22.1s
[CV] END activation=relu, alpha=0.00824294332832176, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0030871462685821273, solver=sgd; total time=  34.2s
[CV] END activation=tanh, alpha=0.011155260452342644, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0011660654839570036, solver=lbfgs; total time=  23.7s
[CV] END activation=tanh, alpha=0.042156779990523176, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0017312620435607246, solver=adam; total time=  16.5s
[CV] END activation=tanh, alpha=0.0017677708836280274, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.000999344949575033, solver=adam; total time=  31.5s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
[CV] END activation=tanh, alpha=0.025696220062070865, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.002330502078781765, solver=adam; total time=   2.9s
[CV] END activation=tanh, alpha=0.0015524358028988227, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0006978629040964538, solver=lbfgs; total time=  24.1s
[CV] END activation=relu, alpha=0.01137699830903779, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0009299739736360966, solver=adam; total time=  11.2s
[CV] END activation=relu, alpha=0.01557638335003179, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0021487494827681125, solver=adam; total time=   3.1s
[CV] END activation=relu, alpha=0.01557638335003179, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0021487494827681125, solver=adam; total time=   2.7s
[CV] END activation=tanh, alpha=0.0003032183386859539, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0015768657560180904, solver=adam; total time=  13.4s
[CV] END activation=tanh, alpha=0.0003032183386859539, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0015768657560180904, solver=adam; total time=  14.4s
[CV] END activation=relu, alpha=0.0016475771270150147, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0005829716649993588, solver=sgd; total time= 3.0min
[CV] END activation=tanh, alpha=0.06641479537712633, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0013296366774833378, solver=sgd; total time= 2.1min
[CV] END activation=relu, alpha=0.007759724535829794, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0024717188550603215, solver=sgd; total time= 1.7min
[CV] END activation=tanh, alpha=0.0008401025147722742, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0002550512570598277, solver=sgd; total time= 2.2min
[CV] END activation=tanh, alpha=0.015588408788798136, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0022827615052853456, solver=adam; total time=  22.8s
[CV] END activation=relu, alpha=0.008369258788831878, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0003719416123127553, solver=sgd; total time=  16.9s
[CV] END activation=tanh, alpha=0.007364529375983353, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0010703060252087756, solver=sgd; total time=  43.0s
[CV] END activation=relu, alpha=0.0047276930875493105, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.000580856436459806, solver=sgd; total time= 2.0min
[CV] END activation=tanh, alpha=0.020136810162603963, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00017712979356367323, solver=adam; total time=  40.9s
[CV] END activation=relu, alpha=0.007765290390851806, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0013024594320840534, solver=lbfgs; total time=   3.5s
[CV] END activation=relu, alpha=0.007765290390851806, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0013024594320840534, solver=lbfgs; total time=   3.5s
[CV] END activation=tanh, alpha=0.03758187178041404, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0012176436573579864, solver=lbfgs; total time=   3.6s
[CV] END activation=relu, alpha=0.02643313503929547, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0008132044228692657, solver=sgd; total time= 2.5min
[CV] END activation=relu, alpha=0.003999662104322434, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0008853057807055415, solver=lbfgs; total time=  18.3s
[CV] END activation=relu, alpha=0.004998702937369953, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0038919431636702494, solver=sgd; total time= 1.2min
[CV] END activation=relu, alpha=0.00705841733520395, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0002237863591962325, solver=sgd; total time= 1.9min
[CV] END activation=tanh, alpha=0.0035766993839981853, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.000392847853734784, solver=lbfgs; total time=  10.5s
[CV] END activation=tanh, alpha=0.011405888106128994, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0009441077904365556, solver=sgd; total time=  19.2s
[CV] END activation=relu, alpha=0.005818710633284476, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=5.1286797532166e-05, solver=adam; total time=  17.4s
[CV] END activation=tanh, alpha=0.009785037715450227, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0024945728753241582, solver=lbfgs; total time=  20.7s
[CV] END activation=tanh, alpha=0.0023620668841892846, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=7.904841623337809e-05, solver=sgd; total time=  41.9s
[CV] END activation=relu, alpha=0.004773885232920751, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0001744929724398442, solver=lbfgs; total time=   2.8s
[CV] END activation=relu, alpha=0.004773885232920751, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0001744929724398442, solver=lbfgs; total time=   2.5s
[CV] END activation=relu, alpha=0.017966312101988038, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.000280169439329975, solver=sgd; total time=  16.7s
[CV] END activation=relu, alpha=0.017966312101988038, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.000280169439329975, solver=sgd; total time=  17.2s
[CV] END activation=tanh, alpha=0.016584725718570274, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0008751291436515352, solver=sgd; total time= 2.9min
[CV] END activation=tanh, alpha=0.0017692378956052405, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.002203712449513837, solver=lbfgs; total time=  11.2s
[CV] END activation=tanh, alpha=0.01326925603851573, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0019914522753652028, solver=lbfgs; total time=   4.3s
[CV] END activation=relu, alpha=0.0016794795247424977, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00041773175574660973, solver=sgd; total time= 3.0min
[CV] END activation=relu, alpha=0.012030488628279963, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=9.910498376000495e-05, solver=adam; total time=  55.2s
[CV] END activation=tanh, alpha=0.004679323461409505, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00046962340731819443, solver=lbfgs; total time=  27.3s
[CV] END activation=tanh, alpha=0.004679323461409505, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00046962340731819443, solver=lbfgs; total time=  19.0s
[CV] END activation=relu, alpha=0.005380228978134951, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0002875827748061769, solver=lbfgs; total time=  23.0s
[CV] END activation=tanh, alpha=0.019399975425825604, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.004097221120107713, solver=lbfgs; total time=  21.0s
[CV] END activation=tanh, alpha=0.012474506940192302, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0004181104714920977, solver=lbfgs; total time=  10.3s
[CV] END activation=relu, alpha=0.009412426761011169, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.000108117756430576, solver=lbfgs; total time=  10.2s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
[CV] END activation=relu, alpha=0.00521583766298311, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0006069704291210512, solver=adam; total time=  13.9s
[CV] END activation=relu, alpha=0.012429822911169007, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0015405169711251835, solver=lbfgs; total time=   3.6s
[CV] END activation=relu, alpha=0.012429822911169007, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0015405169711251835, solver=lbfgs; total time=   2.5s
[CV] END activation=relu, alpha=0.012429822911169007, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0015405169711251835, solver=lbfgs; total time=   3.7s
[CV] END activation=tanh, alpha=0.0008401025147722742, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0002550512570598277, solver=sgd; total time= 2.1min
[CV] END activation=tanh, alpha=0.002792338357677655, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00030900542728840426, solver=adam; total time=  11.8s
[CV] END activation=relu, alpha=0.004791391397458033, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0015647636405187841, solver=adam; total time=   6.7s
[CV] END activation=relu, alpha=0.004791391397458033, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0015647636405187841, solver=adam; total time=   6.2s
[CV] END activation=tanh, alpha=0.024703224115945367, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00024586745789043085, solver=lbfgs; total time=  10.6s
[CV] END activation=tanh, alpha=0.024703224115945367, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00024586745789043085, solver=lbfgs; total time=  10.4s
[CV] END activation=tanh, alpha=0.004765967915234576, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0005214197239471825, solver=adam; total time=  26.2s
[CV] END activation=tanh, alpha=0.007503618273633049, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0009512630806759365, solver=lbfgs; total time=  10.8s
[CV] END activation=tanh, alpha=0.007503618273633049, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0009512630806759365, solver=lbfgs; total time=  11.1s
[CV] END activation=relu, alpha=0.003806126221860297, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0008496317307534936, solver=sgd; total time= 1.7min
[CV] END activation=relu, alpha=0.011033379766192062, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00022647091666955078, solver=sgd; total time= 3.0min
[CV] END activation=tanh, alpha=0.0008200532904974467, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0009859998406191914, solver=adam; total time=  19.9s
[CV] END activation=relu, alpha=0.004114148488816734, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0012143554127425696, solver=lbfgs; total time=  12.4s
[CV] END activation=relu, alpha=0.010633008211432173, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0007994748634099812, solver=sgd; total time=  16.7s
[CV] END activation=relu, alpha=0.005238008663863521, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0005220680361481759, solver=lbfgs; total time=   5.2s
[CV] END activation=relu, alpha=0.005238008663863521, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0005220680361481759, solver=lbfgs; total time=   4.4s
[CV] END activation=tanh, alpha=0.0041057995375075405, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0032294510323579236, solver=adam; total time=   2.8s
[CV] END activation=relu, alpha=0.004998702937369953, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0038919431636702494, solver=sgd; total time=  58.0s
[CV] END activation=tanh, alpha=0.004835824513026582, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0005343014843242719, solver=lbfgs; total time=  10.9s
[CV] END activation=relu, alpha=0.0019284310295813929, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00033213125394628, solver=lbfgs; total time=  22.8s
[CV] END activation=tanh, alpha=0.004314266555113575, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0008342203940123731, solver=sgd; total time= 2.1min
[CV] END activation=relu, alpha=0.010696692688238531, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0008720102514840693, solver=adam; total time=  11.8s
[CV] END activation=tanh, alpha=0.00346988582411485, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00045719564778622345, solver=lbfgs; total time=   5.1s
[CV] END activation=tanh, alpha=0.009785037715450227, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0024945728753241582, solver=lbfgs; total time=  19.9s
[CV] END activation=tanh, alpha=0.0023620668841892846, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=7.904841623337809e-05, solver=sgd; total time=  41.6s
[CV] END activation=relu, alpha=0.004773885232920751, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0001744929724398442, solver=lbfgs; total time=   5.2s
[CV] END activation=relu, alpha=0.017966312101988038, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.000280169439329975, solver=sgd; total time=  16.9s
[CV] END activation=tanh, alpha=0.016584725718570274, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0008751291436515352, solver=sgd; total time= 3.1min
[CV] END activation=tanh, alpha=0.011155260452342644, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0011660654839570036, solver=lbfgs; total time=  21.7s
[CV] END activation=relu, alpha=0.0016794795247424977, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00041773175574660973, solver=sgd; total time= 3.0min
[CV] END activation=tanh, alpha=0.00852629428937817, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0005522665387872556, solver=lbfgs; total time=   5.9s
[CV] END activation=tanh, alpha=0.00852629428937817, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0005522665387872556, solver=lbfgs; total time=   6.8s
[CV] END activation=relu, alpha=0.018459349767744496, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0012104517090389803, solver=adam; total time=   6.8s
[CV] END activation=relu, alpha=0.014050919350463, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0005351034809801996, solver=lbfgs; total time=   3.9s
[CV] END activation=relu, alpha=0.014050919350463, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0005351034809801996, solver=lbfgs; total time=   5.5s
[CV] END activation=relu, alpha=0.003925215272400628, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=2.3051343263516173e-05, solver=adam; total time= 1.7min
[CV] END activation=tanh, alpha=0.019399975425825604, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.004097221120107713, solver=lbfgs; total time=  19.0s
[CV] END activation=tanh, alpha=0.019644776984498017, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00025189530010628946, solver=adam; total time=  35.6s
[CV] END activation=tanh, alpha=0.012630595308419888, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.002272340546859991, solver=adam; total time=   9.7s
[CV] END activation=relu, alpha=0.001649195239367829, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0008341559917230889, solver=sgd; total time= 2.7min
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
[CV] END activation=relu, alpha=0.0075778734778233995, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0006794850084435586, solver=lbfgs; total time=  12.2s
[CV] END activation=tanh, alpha=0.02151525696780641, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0023008375117898744, solver=sgd; total time= 1.8min
[CV] END activation=relu, alpha=0.010633008211432173, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0007994748634099812, solver=sgd; total time=  16.5s
[CV] END activation=relu, alpha=0.003999662104322434, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0008853057807055415, solver=lbfgs; total time=  19.5s
[CV] END activation=relu, alpha=0.015842704978873186, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0030899280793803105, solver=lbfgs; total time=   4.3s
[CV] END activation=relu, alpha=0.002800727840411334, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00029618026094500546, solver=lbfgs; total time=  20.6s
[CV] END activation=tanh, alpha=0.0022931859207086466, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.001644628822196472, solver=adam; total time=  12.7s
[CV] END activation=tanh, alpha=0.02292754676759122, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00034153450480509513, solver=adam; total time=  12.4s
[CV] END activation=tanh, alpha=0.02292754676759122, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00034153450480509513, solver=adam; total time=   9.6s
[CV] END activation=tanh, alpha=0.004835824513026582, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0005343014843242719, solver=lbfgs; total time=  10.7s
[CV] END activation=relu, alpha=0.00705841733520395, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0002237863591962325, solver=sgd; total time= 1.9min
[CV] END activation=tanh, alpha=0.0035766993839981853, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.000392847853734784, solver=lbfgs; total time=  10.2s
[CV] END activation=tanh, alpha=0.011405888106128994, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0009441077904365556, solver=sgd; total time=  19.4s
[CV] END activation=relu, alpha=0.005089431279065441, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.001165593624737755, solver=sgd; total time= 2.5min
[CV] END activation=relu, alpha=0.017864926592473195, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.00023048939801302665, solver=adam; total time=  46.9s
[CV] END activation=relu, alpha=0.004473197015203755, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0005341212449732535, solver=lbfgs; total time=   3.7s
[CV] END activation=tanh, alpha=0.0007181763779822477, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.001054163305803131, solver=adam; total time=  22.2s
[CV] END activation=tanh, alpha=0.0007181763779822477, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.001054163305803131, solver=adam; total time=  33.6s
[CV] END activation=relu, alpha=0.00824294332832176, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0030871462685821273, solver=sgd; total time=  30.6s
[CV] END activation=tanh, alpha=0.011155260452342644, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0011660654839570036, solver=lbfgs; total time=  20.6s
[CV] END activation=tanh, alpha=0.042156779990523176, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0017312620435607246, solver=adam; total time=  18.8s
[CV] END activation=tanh, alpha=0.0017677708836280274, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.000999344949575033, solver=adam; total time=  20.6s
[CV] END activation=tanh, alpha=0.0017677708836280274, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.000999344949575033, solver=adam; total time=  24.8s
[CV] END activation=tanh, alpha=0.0053417268103487505, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=6.044977924583969e-05, solver=adam; total time=  21.3s
[CV] END activation=tanh, alpha=0.0053417268103487505, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=6.044977924583969e-05, solver=adam; total time=  21.2s
[CV] END activation=relu, alpha=0.013378244809414621, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00021374152528458564, solver=adam; total time=  14.9s
[CV] END activation=relu, alpha=0.013378244809414621, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00021374152528458564, solver=adam; total time=  13.5s
[CV] END activation=tanh, alpha=0.00026941327080446704, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0007867745037541065, solver=adam; total time=  14.5s
[CV] END activation=relu, alpha=0.013568634079305147, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0011954741668055448, solver=sgd; total time=  17.4s
[CV] END activation=tanh, alpha=0.011342948917080405, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0011309879710553763, solver=sgd; total time=  43.4s
[CV] END activation=relu, alpha=0.003925215272400628, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=2.3051343263516173e-05, solver=adam; total time= 1.7min
[CV] END activation=tanh, alpha=0.012474506940192302, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0004181104714920977, solver=lbfgs; total time=  11.6s
[CV] END activation=tanh, alpha=0.019644776984498017, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00025189530010628946, solver=adam; total time=  28.7s
[CV] END activation=tanh, alpha=0.00035411992512896314, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0007998654635219555, solver=sgd; total time=  20.3s
[CV] END activation=relu, alpha=0.03232468713509406, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=7.763761158384169e-05, solver=sgd; total time=  17.3s
[CV] END activation=tanh, alpha=0.009336180207526676, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0013205787429985414, solver=sgd; total time= 3.0min
[CV] END activation=tanh, alpha=0.0017834915014127962, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.000510485940467411, solver=adam; total time=  27.6s
[CV] END activation=relu, alpha=0.006993279699030559, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0002958266399968221, solver=adam; total time=   8.2s
[CV] END activation=tanh, alpha=0.009426328507233997, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0010406628960483966, solver=sgd; total time=  42.9s
[CV] END activation=tanh, alpha=0.004502193574081293, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0004535589228290553, solver=adam; total time=  26.2s
[CV] END activation=tanh, alpha=0.004502193574081293, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0004535589228290553, solver=adam; total time=  19.5s
[CV] END activation=relu, alpha=0.014647617791209646, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00039019222872556223, solver=lbfgs; total time=  10.8s
[CV] END activation=tanh, alpha=0.0017043978740745578, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.002487149823956261, solver=lbfgs; total time=  19.4s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
[CV] END activation=relu, alpha=0.012927260969222188, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0013364917207447488, solver=lbfgs; total time=  12.2s
[CV] END activation=relu, alpha=0.007759724535829794, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0024717188550603215, solver=sgd; total time= 1.7min
[CV] END activation=relu, alpha=0.01806839210645113, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0004727126474495221, solver=sgd; total time= 3.0min
[CV] END activation=tanh, alpha=0.01101777585894205, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0012976018568827616, solver=lbfgs; total time=  10.8s
[CV] END activation=tanh, alpha=0.004765967915234576, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0005214197239471825, solver=adam; total time=  16.3s
[CV] END activation=tanh, alpha=0.007364529375983353, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0010703060252087756, solver=sgd; total time=  41.4s
[CV] END activation=tanh, alpha=0.006713070674592943, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0005953749592320846, solver=adam; total time=  16.8s
[CV] END activation=tanh, alpha=0.006713070674592943, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0005953749592320846, solver=adam; total time=  21.5s
[CV] END activation=relu, alpha=0.004682250544842704, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.001577661209323617, solver=adam; total time=  23.3s
[CV] END activation=relu, alpha=0.011033379766192062, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00022647091666955078, solver=sgd; total time= 3.0min
[CV] END activation=tanh, alpha=0.0008200532904974467, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0009859998406191914, solver=adam; total time=  24.3s
[CV] END activation=tanh, alpha=0.0008200532904974467, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0009859998406191914, solver=adam; total time=  12.7s
[CV] END activation=relu, alpha=0.004114148488816734, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0012143554127425696, solver=lbfgs; total time=  11.5s
[CV] END activation=relu, alpha=0.010633008211432173, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0007994748634099812, solver=sgd; total time=  16.4s
[CV] END activation=relu, alpha=0.003999662104322434, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0008853057807055415, solver=lbfgs; total time=  19.7s
[CV] END activation=relu, alpha=0.004998702937369953, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0038919431636702494, solver=sgd; total time=  56.2s
[CV] END activation=tanh, alpha=0.004835824513026582, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0005343014843242719, solver=lbfgs; total time=  11.1s
[CV] END activation=relu, alpha=0.0019284310295813929, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00033213125394628, solver=lbfgs; total time=  18.5s
[CV] END activation=relu, alpha=0.00705841733520395, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0002237863591962325, solver=sgd; total time= 1.9min
[CV] END activation=tanh, alpha=0.011405888106128994, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0009441077904365556, solver=sgd; total time=  18.9s
[CV] END activation=relu, alpha=0.005089431279065441, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.001165593624737755, solver=sgd; total time= 2.3min
[CV] END activation=tanh, alpha=0.016584725718570274, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0008751291436515352, solver=sgd; total time= 2.8min
[CV] END activation=tanh, alpha=0.012684340903193368, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0011029088125609425, solver=sgd; total time=  41.8s
[CV] END activation=tanh, alpha=0.0067285028305236715, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.003165290167016621, solver=sgd; total time=  19.1s
[CV] END activation=tanh, alpha=0.007959515488024533, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0008976266610021868, solver=sgd; total time=  41.0s
[CV] END activation=tanh, alpha=0.005126769173597923, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0005908291403680883, solver=adam; total time=  22.1s
[CV] END activation=tanh, alpha=0.00026941327080446704, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0007867745037541065, solver=adam; total time=  15.2s
[CV] END activation=tanh, alpha=0.002422417065954016, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.000556523480177387, solver=lbfgs; total time=  11.2s
[CV] END activation=relu, alpha=0.013568634079305147, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0011954741668055448, solver=sgd; total time=  16.9s
[CV] END activation=tanh, alpha=0.011342948917080405, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0011309879710553763, solver=sgd; total time=  41.9s
[CV] END activation=relu, alpha=0.011459812701486905, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0010690077084049951, solver=sgd; total time= 2.3min
[CV] END activation=relu, alpha=0.004398255758771709, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0006299821961708244, solver=lbfgs; total time=   3.4s
[CV] END activation=tanh, alpha=0.00035411992512896314, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0007998654635219555, solver=sgd; total time=  20.2s
[CV] END activation=relu, alpha=0.03232468713509406, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=7.763761158384169e-05, solver=sgd; total time=  16.4s
[CV] END activation=tanh, alpha=0.010676646502545729, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0002410558780979127, solver=sgd; total time=  41.6s
[CV] END activation=tanh, alpha=0.0005055323202262127, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0006135798600591278, solver=adam; total time=  20.3s
[CV] END activation=tanh, alpha=0.0005055323202262127, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0006135798600591278, solver=adam; total time=  19.5s
[CV] END activation=relu, alpha=0.0075926410200179775, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.00045595918381241145, solver=adam; total time=  17.5s
[CV] END activation=relu, alpha=0.008643460725749038, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00021145170176783146, solver=lbfgs; total time=  22.2s
[CV] END activation=relu, alpha=0.008643460725749038, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00021145170176783146, solver=lbfgs; total time=  19.3s
[CV] END activation=relu, alpha=0.03032215539417534, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0006987583149464913, solver=sgd; total time= 2.8min
[CV] END activation=relu, alpha=0.014647617791209646, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00039019222872556223, solver=lbfgs; total time=  12.1s
[CV] END activation=relu, alpha=0.0018520864887919904, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0009348067612650253, solver=lbfgs; total time=  12.1s
[CV] END activation=relu, alpha=0.0018520864887919904, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0009348067612650253, solver=lbfgs; total time=  10.7s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
[CV] END activation=relu, alpha=0.011033379766192062, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00022647091666955078, solver=sgd; total time= 3.0min
[CV] END activation=tanh, alpha=0.02151525696780641, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0023008375117898744, solver=sgd; total time= 1.6min
[CV] END activation=relu, alpha=0.015842704978873186, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0030899280793803105, solver=lbfgs; total time=   3.2s
[CV] END activation=relu, alpha=0.002800727840411334, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00029618026094500546, solver=lbfgs; total time=  18.7s
[CV] END activation=tanh, alpha=0.0022931859207086466, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.001644628822196472, solver=adam; total time=  12.7s
[CV] END activation=tanh, alpha=0.0022931859207086466, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.001644628822196472, solver=adam; total time=  10.4s
[CV] END activation=tanh, alpha=0.02292754676759122, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00034153450480509513, solver=adam; total time=  18.8s
[CV] END activation=relu, alpha=0.0019284310295813929, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00033213125394628, solver=lbfgs; total time=  18.9s
[CV] END activation=tanh, alpha=0.004314266555113575, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0008342203940123731, solver=sgd; total time= 2.1min
[CV] END activation=relu, alpha=0.005818710633284476, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=5.1286797532166e-05, solver=adam; total time=  17.2s
[CV] END activation=tanh, alpha=0.00346988582411485, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00045719564778622345, solver=lbfgs; total time=   5.2s
[CV] END activation=tanh, alpha=0.0023620668841892846, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=7.904841623337809e-05, solver=sgd; total time=  42.0s
[CV] END activation=tanh, alpha=0.03709801493576339, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.00011898713435783809, solver=sgd; total time= 3.3min
[CV] END activation=relu, alpha=0.004893561353584806, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00025886653758705605, solver=lbfgs; total time=  11.3s
[CV] END activation=relu, alpha=0.004893561353584806, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00025886653758705605, solver=lbfgs; total time=  12.3s
[CV] END activation=tanh, alpha=0.0014772879770590635, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0008728383537769557, solver=sgd; total time=  19.3s
[CV] END activation=tanh, alpha=0.0017692378956052405, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.002203712449513837, solver=lbfgs; total time=  10.0s
[CV] END activation=tanh, alpha=0.012684340903193368, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0011029088125609425, solver=sgd; total time=  41.8s
[CV] END activation=tanh, alpha=0.0067285028305236715, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.003165290167016621, solver=sgd; total time=  14.8s
[CV] END activation=tanh, alpha=0.007959515488024533, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0008976266610021868, solver=sgd; total time=  41.3s
[CV] END activation=relu, alpha=0.028803347155997028, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0011403663157484765, solver=adam; total time=   9.7s
[CV] END activation=relu, alpha=0.013378244809414621, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00021374152528458564, solver=adam; total time=  12.7s
[CV] END activation=relu, alpha=0.0032996303812403366, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0013720989488549688, solver=adam; total time=  16.6s
[CV] END activation=tanh, alpha=0.00026941327080446704, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0007867745037541065, solver=adam; total time=  16.9s
[CV] END activation=tanh, alpha=0.006005161916446455, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0014792618261225054, solver=adam; total time=   9.8s
[CV] END activation=tanh, alpha=0.006005161916446455, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0014792618261225054, solver=adam; total time=  15.8s
[CV] END activation=tanh, alpha=0.00852629428937817, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0005522665387872556, solver=lbfgs; total time=   3.7s
[CV] END activation=relu, alpha=0.018459349767744496, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0012104517090389803, solver=adam; total time=   8.3s
[CV] END activation=relu, alpha=0.018459349767744496, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0012104517090389803, solver=adam; total time=   8.8s
[CV] END activation=relu, alpha=0.014050919350463, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0005351034809801996, solver=lbfgs; total time=   4.8s
[CV] END activation=relu, alpha=0.003925215272400628, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=2.3051343263516173e-05, solver=adam; total time= 1.9min
[CV] END activation=tanh, alpha=0.012474506940192302, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0004181104714920977, solver=lbfgs; total time=  10.8s
[CV] END activation=tanh, alpha=0.019644776984498017, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00025189530010628946, solver=adam; total time=  29.4s
[CV] END activation=tanh, alpha=0.012630595308419888, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.002272340546859991, solver=adam; total time=  10.5s
[CV] END activation=tanh, alpha=0.0008722524096036777, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0004099776158711347, solver=adam; total time=  16.1s
[CV] END activation=relu, alpha=0.001649195239367829, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0008341559917230889, solver=sgd; total time= 2.5min
[CV] END activation=tanh, alpha=0.015201538674731218, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0007422626202064951, solver=adam; total time=  38.9s
[CV] END activation=tanh, alpha=0.0017834915014127962, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.000510485940467411, solver=adam; total time=  21.7s
[CV] END activation=relu, alpha=0.006993279699030559, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0002958266399968221, solver=adam; total time=   9.5s
[CV] END activation=tanh, alpha=0.009426328507233997, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0010406628960483966, solver=sgd; total time=  41.7s
[CV] END activation=tanh, alpha=0.004502193574081293, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0004535589228290553, solver=adam; total time=  42.9s
[CV] END activation=tanh, alpha=0.00531083478323805, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.00033154288060074997, solver=sgd; total time=  41.9s
[CV] END activation=relu, alpha=0.0014116051635769207, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00028887237259173624, solver=adam; total time=  22.9s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
[CV] END activation=relu, alpha=0.044625088655929124, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.00045584538780684954, solver=adam; total time=  30.9s
[CV] END activation=relu, alpha=0.0075778734778233995, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0006794850084435586, solver=lbfgs; total time=  10.1s
[CV] END activation=relu, alpha=0.0075778734778233995, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0006794850084435586, solver=lbfgs; total time=  12.2s
[CV] END activation=tanh, alpha=0.02151525696780641, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0023008375117898744, solver=sgd; total time= 1.5min
[CV] END activation=relu, alpha=0.004114148488816734, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0012143554127425696, solver=lbfgs; total time=  12.5s
[CV] END activation=relu, alpha=0.0511348025470494, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0004017667491825165, solver=adam; total time=  10.7s
[CV] END activation=relu, alpha=0.005238008663863521, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0005220680361481759, solver=lbfgs; total time=  12.0s
[CV] END activation=tanh, alpha=0.0041057995375075405, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0032294510323579236, solver=adam; total time=   1.6s
[CV] END activation=tanh, alpha=0.0041057995375075405, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0032294510323579236, solver=adam; total time=   3.3s
[CV] END activation=relu, alpha=0.015842704978873186, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0030899280793803105, solver=lbfgs; total time=  10.9s
[CV] END activation=tanh, alpha=0.02414375246123209, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00024349688567817652, solver=sgd; total time= 2.1min
[CV] END activation=relu, alpha=0.006832756371352915, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0008489186291873664, solver=sgd; total time=  40.4s
[CV] END activation=relu, alpha=0.006832756371352915, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0008489186291873664, solver=sgd; total time=  38.9s
[CV] END activation=relu, alpha=0.010696692688238531, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0008720102514840693, solver=adam; total time=  10.7s
[CV] END activation=tanh, alpha=0.00346988582411485, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00045719564778622345, solver=lbfgs; total time=   4.3s
[CV] END activation=tanh, alpha=0.009785037715450227, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0024945728753241582, solver=lbfgs; total time=  24.0s
[CV] END activation=tanh, alpha=0.03709801493576339, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.00011898713435783809, solver=sgd; total time= 3.3min
[CV] END activation=tanh, alpha=0.013839209485258235, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00019162366430828279, solver=lbfgs; total time=  18.3s
[CV] END activation=relu, alpha=0.00824294332832176, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0030871462685821273, solver=sgd; total time=  30.5s
[CV] END activation=tanh, alpha=0.0014772879770590635, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0008728383537769557, solver=sgd; total time=  19.3s
[CV] END activation=tanh, alpha=0.01326925603851573, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0019914522753652028, solver=lbfgs; total time=   6.1s
[CV] END activation=tanh, alpha=0.042156779990523176, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0017312620435607246, solver=adam; total time=  11.5s
[CV] END activation=tanh, alpha=0.012684340903193368, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0011029088125609425, solver=sgd; total time=  40.9s
[CV] END activation=tanh, alpha=0.007959515488024533, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0008976266610021868, solver=sgd; total time=  40.7s
[CV] END activation=relu, alpha=0.014285508962105984, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=4.774352340461999e-05, solver=lbfgs; total time=   4.2s
[CV] END activation=relu, alpha=0.028803347155997028, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0011403663157484765, solver=adam; total time=   8.2s
[CV] END activation=tanh, alpha=0.005126769173597923, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0005908291403680883, solver=adam; total time=  19.2s
[CV] END activation=relu, alpha=0.0032996303812403366, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0013720989488549688, solver=adam; total time=  21.3s
[CV] END activation=tanh, alpha=0.002422417065954016, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.000556523480177387, solver=lbfgs; total time=  11.0s
[CV] END activation=tanh, alpha=0.006005161916446455, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0014792618261225054, solver=adam; total time=  12.5s
[CV] END activation=tanh, alpha=0.011342948917080405, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0011309879710553763, solver=sgd; total time=  41.7s
[CV] END activation=relu, alpha=0.011459812701486905, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0010690077084049951, solver=sgd; total time= 2.6min
[CV] END activation=tanh, alpha=0.0008722524096036777, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0004099776158711347, solver=adam; total time=  18.6s
[CV] END activation=tanh, alpha=0.010676646502545729, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0002410558780979127, solver=sgd; total time=  41.6s
[CV] END activation=tanh, alpha=0.009336180207526676, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0013205787429985414, solver=sgd; total time= 2.8min
[CV] END activation=relu, alpha=0.004345874218315455, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0011654652774007422, solver=adam; total time=   5.6s
[CV] END activation=tanh, alpha=0.009426328507233997, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0010406628960483966, solver=sgd; total time=  41.1s
[CV] END activation=relu, alpha=0.0009725540159183265, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0007742310137900608, solver=sgd; total time=  38.6s
[CV] END activation=relu, alpha=0.003280395322264669, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0002830374670878367, solver=lbfgs; total time=   4.3s
[CV] END activation=relu, alpha=0.020694295125886983, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=9.886621955712806e-05, solver=sgd; total time=  16.1s
[CV] END activation=tanh, alpha=0.0017043978740745578, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.002487149823956261, solver=lbfgs; total time=  21.8s
[CV] END activation=relu, alpha=0.0037442361263322183, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0005585456033882345, solver=sgd; total time=  16.2s
[CV] END activation=relu, alpha=0.0016224814726571823, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00017748079167499852, solver=sgd; total time= 2.0min
[CV] END activation=tanh, alpha=0.0035968138543403484, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0014444624222859897, solver=sgd; total time= 3.0min
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
[CV] END activation=tanh, alpha=0.0067285028305236715, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.003165290167016621, solver=sgd; total time=  17.0s
[CV] END activation=tanh, alpha=0.0053417268103487505, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=6.044977924583969e-05, solver=adam; total time=  20.2s
[CV] END activation=relu, alpha=0.014285508962105984, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=4.774352340461999e-05, solver=lbfgs; total time=   4.2s
[CV] END activation=relu, alpha=0.014285508962105984, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=4.774352340461999e-05, solver=lbfgs; total time=   3.6s
[CV] END activation=relu, alpha=0.028803347155997028, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0011403663157484765, solver=adam; total time=  10.0s
[CV] END activation=tanh, alpha=0.005126769173597923, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0005908291403680883, solver=adam; total time=  20.1s
[CV] END activation=relu, alpha=0.0032996303812403366, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0013720989488549688, solver=adam; total time=  18.3s
[CV] END activation=tanh, alpha=0.002422417065954016, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.000556523480177387, solver=lbfgs; total time=  11.3s
[CV] END activation=relu, alpha=0.013568634079305147, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0011954741668055448, solver=sgd; total time=  16.6s
[CV] END activation=relu, alpha=0.012030488628279963, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=9.910498376000495e-05, solver=adam; total time= 1.3min
[CV] END activation=tanh, alpha=0.004679323461409505, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00046962340731819443, solver=lbfgs; total time=  20.3s
[CV] END activation=relu, alpha=0.005380228978134951, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0002875827748061769, solver=lbfgs; total time=  20.6s
[CV] END activation=relu, alpha=0.005380228978134951, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0002875827748061769, solver=lbfgs; total time=  18.3s
[CV] END activation=tanh, alpha=0.019399975425825604, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.004097221120107713, solver=lbfgs; total time=  20.7s
[CV] END activation=relu, alpha=0.009412426761011169, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.000108117756430576, solver=lbfgs; total time=  11.5s
[CV] END activation=relu, alpha=0.009412426761011169, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.000108117756430576, solver=lbfgs; total time=  11.2s
[CV] END activation=tanh, alpha=0.012630595308419888, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.002272340546859991, solver=adam; total time=  12.3s
[CV] END activation=tanh, alpha=0.0008722524096036777, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0004099776158711347, solver=adam; total time=  23.3s
[CV] END activation=tanh, alpha=0.009336180207526676, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0013205787429985414, solver=sgd; total time= 2.9min
[CV] END activation=tanh, alpha=0.0017834915014127962, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.000510485940467411, solver=adam; total time=  29.4s
[CV] END activation=relu, alpha=0.006993279699030559, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0002958266399968221, solver=adam; total time=   9.6s
[CV] END activation=relu, alpha=0.004345874218315455, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0011654652774007422, solver=adam; total time=  11.2s
[CV] END activation=tanh, alpha=0.011379930262320382, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0014216585267720408, solver=sgd; total time=  20.0s
[CV] END activation=relu, alpha=9.401835905424785e-05, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0010999514767811465, solver=lbfgs; total time=   3.9s
[CV] END activation=relu, alpha=9.401835905424785e-05, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0010999514767811465, solver=lbfgs; total time=   3.3s
[CV] END activation=relu, alpha=9.401835905424785e-05, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0010999514767811465, solver=lbfgs; total time=   3.6s
[CV] END activation=relu, alpha=0.0009725540159183265, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0007742310137900608, solver=sgd; total time=  39.0s
[CV] END activation=relu, alpha=0.003280395322264669, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0002830374670878367, solver=lbfgs; total time=   3.7s
[CV] END activation=relu, alpha=0.020694295125886983, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=9.886621955712806e-05, solver=sgd; total time=  16.2s
[CV] END activation=tanh, alpha=0.0017043978740745578, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.002487149823956261, solver=lbfgs; total time=  24.1s
[CV] END activation=relu, alpha=0.01307841747189621, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.00021100754753174773, solver=lbfgs; total time=   3.6s
[CV] END activation=relu, alpha=0.01307841747189621, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.00021100754753174773, solver=lbfgs; total time=   3.7s
[CV] END activation=relu, alpha=0.005346790951645579, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=9.978478495350907e-05, solver=lbfgs; total time=   3.6s
[CV] END activation=tanh, alpha=0.0010426321989380738, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=8.193270299782198e-05, solver=adam; total time= 1.3min
[CV] END activation=relu, alpha=0.002826294183169559, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0028628605672649716, solver=sgd; total time= 1.3min
[CV] END activation=tanh, alpha=0.0035968138543403484, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0014444624222859897, solver=sgd; total time= 2.4min
[CV] END activation=tanh, alpha=0.003737566980308469, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0005198809649161125, solver=adam; total time=  10.1s
[CV] END activation=relu, alpha=0.012712674799885566, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0013466990181070474, solver=adam; total time=   8.0s
[CV] END activation=tanh, alpha=0.0003653997581792768, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.000518986183065717, solver=sgd; total time= 3.3min
[CV] END activation=relu, alpha=0.02085679076656689, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.001555623558805079, solver=adam; total time=   5.1s
[CV] END activation=relu, alpha=0.02443034181393512, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0027907824370611207, solver=adam; total time=   2.5s
[CV] END activation=tanh, alpha=0.01686595518849357, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0028352381429802907, solver=sgd; total time= 1.8min
[CV] END activation=relu, alpha=0.002012137518944648, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0001922087518038976, solver=lbfgs; total time=   3.9s
[CV] END activation=tanh, alpha=0.009128781650270956, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0007386457020040643, solver=adam; total time=  12.4s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
[CV] END activation=tanh, alpha=0.004314266555113575, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0008342203940123731, solver=sgd; total time= 2.1min
[CV] END activation=tanh, alpha=0.03709801493576339, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.00011898713435783809, solver=sgd; total time= 3.3min
[CV] END activation=tanh, alpha=0.013839209485258235, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00019162366430828279, solver=lbfgs; total time=  19.3s
[CV] END activation=relu, alpha=0.004893561353584806, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00025886653758705605, solver=lbfgs; total time=  11.4s
[CV] END activation=tanh, alpha=0.0014772879770590635, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0008728383537769557, solver=sgd; total time=  19.4s
[CV] END activation=tanh, alpha=0.0017692378956052405, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.002203712449513837, solver=lbfgs; total time=  10.4s
[CV] END activation=tanh, alpha=0.01326925603851573, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0019914522753652028, solver=lbfgs; total time=   4.2s
[CV] END activation=relu, alpha=0.0016794795247424977, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00041773175574660973, solver=sgd; total time= 3.0min
[CV] END activation=relu, alpha=0.012030488628279963, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=9.910498376000495e-05, solver=adam; total time=  50.8s
[CV] END activation=relu, alpha=0.011459812701486905, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0010690077084049951, solver=sgd; total time= 2.6min
[CV] END activation=relu, alpha=0.001649195239367829, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0008341559917230889, solver=sgd; total time= 2.4min
[CV] END activation=relu, alpha=0.03032215539417534, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0006987583149464913, solver=sgd; total time= 2.7min
[CV] END activation=tanh, alpha=0.00531083478323805, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.00033154288060074997, solver=sgd; total time=  41.8s
[CV] END activation=relu, alpha=0.01307841747189621, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.00021100754753174773, solver=lbfgs; total time=   3.7s
[CV] END activation=relu, alpha=0.005346790951645579, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=9.978478495350907e-05, solver=lbfgs; total time=   3.8s
[CV] END activation=relu, alpha=0.005346790951645579, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=9.978478495350907e-05, solver=lbfgs; total time=   3.7s
[CV] END activation=relu, alpha=0.0016224814726571823, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00017748079167499852, solver=sgd; total time= 1.9min
[CV] END activation=tanh, alpha=0.004308825614843536, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=3.5139944198528583e-06, solver=sgd; total time= 3.3min
[CV] END activation=relu, alpha=0.012712674799885566, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0013466990181070474, solver=adam; total time=   6.7s
[CV] END activation=relu, alpha=0.012383157826019169, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0010534990907275768, solver=adam; total time=  23.1s
[CV] END activation=tanh, alpha=0.035509808843687665, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=5.660222467059424e-05, solver=adam; total time=  47.0s
[CV] END activation=relu, alpha=0.006590809301041979, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0019178207198554652, solver=adam; total time=   7.8s
[CV] END activation=tanh, alpha=0.0045582562414226745, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0006360541867613539, solver=sgd; total time=  44.0s
[CV] END activation=relu, alpha=0.009211700508275468, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=8.209950891803041e-05, solver=sgd; total time= 3.1min
[CV] END activation=relu, alpha=0.002012137518944648, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0001922087518038976, solver=lbfgs; total time=   5.4s
[CV] END activation=relu, alpha=0.002012137518944648, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0001922087518038976, solver=lbfgs; total time=   2.4s
[CV] END activation=tanh, alpha=0.009128781650270956, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0007386457020040643, solver=adam; total time=  17.7s
[CV] END activation=relu, alpha=0.0135705912188281, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0019084030149652382, solver=adam; total time=  17.8s
[CV] END activation=relu, alpha=0.0005430798727826846, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.001263726668304321, solver=adam; total time=  15.3s
[CV] END activation=relu, alpha=0.0005430798727826846, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.001263726668304321, solver=adam; total time=  16.9s
[CV] END activation=tanh, alpha=0.013151072671937561, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00016358757271042114, solver=adam; total time=  39.4s
[CV] END activation=relu, alpha=0.000365186617883322, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.001558385829943651, solver=sgd; total time=  34.4s
[CV] END activation=tanh, alpha=0.008272225807520548, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0005710941503955697, solver=lbfgs; total time=   4.7s
[CV] END activation=tanh, alpha=0.008272225807520548, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0005710941503955697, solver=lbfgs; total time=   5.3s
[CV] END activation=relu, alpha=0.0073315675312570425, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0017900479776325653, solver=adam; total time=  25.4s
[CV] END activation=tanh, alpha=0.02689808118607203, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.00039608360177942044, solver=adam; total time=  33.7s
[CV] END activation=tanh, alpha=0.029903617444679988, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.00018889021392304466, solver=sgd; total time=  45.3s
[CV] END activation=tanh, alpha=0.003455438956345222, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.00038234099499285346, solver=adam; total time=  26.7s
[CV] END activation=tanh, alpha=0.004263146978630417, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00018751216770050095, solver=adam; total time=  32.6s
[CV] END activation=relu, alpha=0.013163272533584307, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0013354505522879426, solver=lbfgs; total time=  12.5s
[CV] END activation=tanh, alpha=0.009373683276020926, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0025490649693395233, solver=lbfgs; total time=   8.3s
[CV] END activation=tanh, alpha=0.009373683276020926, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0025490649693395233, solver=lbfgs; total time=   4.8s
[CV] END activation=tanh, alpha=0.03451555280713616, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=1.417345450773102e-06, solver=lbfgs; total time=  10.3s
[CV] END activation=tanh, alpha=0.007408621775912516, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00012756602309029966, solver=lbfgs; total time=  11.3s
[CV] END activation=relu, alpha=0.004398255758771709, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0006299821961708244, solver=lbfgs; total time=   3.8s
[CV] END activation=relu, alpha=0.004398255758771709, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0006299821961708244, solver=lbfgs; total time=   3.7s
[CV] END activation=tanh, alpha=0.00035411992512896314, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0007998654635219555, solver=sgd; total time=  19.9s
[CV] END activation=relu, alpha=0.03232468713509406, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=7.763761158384169e-05, solver=sgd; total time=  17.3s
[CV] END activation=tanh, alpha=0.010676646502545729, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0002410558780979127, solver=sgd; total time=  42.9s
[CV] END activation=tanh, alpha=0.0005055323202262127, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0006135798600591278, solver=adam; total time=  19.8s
[CV] END activation=tanh, alpha=0.005688404542236403, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0004172575257545049, solver=lbfgs; total time=   6.5s
[CV] END activation=tanh, alpha=0.005688404542236403, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0004172575257545049, solver=lbfgs; total time=   4.0s
[CV] END activation=tanh, alpha=0.005688404542236403, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0004172575257545049, solver=lbfgs; total time=   4.9s
[CV] END activation=relu, alpha=0.0075926410200179775, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.00045595918381241145, solver=adam; total time=  17.7s
[CV] END activation=relu, alpha=0.0075926410200179775, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.00045595918381241145, solver=adam; total time=  18.7s
[CV] END activation=relu, alpha=0.008643460725749038, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00021145170176783146, solver=lbfgs; total time=  21.0s
[CV] END activation=relu, alpha=0.03032215539417534, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0006987583149464913, solver=sgd; total time= 2.7min
[CV] END activation=relu, alpha=0.003280395322264669, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0002830374670878367, solver=lbfgs; total time=   7.0s
[CV] END activation=tanh, alpha=0.00531083478323805, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.00033154288060074997, solver=sgd; total time=  42.0s
[CV] END activation=relu, alpha=0.0014116051635769207, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00028887237259173624, solver=adam; total time=  30.3s
[CV] END activation=relu, alpha=0.009809718376308011, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.000377155568975184, solver=adam; total time=  15.7s
[CV] END activation=relu, alpha=0.009809718376308011, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.000377155568975184, solver=adam; total time=  19.0s
[CV] END activation=relu, alpha=0.020958513549687564, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.001169123636000803, solver=adam; total time=  30.6s
[CV] END activation=relu, alpha=0.002826294183169559, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0028628605672649716, solver=sgd; total time= 1.2min
[CV] END activation=tanh, alpha=0.015089732946722039, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0019871038879848216, solver=adam; total time=  36.6s
[CV] END activation=relu, alpha=0.009710284686664246, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00036926050227328644, solver=lbfgs; total time=  14.2s
[CV] END activation=relu, alpha=0.009710284686664246, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00036926050227328644, solver=lbfgs; total time=  11.1s
[CV] END activation=relu, alpha=0.009710284686664246, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00036926050227328644, solver=lbfgs; total time=  10.7s
[CV] END activation=tanh, alpha=0.03184563831753037, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.006297013700054798, solver=sgd; total time= 1.3min
[CV] END activation=tanh, alpha=0.0003653997581792768, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.000518986183065717, solver=sgd; total time= 3.4min
[CV] END activation=relu, alpha=0.02085679076656689, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.001555623558805079, solver=adam; total time=   5.1s
[CV] END activation=relu, alpha=0.02443034181393512, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0027907824370611207, solver=adam; total time=   1.4s
[CV] END activation=relu, alpha=0.02443034181393512, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0027907824370611207, solver=adam; total time=   2.7s
[CV] END activation=tanh, alpha=0.01686595518849357, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0028352381429802907, solver=sgd; total time= 1.6min
[CV] END activation=tanh, alpha=0.004837717739946474, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00012343589910738484, solver=sgd; total time= 2.2min
[CV] END activation=relu, alpha=0.010652972527178119, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.00010933822431743311, solver=sgd; total time=  17.1s
[CV] END activation=tanh, alpha=0.05042573667655309, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.003277879722670342, solver=sgd; total time=  19.5s
[CV] END activation=relu, alpha=0.0073315675312570425, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0017900479776325653, solver=adam; total time=  12.9s
[CV] END activation=relu, alpha=0.009893499728163611, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0002400648131189544, solver=sgd; total time= 3.1min
[CV] END activation=tanh, alpha=0.007408621775912516, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00012756602309029966, solver=lbfgs; total time=  11.6s
[CV] END activation=tanh, alpha=0.008482419056580787, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.002591571654266599, solver=adam; total time=  13.2s
[CV] END activation=tanh, alpha=0.008482419056580787, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.002591571654266599, solver=adam; total time=  17.0s
[CV] END activation=tanh, alpha=0.0015757301476452144, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.001554624909186802, solver=sgd; total time=  19.6s
[CV] END activation=tanh, alpha=0.0010074300351711476, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=1.8716267528293404e-05, solver=adam; total time=  20.4s
[CV] END activation=tanh, alpha=0.011223614507810533, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=2.5016258145243844e-05, solver=lbfgs; total time=   3.4s
[CV] END activation=tanh, alpha=0.011223614507810533, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=2.5016258145243844e-05, solver=lbfgs; total time=   6.0s
[CV] END activation=relu, alpha=0.006826376879431906, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00042699261149140483, solver=adam; total time=   9.9s
[CV] END activation=relu, alpha=0.012285875587929467, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0004931463012639382, solver=lbfgs; total time=  11.4s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.
  warnings.warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END activation=tanh, alpha=0.015201538674731218, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0007422626202064951, solver=adam; total time=  22.6s
[CV] END activation=tanh, alpha=0.015201538674731218, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0007422626202064951, solver=adam; total time=  38.7s
[CV] END activation=relu, alpha=0.004345874218315455, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0011654652774007422, solver=adam; total time=   8.5s
[CV] END activation=tanh, alpha=0.011379930262320382, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0014216585267720408, solver=sgd; total time=  19.9s
[CV] END activation=tanh, alpha=0.011379930262320382, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0014216585267720408, solver=sgd; total time=  19.9s
[CV] END activation=relu, alpha=0.0009725540159183265, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0007742310137900608, solver=sgd; total time=  39.2s
[CV] END activation=relu, alpha=0.020694295125886983, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=9.886621955712806e-05, solver=sgd; total time=  16.2s
[CV] END activation=relu, alpha=0.014647617791209646, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00039019222872556223, solver=lbfgs; total time=  10.0s
[CV] END activation=relu, alpha=0.0018520864887919904, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0009348067612650253, solver=lbfgs; total time=  11.8s
[CV] END activation=relu, alpha=0.0037442361263322183, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0005585456033882345, solver=sgd; total time=  16.5s
[CV] END activation=tanh, alpha=0.0010426321989380738, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=8.193270299782198e-05, solver=adam; total time=  49.3s
[CV] END activation=relu, alpha=0.020958513549687564, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.001169123636000803, solver=adam; total time=  22.4s
[CV] END activation=relu, alpha=0.0006557991005071255, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0024827515266302525, solver=sgd; total time=  36.7s
[CV] END activation=tanh, alpha=0.004308825614843536, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=3.5139944198528583e-06, solver=sgd; total time= 3.4min
[CV] END activation=tanh, alpha=0.013247036447151098, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0008303658312294666, solver=sgd; total time=  20.1s
[CV] END activation=tanh, alpha=0.035509808843687665, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=5.660222467059424e-05, solver=adam; total time=  48.4s
[CV] END activation=tanh, alpha=0.005605943550886013, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=9.886541957780663e-05, solver=adam; total time=  48.3s
[CV] END activation=tanh, alpha=0.004475261733324155, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00020315836541804489, solver=lbfgs; total time=  10.7s
[CV] END activation=relu, alpha=0.009211700508275468, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=8.209950891803041e-05, solver=sgd; total time= 3.1min
[CV] END activation=tanh, alpha=0.004837717739946474, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00012343589910738484, solver=sgd; total time= 2.2min
[CV] END activation=relu, alpha=0.010652972527178119, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.00010933822431743311, solver=sgd; total time=  16.7s
[CV] END activation=tanh, alpha=0.05042573667655309, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.003277879722670342, solver=sgd; total time=  19.6s
[CV] END activation=relu, alpha=0.022610721827004073, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00011007396232976442, solver=lbfgs; total time=  10.9s
[CV] END activation=relu, alpha=0.022610721827004073, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00011007396232976442, solver=lbfgs; total time=  12.1s
[CV] END activation=relu, alpha=0.009152880983353023, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0005250032611643587, solver=lbfgs; total time=   7.8s
[CV] END activation=tanh, alpha=0.0040876114059029516, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0006780459681086023, solver=lbfgs; total time=  10.7s
[CV] END activation=tanh, alpha=0.0040876114059029516, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0006780459681086023, solver=lbfgs; total time=  10.8s
[CV] END activation=tanh, alpha=0.029903617444679988, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.00018889021392304466, solver=sgd; total time=  44.4s
[CV] END activation=tanh, alpha=0.008694697460115437, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0014269464217349947, solver=lbfgs; total time=   5.6s
[CV] END activation=tanh, alpha=0.004263146978630417, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00018751216770050095, solver=adam; total time=  26.8s
[CV] END activation=relu, alpha=1.3897665898231244e-05, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00013635197771472312, solver=sgd; total time= 1.9min
[CV] END activation=tanh, alpha=0.0067612420653492935, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00181837566657909, solver=lbfgs; total time=  10.5s
[CV] END activation=tanh, alpha=0.0010074300351711476, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=1.8716267528293404e-05, solver=adam; total time=  20.6s
[CV] END activation=tanh, alpha=0.015701397917944792, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0004119074262291583, solver=adam; total time=  22.8s
[CV] END activation=tanh, alpha=0.0358504461969663, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0004162523587551446, solver=lbfgs; total time=  21.8s
[CV] END activation=tanh, alpha=0.008655456458271725, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.001737839057171741, solver=lbfgs; total time=   8.2s
[CV] END activation=relu, alpha=0.0163235253191956, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0003638703941187086, solver=lbfgs; total time=   4.3s
[CV] END activation=relu, alpha=0.01470309088085526, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.002200831635641371, solver=lbfgs; total time=  13.1s
[CV] END activation=tanh, alpha=0.017010257093530778, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00156820410748025, solver=sgd; total time= 1.7min
[CV] END ................class_weight=balanced, solver=lbfgs; total time=   0.4s
[CV] END ..................class_weight=balanced, solver=sag; total time=  35.6s
[CV] END .....................class_weight=None, solver=saga; total time=  46.7s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=1420, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=320, warm_start=True; total time=   0.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=6, n_estimators=1020, warm_start=True; total time=   0.0s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END activation=relu, alpha=0.0014116051635769207, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00028887237259173624, solver=adam; total time=  33.3s
[CV] END activation=relu, alpha=0.009809718376308011, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.000377155568975184, solver=adam; total time=  27.2s
[CV] END activation=relu, alpha=0.020958513549687564, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.001169123636000803, solver=adam; total time=  17.3s
[CV] END activation=relu, alpha=0.0006557991005071255, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0024827515266302525, solver=sgd; total time=  38.4s
[CV] END activation=relu, alpha=0.002826294183169559, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0028628605672649716, solver=sgd; total time= 1.0min
[CV] END activation=tanh, alpha=0.015089732946722039, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0019871038879848216, solver=adam; total time=  24.4s
[CV] END activation=tanh, alpha=0.015089732946722039, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0019871038879848216, solver=adam; total time=  30.8s
[CV] END activation=tanh, alpha=0.03184563831753037, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.006297013700054798, solver=sgd; total time= 1.3min
[CV] END activation=tanh, alpha=0.003737566980308469, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0005198809649161125, solver=adam; total time=   8.3s
[CV] END activation=relu, alpha=0.012712674799885566, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0013466990181070474, solver=adam; total time=   5.7s
[CV] END activation=tanh, alpha=0.0003653997581792768, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.000518986183065717, solver=sgd; total time= 3.3min
[CV] END activation=relu, alpha=0.02085679076656689, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.001555623558805079, solver=adam; total time=   6.8s
[CV] END activation=tanh, alpha=0.01686595518849357, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0028352381429802907, solver=sgd; total time= 1.5min
[CV] END activation=tanh, alpha=0.0032612878400729703, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0009553995630157866, solver=sgd; total time= 2.1min
[CV] END activation=relu, alpha=0.000365186617883322, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.001558385829943651, solver=sgd; total time=  38.4s
[CV] END activation=tanh, alpha=0.008272225807520548, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0005710941503955697, solver=lbfgs; total time=   4.2s
[CV] END activation=relu, alpha=0.0073315675312570425, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0017900479776325653, solver=adam; total time=  31.2s
[CV] END activation=relu, alpha=0.009152880983353023, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0005250032611643587, solver=lbfgs; total time=   4.2s
[CV] END activation=relu, alpha=0.009152880983353023, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0005250032611643587, solver=lbfgs; total time=   3.3s
[CV] END activation=tanh, alpha=0.0040876114059029516, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0006780459681086023, solver=lbfgs; total time=  10.6s
[CV] END activation=relu, alpha=0.006821539805775346, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00137715259067505, solver=lbfgs; total time=   4.4s
[CV] END activation=relu, alpha=0.04397943613410018, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0013731209588906063, solver=lbfgs; total time=   4.9s
[CV] END activation=tanh, alpha=0.0194199742058601, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00010949242141051187, solver=lbfgs; total time=  11.5s
[CV] END activation=tanh, alpha=0.0026101821980966202, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0014181773893908265, solver=lbfgs; total time=  23.3s
[CV] END activation=tanh, alpha=0.0026101821980966202, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0014181773893908265, solver=lbfgs; total time=  20.7s
[CV] END activation=tanh, alpha=0.004263146978630417, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00018751216770050095, solver=adam; total time=  27.5s
[CV] END activation=relu, alpha=0.0015961092837880352, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0008510118760550091, solver=lbfgs; total time=   3.8s
[CV] END activation=relu, alpha=0.0015961092837880352, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0008510118760550091, solver=lbfgs; total time=   3.1s
[CV] END activation=relu, alpha=0.0015961092837880352, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0008510118760550091, solver=lbfgs; total time=   3.6s
[CV] END activation=relu, alpha=0.013163272533584307, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0013354505522879426, solver=lbfgs; total time=  12.2s
[CV] END activation=relu, alpha=0.013163272533584307, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0013354505522879426, solver=lbfgs; total time=  10.5s
[CV] END activation=tanh, alpha=0.009373683276020926, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0025490649693395233, solver=lbfgs; total time=   8.3s
[CV] END activation=tanh, alpha=0.03451555280713616, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=1.417345450773102e-06, solver=lbfgs; total time=  10.9s
[CV] END activation=tanh, alpha=0.03451555280713616, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=1.417345450773102e-06, solver=lbfgs; total time=  10.8s
[CV] END activation=relu, alpha=0.007287393780120881, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0009298667853960402, solver=sgd; total time= 1.5min
[CV] END activation=tanh, alpha=0.010686204477020568, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0006382203112566692, solver=lbfgs; total time=  10.4s
[CV] END activation=relu, alpha=0.012285875587929467, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0004931463012639382, solver=lbfgs; total time=  11.4s
[CV] END activation=tanh, alpha=0.0007192018608722902, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.00022798554585164036, solver=lbfgs; total time=  23.0s
[CV] END activation=relu, alpha=0.01470309088085526, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.002200831635641371, solver=lbfgs; total time=  11.6s
[CV] END activation=tanh, alpha=0.017010257093530778, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00156820410748025, solver=sgd; total time= 1.8min
[CV] END ............class_weight=balanced, solver=liblinear; total time=   2.6s
[CV] END ................class_weight=None, solver=newton-cg; total time=   0.4s
[CV] END ................class_weight=None, solver=newton-cg; total time=   0.3s
[CV] END ....................class_weight=None, solver=lbfgs; total time=   0.2s
[CV] END ................class_weight=None, solver=liblinear; total time=   1.5s
[CV] END ................class_weight=None, solver=liblinear; total time=   1.5s
[CV] END ......................class_weight=None, solver=sag; total time=  36.6s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END activation=relu, alpha=0.0037442361263322183, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0005585456033882345, solver=sgd; total time=  16.6s
[CV] END activation=tanh, alpha=0.0010426321989380738, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=8.193270299782198e-05, solver=adam; total time= 1.2min
[CV] END activation=relu, alpha=0.0006557991005071255, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0024827515266302525, solver=sgd; total time=  39.1s
[CV] END activation=tanh, alpha=0.004308825614843536, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=3.5139944198528583e-06, solver=sgd; total time= 3.3min
[CV] END activation=tanh, alpha=0.013247036447151098, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0008303658312294666, solver=sgd; total time=  19.4s
[CV] END activation=relu, alpha=0.012383157826019169, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0010534990907275768, solver=adam; total time=  21.7s
[CV] END activation=tanh, alpha=0.005605943550886013, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=9.886541957780663e-05, solver=adam; total time=  52.6s
[CV] END activation=tanh, alpha=0.0045582562414226745, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0006360541867613539, solver=sgd; total time=  44.6s
[CV] END activation=relu, alpha=0.01361667815273821, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.001928075488880787, solver=lbfgs; total time=  17.4s
[CV] END activation=tanh, alpha=0.0273445602149093, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0002953265750781805, solver=sgd; total time=  43.5s
[CV] END activation=tanh, alpha=0.0273445602149093, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0002953265750781805, solver=sgd; total time=  42.3s
[CV] END activation=tanh, alpha=0.0032612878400729703, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0009553995630157866, solver=sgd; total time= 2.1min
[CV] END activation=relu, alpha=0.0005430798727826846, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.001263726668304321, solver=adam; total time=  22.2s
[CV] END activation=tanh, alpha=0.006231775736839036, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0009217682454187809, solver=lbfgs; total time=  10.3s
[CV] END activation=relu, alpha=0.000365186617883322, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.001558385829943651, solver=sgd; total time=  39.8s
[CV] END activation=tanh, alpha=0.002408086524933565, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0013161311695496795, solver=lbfgs; total time=   3.1s
[CV] END activation=tanh, alpha=0.003069656523539295, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00022670742142738803, solver=adam; total time=  12.2s
[CV] END activation=tanh, alpha=0.0007523634470581774, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0008416822355054652, solver=sgd; total time=  41.3s
[CV] END activation=relu, alpha=0.009893499728163611, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0002400648131189544, solver=sgd; total time= 3.1min
[CV] END activation=tanh, alpha=0.007408621775912516, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00012756602309029966, solver=lbfgs; total time=  10.8s
[CV] END activation=tanh, alpha=0.008482419056580787, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.002591571654266599, solver=adam; total time=  17.8s
[CV] END activation=tanh, alpha=0.002505536415482663, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0011931143045786534, solver=lbfgs; total time=   5.0s
[CV] END activation=tanh, alpha=0.002505536415482663, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0011931143045786534, solver=lbfgs; total time=   3.6s
[CV] END activation=tanh, alpha=0.002505536415482663, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0011931143045786534, solver=lbfgs; total time=   4.4s
[CV] END activation=tanh, alpha=0.0015757301476452144, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.001554624909186802, solver=sgd; total time=  19.9s
[CV] END activation=tanh, alpha=0.015701397917944792, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0004119074262291583, solver=adam; total time=  27.6s
[CV] END activation=tanh, alpha=0.010686204477020568, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0006382203112566692, solver=lbfgs; total time=   9.6s
[CV] END activation=tanh, alpha=0.0358504461969663, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0004162523587551446, solver=lbfgs; total time=  20.8s
[CV] END activation=relu, alpha=0.008019202956203066, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0003777057083914414, solver=lbfgs; total time=  11.5s
[CV] END activation=relu, alpha=0.0163235253191956, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0003638703941187086, solver=lbfgs; total time=   3.7s
[CV] END activation=relu, alpha=0.032837102384606874, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0005112910931291703, solver=sgd; total time=  40.5s
[CV] END activation=tanh, alpha=0.0006147070761170282, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.00023802156894466795, solver=adam; total time=  27.7s
[CV] END ................class_weight=balanced, solver=lbfgs; total time=   0.4s
[CV] END ............class_weight=balanced, solver=liblinear; total time=   2.3s
[CV] END ................class_weight=None, solver=newton-cg; total time=   0.3s
[CV] END ....................class_weight=None, solver=lbfgs; total time=   0.2s
[CV] END ....................class_weight=None, solver=lbfgs; total time=   0.2s
[CV] END ................class_weight=None, solver=liblinear; total time=   2.0s
[CV] END ......................class_weight=None, solver=sag; total time=  35.0s
[CV] END .....................class_weight=None, solver=saga; total time=  49.2s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=320, warm_start=True; total time=   0.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=6, n_estimators=1020, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=6, n_estimators=1020, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1520, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=820, warm_start=False; total time=   1.8s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=420, warm_start=False; total time=   1.1s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=420, warm_start=False; total time=   1.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1020, warm_start=True; total time=   3.1s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END activation=relu, alpha=0.0016224814726571823, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00017748079167499852, solver=sgd; total time= 1.9min
[CV] END activation=tanh, alpha=0.0035968138543403484, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0014444624222859897, solver=sgd; total time= 2.8min
[CV] END activation=tanh, alpha=0.003737566980308469, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0005198809649161125, solver=adam; total time=   8.1s
[CV] END activation=tanh, alpha=0.013247036447151098, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0008303658312294666, solver=sgd; total time=  19.2s
[CV] END activation=relu, alpha=0.012383157826019169, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0010534990907275768, solver=adam; total time=  13.0s
[CV] END activation=tanh, alpha=0.035509808843687665, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=5.660222467059424e-05, solver=adam; total time=  47.5s
[CV] END activation=relu, alpha=0.006590809301041979, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0019178207198554652, solver=adam; total time=   8.7s
[CV] END activation=relu, alpha=0.006590809301041979, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0019178207198554652, solver=adam; total time=  14.6s
[CV] END activation=tanh, alpha=0.004475261733324155, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00020315836541804489, solver=lbfgs; total time=  12.7s
[CV] END activation=tanh, alpha=0.004475261733324155, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00020315836541804489, solver=lbfgs; total time=  11.5s
[CV] END activation=relu, alpha=0.009211700508275468, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=8.209950891803041e-05, solver=sgd; total time= 3.1min
[CV] END activation=tanh, alpha=0.004837717739946474, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00012343589910738484, solver=sgd; total time= 2.2min
[CV] END activation=tanh, alpha=0.003069656523539295, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00022670742142738803, solver=adam; total time=  13.2s
[CV] END activation=tanh, alpha=0.0007523634470581774, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0008416822355054652, solver=sgd; total time=  41.9s
[CV] END activation=tanh, alpha=0.02689808118607203, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.00039608360177942044, solver=adam; total time=  33.3s
[CV] END activation=relu, alpha=0.04397943613410018, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0013731209588906063, solver=lbfgs; total time=   3.1s
[CV] END activation=tanh, alpha=0.029903617444679988, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.00018889021392304466, solver=sgd; total time=  44.9s
[CV] END activation=tanh, alpha=0.008694697460115437, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0014269464217349947, solver=lbfgs; total time=   3.7s
[CV] END activation=tanh, alpha=0.003455438956345222, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.00038234099499285346, solver=adam; total time=  27.6s
[CV] END activation=relu, alpha=1.3897665898231244e-05, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00013635197771472312, solver=sgd; total time= 1.9min
[CV] END activation=tanh, alpha=0.0067612420653492935, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00181837566657909, solver=lbfgs; total time=  10.4s
[CV] END activation=tanh, alpha=0.0067612420653492935, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00181837566657909, solver=lbfgs; total time=  10.9s
[CV] END activation=tanh, alpha=0.015701397917944792, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0004119074262291583, solver=adam; total time=  33.2s
[CV] END activation=relu, alpha=0.012285875587929467, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.0004931463012639382, solver=lbfgs; total time=  12.9s
[CV] END activation=relu, alpha=0.008019202956203066, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0003777057083914414, solver=lbfgs; total time=  11.7s
[CV] END activation=tanh, alpha=0.008655456458271725, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.001737839057171741, solver=lbfgs; total time=   5.0s
[CV] END activation=tanh, alpha=0.005711253890048242, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00024483376500486633, solver=sgd; total time=  20.8s
[CV] END activation=tanh, alpha=0.011151863292735027, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.00012401700685061947, solver=lbfgs; total time=   3.0s
[CV] END activation=tanh, alpha=0.0006147070761170282, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.00023802156894466795, solver=adam; total time=  30.7s
[CV] END ............class_weight=balanced, solver=newton-cg; total time=   0.8s
[CV] END .................class_weight=balanced, solver=saga; total time=  49.3s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=920, warm_start=True; total time=   4.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1920, warm_start=False; total time=   4.4s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1920, warm_start=False; total time=   4.3s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1120, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1120, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1120, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=4, n_estimators=1120, warm_start=False; total time=   4.3s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1920, warm_start=False; total time=   3.5s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1320, warm_start=False; total time=   3.5s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=1920, warm_start=True; total time=   4.3s
[CV] END activation=tanh, alpha=0.03184563831753037, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.006297013700054798, solver=sgd; total time=  57.8s
[CV] END activation=tanh, alpha=0.005605943550886013, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=9.886541957780663e-05, solver=adam; total time=  44.5s
[CV] END activation=tanh, alpha=0.0045582562414226745, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0006360541867613539, solver=sgd; total time=  44.2s
[CV] END activation=relu, alpha=0.01361667815273821, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.001928075488880787, solver=lbfgs; total time=  22.1s
[CV] END activation=relu, alpha=0.01361667815273821, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.001928075488880787, solver=lbfgs; total time=  20.6s
[CV] END activation=tanh, alpha=0.0273445602149093, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0002953265750781805, solver=sgd; total time=  43.7s
[CV] END activation=tanh, alpha=0.0032612878400729703, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0009553995630157866, solver=sgd; total time= 2.2min
[CV] END activation=relu, alpha=0.0135705912188281, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0019084030149652382, solver=adam; total time=  24.9s
[CV] END activation=tanh, alpha=0.015857743152281407, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0011595403531365778, solver=lbfgs; total time=   4.5s
[CV] END activation=tanh, alpha=0.006231775736839036, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0009217682454187809, solver=lbfgs; total time=  12.3s
[CV] END activation=tanh, alpha=0.013151072671937561, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00016358757271042114, solver=adam; total time=  42.6s
[CV] END activation=tanh, alpha=0.002408086524933565, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0013161311695496795, solver=lbfgs; total time=   5.3s
[CV] END activation=tanh, alpha=0.003069656523539295, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00022670742142738803, solver=adam; total time=  16.5s
[CV] END activation=tanh, alpha=0.0007523634470581774, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.0008416822355054652, solver=sgd; total time=  41.1s
[CV] END activation=tanh, alpha=0.02689808118607203, hidden_layer_sizes=(257,), learning_rate=constant, learning_rate_init=0.00039608360177942044, solver=adam; total time=  22.5s
[CV] END activation=relu, alpha=0.006821539805775346, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00137715259067505, solver=lbfgs; total time=   5.9s
[CV] END activation=relu, alpha=0.006821539805775346, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00137715259067505, solver=lbfgs; total time=   2.9s
[CV] END activation=relu, alpha=0.04397943613410018, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0013731209588906063, solver=lbfgs; total time=   3.1s
[CV] END activation=tanh, alpha=0.0194199742058601, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00010949242141051187, solver=lbfgs; total time=  10.7s
[CV] END activation=tanh, alpha=0.0194199742058601, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00010949242141051187, solver=lbfgs; total time=  11.2s
[CV] END activation=tanh, alpha=0.0026101821980966202, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0014181773893908265, solver=lbfgs; total time=  20.6s
[CV] END activation=tanh, alpha=0.008694697460115437, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0014269464217349947, solver=lbfgs; total time=   4.7s
[CV] END activation=tanh, alpha=0.003455438956345222, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.00038234099499285346, solver=adam; total time=  23.6s
[CV] END activation=relu, alpha=1.3897665898231244e-05, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00013635197771472312, solver=sgd; total time= 1.9min
[CV] END activation=tanh, alpha=0.0015757301476452144, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.001554624909186802, solver=sgd; total time=  20.1s
[CV] END activation=tanh, alpha=0.0010074300351711476, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=1.8716267528293404e-05, solver=adam; total time=  20.8s
[CV] END activation=tanh, alpha=0.011223614507810533, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=2.5016258145243844e-05, solver=lbfgs; total time=   4.4s
[CV] END activation=tanh, alpha=0.010686204477020568, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0006382203112566692, solver=lbfgs; total time=  10.3s
[CV] END activation=tanh, alpha=0.0358504461969663, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.0004162523587551446, solver=lbfgs; total time=  22.5s
[CV] END activation=relu, alpha=0.008019202956203066, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0003777057083914414, solver=lbfgs; total time=  14.8s
[CV] END activation=relu, alpha=0.01470309088085526, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.002200831635641371, solver=lbfgs; total time=  12.4s
[CV] END activation=tanh, alpha=0.017010257093530778, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00156820410748025, solver=sgd; total time= 1.9min
[CV] END ............class_weight=balanced, solver=liblinear; total time=   2.0s
[CV] END .................class_weight=balanced, solver=saga; total time=  47.8s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=920, warm_start=True; total time=   3.9s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1920, warm_start=False; total time=   4.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1620, warm_start=False; total time=   3.3s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=1720, warm_start=True; total time=   3.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=1820, warm_start=False; total time=   4.4s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=720, warm_start=False; total time=   1.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1320, warm_start=False; total time=   3.4s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=4, n_estimators=220, warm_start=False; total time=   0.8s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=720, warm_start=False; total time=   1.8s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=520, warm_start=False; total time=   1.6s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END activation=relu, alpha=0.007287393780120881, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0009298667853960402, solver=sgd; total time= 1.5min
[CV] END activation=relu, alpha=0.006826376879431906, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00042699261149140483, solver=adam; total time=  25.9s
[CV] END activation=tanh, alpha=0.008655456458271725, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.001737839057171741, solver=lbfgs; total time=   4.5s
[CV] END activation=tanh, alpha=0.005711253890048242, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00024483376500486633, solver=sgd; total time=  21.5s
[CV] END activation=tanh, alpha=0.011151863292735027, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.00012401700685061947, solver=lbfgs; total time=   3.1s
[CV] END activation=tanh, alpha=0.011151863292735027, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.00012401700685061947, solver=lbfgs; total time=   3.3s
[CV] END activation=tanh, alpha=0.0006147070761170282, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.00023802156894466795, solver=adam; total time=  26.6s
[CV] END ............class_weight=balanced, solver=newton-cg; total time=   0.6s
[CV] END ..................class_weight=balanced, solver=sag; total time=  32.7s
[CV] END ......................class_weight=None, solver=sag; total time=  31.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=1420, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=820, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=820, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=4, n_estimators=1020, warm_start=True; total time=   2.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=4, n_estimators=1520, warm_start=True; total time=   3.8s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=4, n_estimators=1520, warm_start=True; total time=   4.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=1520, warm_start=True; total time=   3.2s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=1520, warm_start=True; total time=   3.5s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1920, warm_start=False; total time=   3.5s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1020, warm_start=False; total time=   2.6s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=720, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=220, warm_start=False; total time=   0.5s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=520, warm_start=False; total time=   1.5s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=4, n_estimators=220, warm_start=False; total time=   0.8s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=720, warm_start=False; total time=   1.9s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=520, warm_start=False; total time=   1.6s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1120, warm_start=False; total time=   2.6s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=1520, warm_start=True; total time=   3.5s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=520, warm_start=False; total time=   1.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=4, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=4, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=4, n_estimators=1420, warm_start=False; total time=   0.0s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END activation=tanh, alpha=0.0007192018608722902, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.00022798554585164036, solver=lbfgs; total time=  20.3s
[CV] END activation=relu, alpha=0.0163235253191956, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0003638703941187086, solver=lbfgs; total time=   3.6s
[CV] END activation=relu, alpha=0.032837102384606874, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0005112910931291703, solver=sgd; total time=  40.4s
[CV] END ............class_weight=balanced, solver=newton-cg; total time=   0.7s
[CV] END .................class_weight=balanced, solver=saga; total time=  51.5s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=1420, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=820, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=4, n_estimators=1020, warm_start=True; total time=   2.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=4, n_estimators=1520, warm_start=True; total time=   3.9s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=420, warm_start=False; total time=   1.1s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=320, warm_start=False; total time=   0.8s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=320, warm_start=False; total time=   0.9s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=320, warm_start=False; total time=   0.8s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=1520, warm_start=True; total time=   3.2s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=4, n_estimators=1120, warm_start=False; total time=   4.2s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=1820, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=1820, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=1820, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=720, warm_start=False; total time=   1.8s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=1220, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=1220, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=1220, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=720, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=720, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=720, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=1220, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=1220, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=1220, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=120, warm_start=True; total time=   0.4s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1020, warm_start=True; total time=   3.8s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=520, warm_start=False; total time=   1.5s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=4, n_estimators=220, warm_start=False; total time=   0.8s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1420, warm_start=True; total time=   4.4s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=320, warm_start=True; total time=   0.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=1520, warm_start=True; total time=   3.6s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=1320, warm_start=True; total time=   4.4s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=320, warm_start=True; total time=   0.7s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=4, n_estimators=120, warm_start=True; total time=   0.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=920, warm_start=False; total time=   2.4s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1420, warm_start=False; total time=   3.6s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=4, n_estimators=720, warm_start=True; total time=   1.9s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=4, n_estimators=720, warm_start=True; total time=   1.9s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=920, warm_start=False; total time=   0.0s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END activation=tanh, alpha=0.009128781650270956, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0007386457020040643, solver=adam; total time=  15.9s
[CV] END activation=relu, alpha=0.0135705912188281, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0019084030149652382, solver=adam; total time=  22.3s
[CV] END activation=tanh, alpha=0.015857743152281407, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0011595403531365778, solver=lbfgs; total time=   3.8s
[CV] END activation=tanh, alpha=0.015857743152281407, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.0011595403531365778, solver=lbfgs; total time=   4.3s
[CV] END activation=tanh, alpha=0.006231775736839036, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0009217682454187809, solver=lbfgs; total time=  11.1s
[CV] END activation=tanh, alpha=0.013151072671937561, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.00016358757271042114, solver=adam; total time=  46.0s
[CV] END activation=tanh, alpha=0.002408086524933565, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.0013161311695496795, solver=lbfgs; total time=   4.5s
[CV] END activation=relu, alpha=0.010652972527178119, hidden_layer_sizes=(11, 244), learning_rate=constant, learning_rate_init=0.00010933822431743311, solver=sgd; total time=  17.2s
[CV] END activation=tanh, alpha=0.05042573667655309, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.003277879722670342, solver=sgd; total time=  19.5s
[CV] END activation=relu, alpha=0.022610721827004073, hidden_layer_sizes=(454, 80, 482), learning_rate=adaptive, learning_rate_init=0.00011007396232976442, solver=lbfgs; total time=  11.1s
[CV] END activation=relu, alpha=0.009893499728163611, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=adaptive, learning_rate_init=0.0002400648131189544, solver=sgd; total time= 3.1min
[CV] END activation=relu, alpha=0.007287393780120881, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.0009298667853960402, solver=sgd; total time= 1.5min
[CV] END activation=relu, alpha=0.006826376879431906, hidden_layer_sizes=(454, 80, 482), learning_rate=constant, learning_rate_init=0.00042699261149140483, solver=adam; total time=  12.0s
[CV] END activation=tanh, alpha=0.0007192018608722902, hidden_layer_sizes=(136, 443, 406, 145), learning_rate=constant, learning_rate_init=0.00022798554585164036, solver=lbfgs; total time=  22.4s
[CV] END activation=tanh, alpha=0.005711253890048242, hidden_layer_sizes=(11, 244), learning_rate=adaptive, learning_rate_init=0.00024483376500486633, solver=sgd; total time=  20.4s
[CV] END activation=relu, alpha=0.032837102384606874, hidden_layer_sizes=(257,), learning_rate=adaptive, learning_rate_init=0.0005112910931291703, solver=sgd; total time=  39.0s
[CV] END ................class_weight=balanced, solver=lbfgs; total time=   0.5s
[CV] END ..................class_weight=balanced, solver=sag; total time=  40.4s
[CV] END .....................class_weight=None, solver=saga; total time=  49.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=320, warm_start=True; total time=   0.8s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=4, n_estimators=1020, warm_start=True; total time=   2.1s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1920, warm_start=False; total time=   4.3s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1920, warm_start=False; total time=   4.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=1520, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=1520, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=1520, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=1720, warm_start=True; total time=   3.4s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=1820, warm_start=False; total time=   4.6s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=120, warm_start=True; total time=   0.4s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1020, warm_start=False; total time=   2.6s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1320, warm_start=False; total time=   3.4s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1420, warm_start=True; total time=   4.5s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=4, n_estimators=1520, warm_start=False; total time=   4.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=1320, warm_start=True; total time=   4.4s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=320, warm_start=True; total time=   0.8s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=920, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=920, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=920, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=4, n_estimators=120, warm_start=True; total time=   0.3s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=4, n_estimators=120, warm_start=True; total time=   0.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=920, warm_start=False; total time=   2.5s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1820, warm_start=True; total time=   7.9s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1120, warm_start=False; total time=   2.1s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=1820, warm_start=False; total time=   4.3s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=920, warm_start=True; total time=   4.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1620, warm_start=False; total time=   3.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1620, warm_start=False; total time=   3.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=20, warm_start=False; total time=   0.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=20, warm_start=False; total time=   0.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=20, warm_start=False; total time=   0.1s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=4, n_estimators=1220, warm_start=False; total time=   2.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=4, n_estimators=1120, warm_start=False; total time=   4.3s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=720, warm_start=False; total time=   1.8s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=120, warm_start=True; total time=   0.4s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1020, warm_start=True; total time=   3.7s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=1920, warm_start=True; total time=   4.3s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=520, warm_start=False; total time=   1.6s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1120, warm_start=False; total time=   2.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=320, warm_start=True; total time=   1.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=1320, warm_start=False; total time=   4.9s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=1520, warm_start=True; total time=   4.4s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1420, warm_start=False; total time=   3.5s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=4, n_estimators=720, warm_start=True; total time=   1.8s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=720, warm_start=True; total time=   2.8s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1120, warm_start=False; total time=   2.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=320, warm_start=True; total time=   1.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=320, warm_start=True; total time=   1.1s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=820, warm_start=False; total time=   2.6s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=8, n_estimators=1420, warm_start=True; total time=   3.3s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=720, warm_start=True; total time=   1.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=1720, warm_start=False; total time=   5.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=20, warm_start=True; total time=   0.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=20, warm_start=True; total time=   0.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=20, warm_start=True; total time=   0.1s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=620, warm_start=False; total time=   1.9s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=420, warm_start=False; total time=   1.1s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1520, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1520, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=820, warm_start=False; total time=   1.8s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=820, warm_start=False; total time=   1.8s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1920, warm_start=False; total time=   4.4s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1020, warm_start=True; total time=   3.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=1720, warm_start=True; total time=   3.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=1820, warm_start=False; total time=   4.5s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1020, warm_start=True; total time=   3.7s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=520, warm_start=False; total time=   1.6s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=720, warm_start=False; total time=   1.8s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1420, warm_start=True; total time=   4.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=1520, warm_start=True; total time=   3.6s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=520, warm_start=False; total time=   1.2s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=520, warm_start=False; total time=   1.2s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=1520, warm_start=True; total time=   4.7s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1420, warm_start=False; total time=   3.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=1220, warm_start=True; total time=   4.4s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=1620, warm_start=False; total time=   5.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=820, warm_start=False; total time=   2.7s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=20, warm_start=True; total time=   0.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=20, warm_start=True; total time=   0.1s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=1520, warm_start=False; total time=   3.8s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=720, warm_start=True; total time=   1.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=320, warm_start=False; total time=   1.2s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1720, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1720, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1720, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1620, warm_start=False; total time=   3.6s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=620, warm_start=False; total time=   1.8s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=420, warm_start=False; total time=   0.8s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=1320, warm_start=True; total time=   3.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=420, warm_start=False; total time=   1.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=20, warm_start=False; total time=   0.0s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1020, warm_start=True; total time=   3.2s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=4, n_estimators=1220, warm_start=False; total time=   2.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=4, n_estimators=1220, warm_start=False; total time=   2.8s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1020, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1020, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1020, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1920, warm_start=False; total time=   3.5s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1020, warm_start=False; total time=   2.6s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=720, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=720, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=220, warm_start=False; total time=   0.5s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=220, warm_start=False; total time=   0.4s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=1920, warm_start=True; total time=   4.3s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=320, warm_start=True; total time=   1.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1120, warm_start=False; total time=   2.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=320, warm_start=True; total time=   1.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=320, warm_start=True; total time=   1.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=1320, warm_start=False; total time=   5.1s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1720, warm_start=True; total time=   4.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1820, warm_start=True; total time=   7.8s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1120, warm_start=False; total time=   2.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=320, warm_start=True; total time=   1.1s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=120, warm_start=False; total time=   0.4s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=120, warm_start=False; total time=   0.4s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=120, warm_start=False; total time=   0.3s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=1120, warm_start=True; total time=   4.3s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=320, warm_start=False; total time=   0.8s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=720, warm_start=True; total time=   1.7s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=120, warm_start=False; total time=   0.4s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=1720, warm_start=False; total time=   5.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1620, warm_start=False; total time=   3.6s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=920, warm_start=True; total time=   1.8s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=420, warm_start=False; total time=   1.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=320, warm_start=False; total time=   1.3s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1520, warm_start=False; total time=   3.8s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=320, warm_start=True; total time=   1.2s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=320, warm_start=True; total time=   0.8s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=4, n_estimators=1520, warm_start=False; total time=   3.9s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=1320, warm_start=True; total time=   4.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=320, warm_start=True; total time=   0.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1720, warm_start=True; total time=   3.9s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=1220, warm_start=True; total time=   4.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=720, warm_start=True; total time=   2.6s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=1620, warm_start=False; total time=   5.1s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=8, n_estimators=1420, warm_start=True; total time=   3.2s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=1520, warm_start=False; total time=   3.9s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=20, warm_start=False; total time=   0.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=20, warm_start=False; total time=   0.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=20, warm_start=False; total time=   0.1s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=1220, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=1220, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=1220, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=520, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=520, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=520, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=120, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=120, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=120, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=320, warm_start=False; total time=   1.2s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=1520, warm_start=True; total time=   5.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=420, warm_start=False; total time=   1.2s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1020, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1020, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1020, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=1320, warm_start=True; total time=   3.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1020, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1020, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=320, warm_start=False; total time=   1.3s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=8, n_estimators=1720, warm_start=False; total time=   4.4s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=1020, warm_start=True; total time=   2.7s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=320, warm_start=True; total time=   1.2s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=620, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=620, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=620, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=320, warm_start=True; total time=   0.8s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1620, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1620, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1620, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=4, n_estimators=1520, warm_start=False; total time=   4.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=1320, warm_start=False; total time=   5.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1720, warm_start=True; total time=   3.9s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1820, warm_start=True; total time=   7.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1920, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=1820, warm_start=False; total time=   4.2s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=1120, warm_start=True; total time=   4.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=320, warm_start=False; total time=   0.8s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=1220, warm_start=False; total time=   3.9s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=1520, warm_start=True; total time=   5.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=520, warm_start=False; total time=   1.4s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=420, warm_start=False; total time=   0.9s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=920, warm_start=True; total time=   1.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=1520, warm_start=True; total time=   2.9s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1520, warm_start=False; total time=   3.7s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=1020, warm_start=True; total time=   2.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=820, warm_start=True; total time=   3.1s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=1420, warm_start=False; total time=   3.5s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=720, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=720, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=720, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=1920, warm_start=True; total time=   8.3s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=8, n_estimators=1820, warm_start=False; total time=   4.2s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=220, warm_start=True; total time=   0.6s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=220, warm_start=True; total time=   0.5s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=720, warm_start=True; total time=   1.8s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=320, warm_start=True; total time=   0.6s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=1520, warm_start=False; total time=   3.4s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=220, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=220, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=4, n_estimators=220, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=620, warm_start=False; total time=   2.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1020, warm_start=False; total time=   3.4s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=8, n_estimators=1520, warm_start=True; total time=   4.5s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=920, warm_start=False; total time=   2.3s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=1220, warm_start=True; total time=   4.7s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=720, warm_start=True; total time=   2.8s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1920, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1920, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=1820, warm_start=False; total time=   4.2s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=1120, warm_start=True; total time=   4.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=320, warm_start=False; total time=   0.8s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=1220, warm_start=False; total time=   3.9s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=320, warm_start=False; total time=   1.2s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1620, warm_start=False; total time=   3.6s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=520, warm_start=False; total time=   1.5s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=420, warm_start=False; total time=   0.9s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=220, warm_start=False; total time=   0.7s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=1520, warm_start=True; total time=   3.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=1420, warm_start=False; total time=   3.7s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=420, warm_start=False; total time=   1.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1320, warm_start=True; total time=   4.3s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=820, warm_start=False; total time=   2.6s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=20, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=20, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=20, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1920, warm_start=True; total time=   3.7s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=1920, warm_start=True; total time=   8.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=220, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=220, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=220, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=120, warm_start=True; total time=   0.4s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=120, warm_start=True; total time=   0.4s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1620, warm_start=True; total time=   5.4s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=1520, warm_start=False; total time=   3.4s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=520, warm_start=False; total time=   1.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1020, warm_start=False; total time=   3.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=1020, warm_start=True; total time=   3.3s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1120, warm_start=True; total time=   4.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=820, warm_start=False; total time=   3.5s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=920, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=920, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=1620, warm_start=False; total time=   5.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=820, warm_start=False; total time=   2.7s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=20, warm_start=True; total time=   0.1s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=1520, warm_start=False; total time=   3.9s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=120, warm_start=False; total time=   0.4s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=120, warm_start=False; total time=   0.4s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=1720, warm_start=False; total time=   5.4s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=620, warm_start=False; total time=   1.9s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=420, warm_start=False; total time=   1.1s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=220, warm_start=False; total time=   0.7s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=1520, warm_start=True; total time=   3.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=1420, warm_start=False; total time=   3.8s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=420, warm_start=False; total time=   1.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1320, warm_start=True; total time=   4.3s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=820, warm_start=False; total time=   2.6s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1920, warm_start=True; total time=   3.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1520, warm_start=False; total time=   4.8s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1220, warm_start=True; total time=   3.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1820, warm_start=True; total time=   6.1s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=1520, warm_start=False; total time=   3.4s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1520, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1520, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=1520, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=1620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=1620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=1620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=520, warm_start=False; total time=   1.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1020, warm_start=False; total time=   3.4s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=1020, warm_start=True; total time=   3.5s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=120, warm_start=True; total time=   0.3s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=920, warm_start=True; total time=   2.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1320, warm_start=True; total time=   4.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1120, warm_start=False; total time=   4.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=520, warm_start=False; total time=   1.3s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=620, warm_start=True; total time=   1.5s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=1420, warm_start=True; total time=   3.6s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1420, warm_start=True; total time=   3.6s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=8, n_estimators=1420, warm_start=True; total time=   3.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=1220, warm_start=False; total time=   4.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=1520, warm_start=True; total time=   5.2s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=520, warm_start=False; total time=   1.4s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=1320, warm_start=True; total time=   3.2s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1020, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=320, warm_start=False; total time=   1.4s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=8, n_estimators=1720, warm_start=False; total time=   4.4s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=1020, warm_start=True; total time=   2.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=920, warm_start=True; total time=   2.5s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=220, warm_start=True; total time=   0.5s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=720, warm_start=True; total time=   3.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1920, warm_start=True; total time=   3.8s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=220, warm_start=False; total time=   0.6s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=320, warm_start=True; total time=   0.9s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=320, warm_start=True; total time=   1.1s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1220, warm_start=True; total time=   3.9s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=120, warm_start=True; total time=   0.4s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=720, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=720, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=6, n_estimators=720, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1620, warm_start=True; total time=   5.4s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1320, warm_start=True; total time=   3.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=620, warm_start=False; total time=   1.4s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1420, warm_start=True; total time=   3.1s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=620, warm_start=False; total time=   1.6s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=1420, warm_start=False; total time=   3.3s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=920, warm_start=True; total time=   2.8s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1120, warm_start=False; total time=   3.8s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1120, warm_start=False; total time=   4.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=520, warm_start=False; total time=   1.2s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=620, warm_start=True; total time=   1.4s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1120, warm_start=False; total time=   2.7s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=20, warm_start=True; total time=   0.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=6, n_estimators=920, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=420, warm_start=False; total time=   1.4s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=920, warm_start=True; total time=   2.5s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1720, warm_start=False; total time=   3.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=320, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=320, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=4, n_estimators=320, warm_start=True; total time=   0.0s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=420, warm_start=False; total time=   0.9s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=820, warm_start=True; total time=   3.2s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=920, warm_start=True; total time=   2.4s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=720, warm_start=True; total time=   3.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=1320, warm_start=False; total time=   3.1s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1520, warm_start=False; total time=   4.9s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=120, warm_start=False; total time=   0.3s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=8, n_estimators=1820, warm_start=False; total time=   4.5s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=220, warm_start=True; total time=   0.5s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=720, warm_start=True; total time=   1.9s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=320, warm_start=True; total time=   0.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1320, warm_start=True; total time=   3.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=620, warm_start=False; total time=   1.5s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=620, warm_start=False; total time=   2.3s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=620, warm_start=False; total time=   1.6s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=1020, warm_start=True; total time=   3.4s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=120, warm_start=True; total time=   0.3s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=120, warm_start=True; total time=   0.3s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=920, warm_start=True; total time=   2.9s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=820, warm_start=False; total time=   3.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1720, warm_start=False; total time=   6.5s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=120, warm_start=True; total time=   0.4s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=120, warm_start=True; total time=   0.4s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=1420, warm_start=True; total time=   3.6s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1420, warm_start=True; total time=   3.5s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=4, n_estimators=720, warm_start=False; total time=   1.8s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=8, n_estimators=220, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=8, n_estimators=220, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=8, n_estimators=220, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1320, warm_start=True; total time=   4.4s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=120, warm_start=True; total time=   0.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1120, warm_start=True; total time=   2.5s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=920, warm_start=True; total time=   2.4s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=220, warm_start=True; total time=   0.5s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=1420, warm_start=False; total time=   3.5s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=1320, warm_start=False; total time=   3.1s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=220, warm_start=False; total time=   0.5s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=220, warm_start=False; total time=   0.6s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=320, warm_start=True; total time=   0.8s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1220, warm_start=True; total time=   3.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1820, warm_start=True; total time=   6.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=320, warm_start=True; total time=   0.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1320, warm_start=True; total time=   3.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=620, warm_start=False; total time=   1.5s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1420, warm_start=True; total time=   3.3s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=1120, warm_start=True; total time=   3.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1120, warm_start=True; total time=   4.3s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1120, warm_start=False; total time=   3.9s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1120, warm_start=False; total time=   4.3s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1120, warm_start=False; total time=   3.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=1420, warm_start=True; total time=   3.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1120, warm_start=False; total time=   4.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=4, n_estimators=720, warm_start=False; total time=   1.8s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=220, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=220, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=220, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=20, warm_start=False; total time=   0.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=20, warm_start=False; total time=   0.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1720, warm_start=False; total time=   4.6s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=520, warm_start=False; total time=   1.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=720, warm_start=False; total time=   1.5s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=520, warm_start=False; total time=   1.2s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=520, warm_start=False; total time=   1.2s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1620, warm_start=False; total time=   4.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1520, warm_start=False; total time=   2.9s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1220, warm_start=True; total time=   2.9s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=620, warm_start=False; total time=   1.6s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=220, warm_start=False; total time=   0.6s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=920, warm_start=True; total time=   1.8s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=420, warm_start=False; total time=   1.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=520, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=520, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=520, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=1420, warm_start=False; total time=   3.7s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1520, warm_start=False; total time=   3.5s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=820, warm_start=True; total time=   3.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1920, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1920, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=1920, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=220, warm_start=True; total time=   0.5s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=1420, warm_start=False; total time=   3.5s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=1320, warm_start=False; total time=   3.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1520, warm_start=False; total time=   4.9s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=120, warm_start=False; total time=   0.3s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=120, warm_start=False; total time=   0.3s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=8, n_estimators=1820, warm_start=False; total time=   4.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1620, warm_start=True; total time=   5.2s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=420, warm_start=True; total time=   1.8s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=520, warm_start=False; total time=   1.2s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1420, warm_start=True; total time=   3.1s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=1120, warm_start=True; total time=   3.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=1420, warm_start=False; total time=   3.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1320, warm_start=True; total time=   4.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1720, warm_start=False; total time=   6.4s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=620, warm_start=True; total time=   1.5s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1120, warm_start=False; total time=   2.7s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1420, warm_start=True; total time=   3.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1120, warm_start=False; total time=   3.8s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=20, warm_start=False; total time=   0.1s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1720, warm_start=False; total time=   4.5s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=520, warm_start=False; total time=   1.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1220, warm_start=False; total time=   3.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=520, warm_start=False; total time=   1.2s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1620, warm_start=False; total time=   4.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=1920, warm_start=False; total time=   6.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=8, n_estimators=1720, warm_start=False; total time=   4.4s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1320, warm_start=True; total time=   4.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=820, warm_start=False; total time=   2.5s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=720, warm_start=True; total time=   3.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=1920, warm_start=True; total time=   8.5s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=320, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=320, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=320, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1820, warm_start=True; total time=   6.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=720, warm_start=True; total time=   1.7s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=420, warm_start=True; total time=   1.8s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=420, warm_start=True; total time=   1.8s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=620, warm_start=False; total time=   2.2s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=620, warm_start=False; total time=   1.6s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=1120, warm_start=True; total time=   2.9s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1120, warm_start=True; total time=   4.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1120, warm_start=False; total time=   3.7s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1720, warm_start=False; total time=   6.5s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=120, warm_start=True; total time=   0.4s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1120, warm_start=False; total time=   2.7s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=720, warm_start=True; total time=   1.9s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1120, warm_start=False; total time=   4.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=120, warm_start=False; total time=   0.2s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=120, warm_start=False; total time=   0.2s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=120, warm_start=False; total time=   0.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1320, warm_start=True; total time=   4.4s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1120, warm_start=True; total time=   2.5s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1220, warm_start=False; total time=   3.1s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1420, warm_start=False; total time=   3.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1920, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1920, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1920, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1520, warm_start=False; total time=   3.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=1520, warm_start=False; total time=   5.0s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=1420, warm_start=False; total time=   3.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1320, warm_start=True; total time=   4.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=820, warm_start=False; total time=   3.4s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=920, warm_start=False; total time=   2.2s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=20, warm_start=True; total time=   0.1s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=20, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=20, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=520, warm_start=False; total time=   1.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1120, warm_start=False; total time=   2.9s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=720, warm_start=True; total time=   1.9s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=6, n_estimators=920, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=6, n_estimators=920, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=420, warm_start=False; total time=   1.4s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=920, warm_start=True; total time=   2.5s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1720, warm_start=False; total time=   3.8s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=820, warm_start=False; total time=   2.7s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=120, warm_start=True; total time=   0.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=120, warm_start=True; total time=   0.2s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1120, warm_start=True; total time=   2.5s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=1220, warm_start=False; total time=   3.1s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1420, warm_start=False; total time=   3.7s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=2, n_estimators=1520, warm_start=False; total time=   3.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=1520, warm_start=False; total time=   4.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=1220, warm_start=True; total time=   2.9s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1420, warm_start=False; total time=   4.3s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=1920, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=1920, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=1920, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=8, n_estimators=820, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=8, n_estimators=820, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=8, n_estimators=820, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=1520, warm_start=True; total time=   3.9s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=320, warm_start=True; total time=   1.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=320, warm_start=True; total time=   1.4s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=4, n_estimators=420, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=4, n_estimators=420, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=4, n_estimators=420, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1020, warm_start=True; total time=   1.8s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=220, warm_start=True; total time=   0.9s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=320, warm_start=True; total time=   0.8s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=320, warm_start=True; total time=   0.8s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=4, n_estimators=1220, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=4, n_estimators=1220, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=4, n_estimators=1220, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=920, warm_start=False; total time=   2.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=920, warm_start=False; total time=   2.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1120, warm_start=False; total time=   2.9s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=720, warm_start=True; total time=   1.9s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=20, warm_start=True; total time=   0.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=20, warm_start=True; total time=   0.1s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=420, warm_start=False; total time=   1.4s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=8, n_estimators=920, warm_start=True; total time=   2.3s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1620, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1620, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=8, n_estimators=1620, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=120, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=120, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=120, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=6, n_estimators=1720, warm_start=False; total time=   3.9s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=820, warm_start=False; total time=   2.7s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=820, warm_start=False; total time=   2.5s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=1820, warm_start=True; total time=   5.9s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=1620, warm_start=False; total time=   4.1s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=1520, warm_start=False; total time=   4.8s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=620, warm_start=False; total time=   1.5s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=1420, warm_start=False; total time=   2.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1720, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1720, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1720, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1320, warm_start=False; total time=   2.9s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=1020, warm_start=True; total time=   3.2s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1220, warm_start=False; total time=   3.1s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=720, warm_start=False; total time=   1.9s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1520, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1520, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1520, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=220, warm_start=True; total time=   1.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=1720, warm_start=False; total time=   4.2s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1320, warm_start=False; total time=   4.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=620, warm_start=False; total time=   2.9s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=320, warm_start=True; total time=   1.4s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=320, warm_start=True; total time=   1.0s
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
/shared/install_dir/mambaforge/envs/cavityminer_train/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:862: UserWarning: class_weight presets "balanced" or "balanced_subsample" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use "balanced" weights, use compute_class_weight ("balanced", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.
  warn(
XGB: train score -0.000 validation score -0.034
Fitting 3 folds for each of 300 candidates, totalling 900 fits
RF: train score -0.088 validation score -0.095
Fitting 3 folds for each of 300 candidates, totalling 900 fits
MLP: train score -0.000 validation score -0.034
Fitting 3 folds for each of 10 candidates, totalling 30 fits
LR: train score -0.038 validation score -0.060
Fitting 3 folds for each of 300 candidates, totalling 900 fits
Extra: train score -0.099 validation score -0.099
XGB [0.9486893530997305, 0.852473306493961, 0.8761904761904762]
RF [0.9171597035040433, 0.8302047960791179, 0.9466666666666668]
MLP [0.9619373315363883, 0.9074111675126901, 0.8476190476190476]
LR [0.9362499999999999, 0.852763871871171, 0.9066666666666667]
Extra [0.9118665768194071, 0.8295816558725714, 0.9580952380952381]
combined [0.9551617250673854, 0.8955645020129528, 0.9238095238095239]
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=4, n_estimators=720, warm_start=False; total time=   1.8s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1320, warm_start=True; total time=   4.7s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=20, warm_start=False; total time=   0.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=20, warm_start=False; total time=   0.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=20, warm_start=False; total time=   0.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=520, warm_start=False; total time=   1.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=1820, warm_start=True; total time=   6.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=1620, warm_start=False; total time=   4.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=1920, warm_start=False; total time=   6.4s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=1220, warm_start=True; total time=   2.9s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=1820, warm_start=False; total time=   6.8s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=320, warm_start=True; total time=   1.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=320, warm_start=True; total time=   1.4s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=20, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=20, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=4, n_estimators=20, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=720, warm_start=False; total time=   1.8s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1020, warm_start=True; total time=   1.8s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=320, warm_start=True; total time=   0.9s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=220, warm_start=True; total time=   0.6s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1620, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=6, n_estimators=1520, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=6, n_estimators=1520, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1220, warm_start=False; total time=   2.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1320, warm_start=False; total time=   4.4s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1920, warm_start=False; total time=   6.7s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=720, warm_start=False; total time=   3.2s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=820, warm_start=True; total time=   2.6s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1520, warm_start=True; total time=   3.8s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=1420, warm_start=False; total time=   4.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=6, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=6, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=6, n_estimators=1320, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=120, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=120, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=120, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=1420, warm_start=False; total time=   2.8s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=1820, warm_start=False; total time=   6.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=6, n_estimators=320, warm_start=True; total time=   1.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=320, warm_start=True; total time=   1.4s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1520, warm_start=False; total time=   5.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1920, warm_start=True; total time=   4.2s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1620, warm_start=False; total time=   3.6s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1920, warm_start=False; total time=   6.6s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=420, warm_start=False; total time=   1.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1220, warm_start=True; total time=   2.8s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=4, n_estimators=1320, warm_start=False; total time=   3.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=420, warm_start=False; total time=   1.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=420, warm_start=False; total time=   0.9s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=1420, warm_start=False; total time=   4.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=7, min_samples_split=6, n_estimators=1220, warm_start=True; total time=   3.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=8, n_estimators=1820, warm_start=False; total time=   6.7s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1220, warm_start=False; total time=   3.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1520, warm_start=False; total time=   5.6s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1220, warm_start=False; total time=   2.6s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1620, warm_start=False; total time=   3.5s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=1920, warm_start=False; total time=   5.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=1320, warm_start=False; total time=   3.3s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=120, warm_start=False; total time=   0.3s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=120, warm_start=False; total time=   0.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=220, warm_start=True; total time=   0.6s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=20, warm_start=True; total time=   0.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=20, warm_start=True; total time=   0.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=20, warm_start=True; total time=   0.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1020, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1020, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1020, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=820, warm_start=True; total time=   2.7s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=120, warm_start=False; total time=   0.4s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1420, warm_start=True; total time=   3.5s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=1620, warm_start=True; total time=   6.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=720, warm_start=False; total time=   1.5s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=3, min_samples_split=8, n_estimators=720, warm_start=False; total time=   1.4s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1420, warm_start=False; total time=   3.6s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=1620, warm_start=False; total time=   4.1s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1220, warm_start=True; total time=   2.8s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1220, warm_start=True; total time=   2.7s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1420, warm_start=False; total time=   4.4s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=7, min_samples_split=6, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=1020, warm_start=True; total time=   3.2s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=1520, warm_start=True; total time=   3.9s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=720, warm_start=False; total time=   1.9s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=8, n_estimators=220, warm_start=True; total time=   0.9s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=1720, warm_start=False; total time=   4.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1320, warm_start=False; total time=   4.6s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=1920, warm_start=False; total time=   5.5s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=720, warm_start=False; total time=   3.2s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=120, warm_start=False; total time=   0.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=220, warm_start=True; total time=   0.6s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=1320, warm_start=True; total time=   3.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=120, warm_start=False; total time=   0.4s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1420, warm_start=True; total time=   3.5s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=1620, warm_start=True; total time=   6.2s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=2, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=1720, warm_start=False; total time=   4.9s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=420, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=1820, warm_start=True; total time=   6.1s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=6, n_estimators=1620, warm_start=False; total time=   4.3s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=1920, warm_start=False; total time=   6.5s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=1420, warm_start=False; total time=   2.9s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1320, warm_start=False; total time=   3.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=1020, warm_start=True; total time=   3.2s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1220, warm_start=False; total time=   3.2s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=2, max_features=log2, min_samples_leaf=5, min_samples_split=2, n_estimators=1020, warm_start=True; total time=   1.9s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=6, n_estimators=1720, warm_start=False; total time=   3.9s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1920, warm_start=True; total time=   4.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=320, warm_start=False; total time=   1.1s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=620, warm_start=False; total time=   2.9s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1920, warm_start=False; total time=   6.5s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=1320, warm_start=True; total time=   3.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=8, n_estimators=120, warm_start=False; total time=   0.4s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1420, warm_start=True; total time=   3.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=1620, warm_start=True; total time=   6.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=8, n_estimators=620, warm_start=False; total time=   1.5s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=1420, warm_start=False; total time=   4.3s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=7, min_samples_split=2, n_estimators=1320, warm_start=False; total time=   2.9s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=1520, warm_start=True; total time=   3.8s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=9, min_samples_split=4, n_estimators=1520, warm_start=False; total time=   5.5s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=220, warm_start=True; total time=   0.6s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=1120, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1620, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=1, min_samples_split=8, n_estimators=1620, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=6, n_estimators=1520, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=2, n_estimators=1220, warm_start=False; total time=   2.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1620, warm_start=False; total time=   3.5s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=1720, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=8, n_estimators=1920, warm_start=False; total time=   5.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=1320, warm_start=False; total time=   3.4s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=420, warm_start=False; total time=   1.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1220, warm_start=True; total time=   2.7s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=5, min_samples_split=2, n_estimators=20, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=4, n_estimators=1320, warm_start=False; total time=   3.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1520, warm_start=True; total time=   3.6s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=420, warm_start=True; total time=   1.4s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1820, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1620, warm_start=False; total time=   3.6s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=4, n_estimators=220, warm_start=True; total time=   0.6s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=2, max_features=log2, min_samples_leaf=9, min_samples_split=2, n_estimators=1920, warm_start=True; total time=   4.2s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=6, n_estimators=1020, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=6, n_estimators=1020, warm_start=True; total time=   0.0s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=3, min_samples_split=6, n_estimators=1020, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=920, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=920, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=3, min_samples_split=2, n_estimators=920, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=auto, min_samples_leaf=5, min_samples_split=8, n_estimators=620, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=320, warm_start=False; total time=   1.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=320, warm_start=False; total time=   1.0s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=620, warm_start=False; total time=   3.1s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=sqrt, min_samples_leaf=9, min_samples_split=2, n_estimators=320, warm_start=True; total time=   1.1s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=520, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=520, warm_start=False; total time=   0.0s
[CV] END bootstrap=True, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=4, n_estimators=520, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=5, min_samples_split=4, n_estimators=1320, warm_start=False; total time=   3.6s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=4, n_estimators=420, warm_start=False; total time=   1.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=6, n_estimators=1220, warm_start=True; total time=   2.8s
[CV] END bootstrap=True, class_weight=balanced, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=4, n_estimators=820, warm_start=True; total time=   2.6s
[CV] END bootstrap=False, class_weight=balanced, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=3, min_samples_split=6, n_estimators=1520, warm_start=True; total time=   3.7s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=720, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=720, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=auto, min_samples_leaf=1, min_samples_split=2, n_estimators=720, warm_start=False; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=420, warm_start=True; total time=   1.4s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=4, n_estimators=420, warm_start=True; total time=   1.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1620, warm_start=False; total time=   3.6s
[CV] END bootstrap=True, class_weight=balanced_subsample, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=720, warm_start=False; total time=   3.2s
[CV] END bootstrap=True, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=6, n_estimators=220, warm_start=True; total time=   0.6s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=log2, min_samples_leaf=1, min_samples_split=6, n_estimators=1320, warm_start=True; total time=   3.1s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=4, max_features=log2, min_samples_leaf=9, min_samples_split=4, n_estimators=1320, warm_start=False; total time=   3.2s
[CV] END bootstrap=False, class_weight=balanced, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=7, min_samples_split=4, n_estimators=420, warm_start=False; total time=   1.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=1520, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=1520, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=gini, max_depth=2, max_features=auto, min_samples_leaf=7, min_samples_split=8, n_estimators=1520, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1120, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1120, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=entropy, max_depth=4, max_features=auto, min_samples_leaf=9, min_samples_split=2, n_estimators=1120, warm_start=True; total time=   0.0s
[CV] END bootstrap=False, class_weight=None, criterion=gini, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=8, n_estimators=1420, warm_start=False; total time=   4.3s
[CV] END bootstrap=False, class_weight=balanced_subsample, criterion=entropy, max_depth=2, max_features=sqrt, min_samples_leaf=3, min_samples_split=2, n_estimators=1620, warm_start=False; total time=   3.5s
